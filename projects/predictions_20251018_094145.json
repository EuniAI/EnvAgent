{
    "three.js": {
        "project_name": "three.js",
        "project_repo_url": "https://github.com/mrdoob/three.js",
        "success": true,
        "playground_path": "/tmp/tmpu4jbjj80/three",
        "container_info": null,
        "testsuite_states": {
            "testsuite_max_refined_query_loop": 4,
            "testsuite_context_provider_messages": [
                {
                    "type": "SystemMessage",
                    "content": "content=\"You are to discover ONE minimal, safe, and quick verification shell command from README/docs to confirm the environment/setup works (e.g., '<tool> --version', '<package> --help', 'make check', 'pytest -q'). Avoid destructive or long-running commands.\" additional_kwargs={} response_metadata={} id='51a7b8c9-3651-490a-930c-c967b0d1321f'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Find one quick verification command from README/docs for this repository.' additional_kwargs={} response_metadata={} id='278f42e6-050a-43ce-b9c8-710049603a5c'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_3iv5DpJBG4mIxAizuvpIKUgW', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 27839, 'total_tokens': 27859, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1339ec5b-3bd1-46f9-8020-0a811ee03f76-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_3iv5DpJBG4mIxAizuvpIKUgW', 'type': 'tool_call'}] usage_metadata={'input_tokens': 27839, 'output_tokens': 20, 'total_tokens': 27859, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3216376}\\npreview: # three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from \\'three\\';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don\\'t need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/unit/README.md\\', \\'node_id\\': 3217345}\\npreview: ## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/e2e/README.md\\', \\'node_id\\': 3229636}\\npreview: # Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> \\'networkidle0\\' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'manual/resources/tools/geo-picking/README.md\\', \\'node_id\\': 3304630}\\npreview: # Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI\\'m not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don\\'t already know how to do that [here\\'s a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere\\'s also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/RobotExpressive/README.md\\', \\'node_id\\': 3306603}\\npreview: # RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator\\'s Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Nefertiti/README.md\\', \\'node_id\\': 3306605}\\npreview: # Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/MaterialsVariantsShoe/README.md\\', \\'node_id\\': 3306607}\\npreview: # Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Flower/README.md\\', \\'node_id\\': 3306613}\\npreview: # Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/DamagedHelmet/README.md\\', \\'node_id\\': 3306615}\\npreview: # Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/ClearcoatTest/README.md\\', \\'node_id\\': 3306619}\\npreview: # Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/AnimatedMorphSphere/README.md\\', \\'node_id\\': 3306621}\\npreview: # Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/fbx/README.md\\', \\'node_id\\': 3306625}\\npreview: ## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/3mf/README.md\\', \\'node_id\\': 3306631}\\npreview: ## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/draco/README.md\\', \\'node_id\\': 3341252}\\npreview: # Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project\\'s [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath(\\'path/to/decoders/\\');\\ndracoLoader.setDecoderConfig({type: \\'js\\'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/basis/README.md\\', \\'node_id\\': 3342150}\\npreview: # Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/ies/README.md\\', \\'node_id\\': 3351929}\\npreview: Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/README.md\\', \\'node_id\\': 3351932}\\npreview: ## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces\\n\\n\\nResult 18:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/ttf/README.md\\', \\'node_id\\': 3351935}\\npreview: # Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)' name='preview_file_content_with_basename' id='1ff734c5-3193-4504-9556-7209849e31d4' tool_call_id='call_3iv5DpJBG4mIxAizuvpIKUgW' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3216376}, 'preview': \"# three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from 'three';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3217345}, 'preview': '## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/e2e/README.md', 'node_id': 3229636}, 'preview': \"# Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> 'networkidle0' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'manual/resources/tools/geo-picking/README.md', 'node_id': 3304630}, 'preview': \"# Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI'm not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don't already know how to do that [here's a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere's also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/RobotExpressive/README.md', 'node_id': 3306603}, 'preview': \"# RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator's Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Nefertiti/README.md', 'node_id': 3306605}, 'preview': '# Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/MaterialsVariantsShoe/README.md', 'node_id': 3306607}, 'preview': '# Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Flower/README.md', 'node_id': 3306613}, 'preview': '# Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/DamagedHelmet/README.md', 'node_id': 3306615}, 'preview': '# Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/ClearcoatTest/README.md', 'node_id': 3306619}, 'preview': '# Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/AnimatedMorphSphere/README.md', 'node_id': 3306621}, 'preview': '# Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/fbx/README.md', 'node_id': 3306625}, 'preview': '## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/3mf/README.md', 'node_id': 3306631}, 'preview': '## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/draco/README.md', 'node_id': 3341252}, 'preview': \"# Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project's [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath('path/to/decoders/');\\ndracoLoader.setDecoderConfig({type: 'js'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/basis/README.md', 'node_id': 3342150}, 'preview': '# Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/ies/README.md', 'node_id': 3351929}, 'preview': 'Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/README.md', 'node_id': 3351932}, 'preview': '## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/ttf/README.md', 'node_id': 3351935}, 'preview': '# Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_L5aVuAZ5Sm1Wvrr4b4o2yLhM', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 27839, 'total_tokens': 27859, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 27776}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--7721cf3f-2b49-42b4-95e9-100b337e73cb-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_L5aVuAZ5Sm1Wvrr4b4o2yLhM', 'type': 'tool_call'}] usage_metadata={'input_tokens': 27839, 'output_tokens': 20, 'total_tokens': 27859, 'input_token_details': {'audio': 0, 'cache_read': 27776}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3216376}\\npreview: # three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from \\'three\\';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don\\'t need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/unit/README.md\\', \\'node_id\\': 3217345}\\npreview: ## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/e2e/README.md\\', \\'node_id\\': 3229636}\\npreview: # Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> \\'networkidle0\\' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'manual/resources/tools/geo-picking/README.md\\', \\'node_id\\': 3304630}\\npreview: # Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI\\'m not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don\\'t already know how to do that [here\\'s a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere\\'s also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/RobotExpressive/README.md\\', \\'node_id\\': 3306603}\\npreview: # RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator\\'s Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Nefertiti/README.md\\', \\'node_id\\': 3306605}\\npreview: # Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/MaterialsVariantsShoe/README.md\\', \\'node_id\\': 3306607}\\npreview: # Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Flower/README.md\\', \\'node_id\\': 3306613}\\npreview: # Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/DamagedHelmet/README.md\\', \\'node_id\\': 3306615}\\npreview: # Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/ClearcoatTest/README.md\\', \\'node_id\\': 3306619}\\npreview: # Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/AnimatedMorphSphere/README.md\\', \\'node_id\\': 3306621}\\npreview: # Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/fbx/README.md\\', \\'node_id\\': 3306625}\\npreview: ## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/3mf/README.md\\', \\'node_id\\': 3306631}\\npreview: ## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/draco/README.md\\', \\'node_id\\': 3341252}\\npreview: # Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project\\'s [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath(\\'path/to/decoders/\\');\\ndracoLoader.setDecoderConfig({type: \\'js\\'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/basis/README.md\\', \\'node_id\\': 3342150}\\npreview: # Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/ies/README.md\\', \\'node_id\\': 3351929}\\npreview: Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/README.md\\', \\'node_id\\': 3351932}\\npreview: ## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces\\n\\n\\nResult 18:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/ttf/README.md\\', \\'node_id\\': 3351935}\\npreview: # Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)' name='preview_file_content_with_basename' id='f8d37119-eaf4-45c7-99fc-e6ee8545508a' tool_call_id='call_L5aVuAZ5Sm1Wvrr4b4o2yLhM' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3216376}, 'preview': \"# three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from 'three';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3217345}, 'preview': '## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/e2e/README.md', 'node_id': 3229636}, 'preview': \"# Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> 'networkidle0' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'manual/resources/tools/geo-picking/README.md', 'node_id': 3304630}, 'preview': \"# Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI'm not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don't already know how to do that [here's a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere's also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/RobotExpressive/README.md', 'node_id': 3306603}, 'preview': \"# RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator's Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Nefertiti/README.md', 'node_id': 3306605}, 'preview': '# Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/MaterialsVariantsShoe/README.md', 'node_id': 3306607}, 'preview': '# Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Flower/README.md', 'node_id': 3306613}, 'preview': '# Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/DamagedHelmet/README.md', 'node_id': 3306615}, 'preview': '# Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/ClearcoatTest/README.md', 'node_id': 3306619}, 'preview': '# Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/AnimatedMorphSphere/README.md', 'node_id': 3306621}, 'preview': '# Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/fbx/README.md', 'node_id': 3306625}, 'preview': '## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/3mf/README.md', 'node_id': 3306631}, 'preview': '## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/draco/README.md', 'node_id': 3341252}, 'preview': \"# Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project's [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath('path/to/decoders/');\\ndracoLoader.setDecoderConfig({type: 'js'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/basis/README.md', 'node_id': 3342150}, 'preview': '# Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/ies/README.md', 'node_id': 3351929}, 'preview': 'Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/README.md', 'node_id': 3351932}, 'preview': '## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/ttf/README.md', 'node_id': 3351935}, 'preview': '# Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_1MrGXoUxQ2LjJ8Eh5xU7lFoc', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 27839, 'total_tokens': 27859, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 27776}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--322d9e53-f7cc-4e34-ba43-1b7fceb4fa4b-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_1MrGXoUxQ2LjJ8Eh5xU7lFoc', 'type': 'tool_call'}] usage_metadata={'input_tokens': 27839, 'output_tokens': 20, 'total_tokens': 27859, 'input_token_details': {'audio': 0, 'cache_read': 27776}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3216376}\\npreview: # three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from \\'three\\';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don\\'t need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/unit/README.md\\', \\'node_id\\': 3217345}\\npreview: ## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/e2e/README.md\\', \\'node_id\\': 3229636}\\npreview: # Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> \\'networkidle0\\' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'manual/resources/tools/geo-picking/README.md\\', \\'node_id\\': 3304630}\\npreview: # Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI\\'m not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don\\'t already know how to do that [here\\'s a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere\\'s also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/RobotExpressive/README.md\\', \\'node_id\\': 3306603}\\npreview: # RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator\\'s Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Nefertiti/README.md\\', \\'node_id\\': 3306605}\\npreview: # Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/MaterialsVariantsShoe/README.md\\', \\'node_id\\': 3306607}\\npreview: # Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/Flower/README.md\\', \\'node_id\\': 3306613}\\npreview: # Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/DamagedHelmet/README.md\\', \\'node_id\\': 3306615}\\npreview: # Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/ClearcoatTest/README.md\\', \\'node_id\\': 3306619}\\npreview: # Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/gltf/AnimatedMorphSphere/README.md\\', \\'node_id\\': 3306621}\\npreview: # Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/fbx/README.md\\', \\'node_id\\': 3306625}\\npreview: ## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/models/3mf/README.md\\', \\'node_id\\': 3306631}\\npreview: ## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/draco/README.md\\', \\'node_id\\': 3341252}\\npreview: # Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project\\'s [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath(\\'path/to/decoders/\\');\\ndracoLoader.setDecoderConfig({type: \\'js\\'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/jsm/libs/basis/README.md\\', \\'node_id\\': 3342150}\\npreview: # Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/ies/README.md\\', \\'node_id\\': 3351929}\\npreview: Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/README.md\\', \\'node_id\\': 3351932}\\npreview: ## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces\\n\\n\\nResult 18:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'examples/fonts/ttf/README.md\\', \\'node_id\\': 3351935}\\npreview: # Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)' name='preview_file_content_with_basename' id='749735f5-b475-42ac-83a7-685b9a2801c0' tool_call_id='call_1MrGXoUxQ2LjJ8Eh5xU7lFoc' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3216376}, 'preview': \"# three.js\\n\\n[![NPM Package][npm]][npm-url]\\n[![Build Size][build-size]][build-size-url]\\n[![NPM Downloads][npm-downloads]][npmtrends-url]\\n[![Discord][discord]][discord-url]\\n[![DeepWiki][deepwiki]][deepwiki-url]\\n\\n#### JavaScript 3D library\\n\\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\\n\\n[Examples](https://threejs.org/examples/) &mdash;\\n[Docs](https://threejs.org/docs/) &mdash;\\n[Manual](https://threejs.org/manual/) &mdash;\\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\\n[Forum](https://discourse.threejs.org/) &mdash;\\n[Discord](https://discord.gg/56GBJwAnUS)\\n\\n### Usage\\n\\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\\n\\n```javascript\\nimport * as THREE from 'three';\\n\\nconst width = window.innerWidth, height = window.innerHeight;\\n\\n// init\\n\\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\\ncamera.position.z = 1;\\n\\nconst scene = new THREE.Scene();\\n\\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\\nconst material = new THREE.MeshNormalMaterial();\\n\\nconst mesh = new THREE.Mesh( geometry, material );\\nscene.add( mesh );\\n\\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\\nrenderer.setSize( width, height );\\nrenderer.setAnimationLoop( animate );\\ndocument.body.appendChild( renderer.domElement );\\n\\n// animation\\n\\nfunction animate( time ) {\\n\\n\\tmesh.rotation.x = time / 2000;\\n\\tmesh.rotation.y = time / 1000;\\n\\n\\trenderer.render( scene, camera );\\n\\n}\\n```\\n\\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n\\n### Cloning this repository\\n\\nCloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\\n\\n```sh\\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\\n```\\n\\n### Change log\\n\\n[Releases](https://github.com/mrdoob/three.js/releases)\\n\\n\\n[npm]: https://img.shields.io/npm/v/three\\n[npm-url]: https://www.npmjs.com/package/three\\n[build-size]: https://badgen.net/bundlephobia/minzip/three\\n[build-size-url]: https://bundlephobia.com/result?p=three\\n[npm-downloads]: https://img.shields.io/npm/dw/three\\n[npmtrends-url]: https://www.npmtrends.com/three\\n[discord]: https://img.shields.io/discord/685241246557667386\\n[discord-url]: https://discord.gg/56GBJwAnUS\\n[deepwiki]: https://deepwiki.com/badge.svg\\n[deepwiki-url]: https://deepwiki.com/mrdoob/three.js\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3217345}, 'preview': '## Setup\\n\\n- Execute `npm install` from the root folder\\n\\n## Run\\n\\nYou can run the unit tests in two environments:\\n\\n- Node.js: Execute `npm run test-unit` from the root folder\\n- Browser: Execute `npx servez -p 8080 --ssl` (or run any other local web sever) from the root folder and access `https://localhost:8080/test/unit/UnitTests.html` in a web browser.\\n\\nSee [Installation](https://threejs.org/docs/#manual/introduction/Installation) for more information.\\n\\n## Notes\\n\\nA small number of tests can only be run in a browser environment.\\n\\nFor browser tests, further changes to the library will not be reflected until the page is refreshed.\\n\\n## Troubleshooting\\n\\nWhen adding or updating tests, the most common cause of test failure is forgetting to change `QUnit.todo` to `QUnit.test` when the test is ready.\\n\\nAn error that indicates \"no tests were found\" means that an import statement could not be resolved. This is usually caused by a typo in the import path.\\n\\n## Debugging\\n\\nTo debug a test, add `debugger;` to the test code. Then, run the test in a browser and open the developer tools. The test will stop at the `debugger` statement and you can inspect the code.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/e2e/README.md', 'node_id': 3229636}, 'preview': \"# Three.js end-to-end testing\\n\\n### Motivation\\nSimplify code reviews with quick pixel testing inside CI. The same screenshots are used for thumbnails.\\n\\n### Local usage\\nIf you get an error in e2e test after PR and you sure that all is correct,\\njust make a new screenshot to example. As a last resort increase timeouts or add it to exception list.\\n\\n```shell\\n# generate new screenshots for exact examples\\nnpm run make-screenshot <example1_name> ... <exampleN_name>\\n\\n# check exact examples\\nnpm run test-e2e <example1_name> ... <exampleN_name>\\n\\n# check all examples\\nnpm run test-e2e\\n```\\n\\nMerge only those commits that pass the tests, otherwise all next commits will also fail.\\n\\n### How it works\\n- ci configs with parallelism\\n- deterministic random/timer/rAF/video for screenshots\\n- increased robustness with hided text, datgui, different flags and timeouts.\\n- pipeline: turn off rAF -> 'networkidle0' -> networkTax -> turn on rAF -> render promise\\n- added 3 progressive attempts for robustness\\n\\n### Development progress\\n\\n|           Travis                        |               Attempts               |\\n|-----------------------------------------|--------------------------------------|\\n| 61 from 362 failed, time=21:14          | networkidle0 timeout                 |\\n| 26 from 362 failed, time=16:22          | with rAF hook                        |\\n| 13=1+1+7+4 failed, time=4:26            | with render promise and parallelism  |\\n| 4=0+0+2+2 failed, time=5:13             | with network tax and other settings  |\\n| 4=0+0+2+2 failed, time=3:26             | with progressive attempts            |\\n\\n### Status\\n97% examples are covered with tests. Check exception list for more information.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'manual/resources/tools/geo-picking/README.md', 'node_id': 3304630}, 'preview': \"# Geo Picking Data\\n\\nThese tools were used to generate data for both\\n[the article on aligning HTML elements to 3D](https://threejs.org/manual/en/align-html-elements-to-3d.html)\\nand [the article on using indexed textures for picking and color](https://threejs.org/manual/en/indexed-textures.html)\\n\\nI'm not going to go into details on how they work but you can look inside\\nand see them draw the images and extract the data. Maybe you can use them\\nto make or extract similar maps from other data.\\n\\nThe one I actually used is `make-geo-picking-texture.html`. To run it you need\\nto download the data from [here](http://thematicmapping.org/downloads/world_borders.php)\\nthen unzip it and put it in this folder.\\n\\nThen run a simple server. If you don't already know how to do that [here's a simple one](https://greggman.github.io/servez/)\\nthat will take just a few clicks to use. Run it, point it at this folder, then load `make-geo-picking-texture.html`\\nin your browser.\\n\\nThere's also another one called `make-geo-picking-texture-ogc.html`. It works with data from\\n[here](https://gadm.org/download_world.html). To use that one download the database then use\\na tool like [https://sqlitebrowser.org/](https://sqlitebrowser.org/). Open the database and\\nexport the table called `level1` to a json file called `level1.json`\\n\\nThen run a simple server like above and open `make-geo-picking-texture-ogc.html` in your browser.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/RobotExpressive/README.md', 'node_id': 3306603}, 'preview': \"# RobotExpressive\\n\\nModel by [Tomás Laulhé](https://www.patreon.com/quaternius). Before using this\\nmodel on a project, consider supporting the creator's Patreon. CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Added three facial expression morph targets\\n- Converted with FBX2GLTF\\n- Removed duplicate materials and reduced material metalness\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Nefertiti/README.md', 'node_id': 3306605}, 'preview': '# Nefertiti\\n\\n## License Information\\n\\nModel is provided under a creative commons license for non-commercial purposes (CC BY-NC).\\n\\n3D scan of a copy of the Nefertiti Bust\\n\\nDigitized by Fraunhofer IGD, Competence Center Cultural Heritage Digitization, http://www.cultlab3d.de/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/MaterialsVariantsShoe/README.md', 'node_id': 3306607}, 'preview': '# Materials Variants Shoe\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.jpg)\\n\\n## Description\\n\\nThis model uses the KHR_materials_variants extension. It is a shoe with 3 color variants in it: \"Beach\", \"Midnight\", and \"Street\".\\n\\nIf each variant was a separate model, they would be 5.4 MB each. Combined they make up a single model that is 7.8MB since they share geometry and all textures except the base color texture.\\n\\nnote: The textures in this repository have been resized to save space. \\n      See https://github.com/pushmatrix/glTF-Sample-Models/tree/master/2.0/MaterialsVariantsShoe for the original.\\n\\n## License Information\\nCopyright 2020 Shopify, Inc. \\nCC BY 4.0 https://creativecommons.org/licenses/by/4.0/'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/Flower/README.md', 'node_id': 3306613}, 'preview': '# Flower\\n\\nModel by [Kenney](https://twitter.com/KenneyNL), from [Nature Pack](https://www.kenney.nl/assets/nature-pack). CC0 1.0.\\n\\nModifications by [Don McCurdy](https://donmccurdy.com/):\\n\\n- Split stem and blossom meshes.\\n- Color adjustments.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/DamagedHelmet/README.md', 'node_id': 3306615}, 'preview': '# Damaged Helmet\\n\\nhttps://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/DamagedHelmet\\n\\n## License Information\\n\\nBattle Damaged Sci-fi Helmet - PBR by [theblueturtle_](https://sketchfab.com/theblueturtle_), published under a Creative Commons Attribution-NonCommercial license\\n\\nhttps://sketchfab.com/models/b81008d513954189a063ff901f7abfe4\\n\\n## Modifications\\n\\nThe original model was built on an early draft of glTF 2.0 that did not become final.  This new model has been imported and re-exported from Blender to bring it into alignment with the final release glTF 2.0 specification.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/ClearcoatTest/README.md', 'node_id': 3306619}, 'preview': '# Clearcoat Test\\n\\nThis model tests various settings and textures from the KHR_materials_clearcoat extension. Original version and further details in [glTF-Sample-Models / 2.0 / ClearcoatTest](https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/ClearCoatTest).\\n\\n## License Information\\n\\nCopyright 2020 Analytical Graphics, Inc. [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). Model and textures by Ed Mackey.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/gltf/AnimatedMorphSphere/README.md', 'node_id': 3306621}, 'preview': '# Animated Morph Sphere\\n\\n## Details\\n\\nThe sphere contains two morph targets in it:\\n\\n  * **`blob`** : moves the vertices so that it becomes a somewhat amorphous fat, blob shape.\\n  * **`ship`** : moves the vertices so that it looks a bit like a spaceship, the goal being\\n    to just make it a much more complicated morph example than the [cube](../AnimatedMorphCube/README.md).\\n\\nThe animation loops, morphing between these two states.\\n\\n## Screenshot\\n\\n![screenshot](screenshot/screenshot.gif)\\n\\n## License Information\\n\\nPublic domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))\\n\\nDonated by Howard Wolosky for glTF testing.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/fbx/README.md', 'node_id': 3306625}, 'preview': '## License of the files in this directory\\n\\n### nurbs.fbx\\n\\nLicense: Public domain ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/models/3mf/README.md', 'node_id': 3306631}, 'preview': '## License of the files in this directory\\n\\n### cube_gears.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### facecolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `rhombicuboctahedron_color.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### multipletextures.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### vertexcolors.3mf \\n\\nSource: https://github.com/3MFConsortium/3mf-samples (original name `pyramid_vertexcolor.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License\\n\\n### volumetric.3mf \\n\\nSource: https://github.com/3MFConsortium/gladius (original name `SphereInACage.3mf`)\\n\\nLicense: BSD 2-Clause \"Simplified\" License'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/draco/README.md', 'node_id': 3341252}, 'preview': \"# Draco 3D Data Compression\\n\\nDraco is an open-source library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.\\n\\n[Website](https://google.github.io/draco/) | [GitHub](https://github.com/google/draco)\\n\\n## Contents\\n\\nThis folder contains three utilities:\\n\\n* `draco_decoder.js` — Emscripten-compiled decoder, compatible with any modern browser.\\n* `draco_decoder.wasm` — WebAssembly decoder, compatible with newer browsers and devices.\\n* `draco_wasm_wrapper.js` — JavaScript wrapper for the WASM decoder.\\n\\nEach file is provided in two variations:\\n\\n* **Default:** Latest stable builds, tracking the project's [master branch](https://github.com/google/draco).\\n* **glTF:** Builds targeted by the [glTF mesh compression extension](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression), tracking the [corresponding Draco branch](https://github.com/google/draco/tree/gltf_2.0_draco_extension).\\n\\nEither variation may be used with `DRACOLoader`:\\n\\n```js\\nvar dracoLoader = new DRACOLoader();\\ndracoLoader.setDecoderPath('path/to/decoders/');\\ndracoLoader.setDecoderConfig({type: 'js'}); // (Optional) Override detection of WASM support.\\n```\\n\\nFurther [documentation on GitHub](https://github.com/google/draco/tree/master/javascript/example#static-loading-javascript-decoder).\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/google/draco/blob/master/LICENSE)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/jsm/libs/basis/README.md', 'node_id': 3342150}, 'preview': '# Basis Universal GPU Texture Compression\\n\\nBasis Universal is a \"[supercompressed](http://gamma.cs.unc.edu/GST/gst.pdf)\"\\nGPU texture and texture video compression system that outputs a highly\\ncompressed intermediate file format (.basis) that can be quickly transcoded to\\na wide variety of GPU texture compression formats.\\n\\n[GitHub](https://github.com/BinomialLLC/basis_universal)\\n\\n## Transcoders\\n\\nBasis Universal texture data may be used in two different file formats:\\n`.basis` and `.ktx2`, where `ktx2` is a standardized wrapper around basis texture data.\\n\\nFor further documentation about the Basis compressor and transcoder, refer to\\nthe [Basis GitHub repository](https://github.com/BinomialLLC/basis_universal).\\n\\nThe folder contains two files required for transcoding `.basis` or `.ktx2` textures:\\n\\n* `basis_transcoder.js` — JavaScript wrapper for the WebAssembly transcoder.\\n* `basis_transcoder.wasm` — WebAssembly transcoder.\\n\\nBoth are dependencies of `KTX2Loader`:\\n\\n```js\\nconst ktx2Loader = new KTX2Loader();\\nktx2Loader.setTranscoderPath( \\'examples/jsm/libs/basis/\\' );\\nktx2Loader.detectSupport( renderer );\\nktx2Loader.load( \\'diffuse.ktx2\\', function ( texture ) {\\n\\n\\tconst material = new THREE.MeshStandardMaterial( { map: texture } );\\n\\n}, function () {\\n\\n\\tconsole.log( \\'onProgress\\' );\\n\\n}, function ( e ) {\\n\\n\\tconsole.error( e );\\n\\n} );\\n```\\n\\n## License\\n\\n[Apache License 2.0](https://github.com/BinomialLLC/basis_universal/blob/master/LICENSE)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/ies/README.md', 'node_id': 3351929}, 'preview': 'Profiles from the [IES Library](https://ieslibrary.com/en/home) website.\\n\\nNew profiles can be created via [CNDL](https://cndl.io/).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/README.md', 'node_id': 3351932}, 'preview': '## MgOpen typefaces\\n\\n# Source and License\\n\\nhttps://web.archive.org/web/20050528114140/https://ellak.gr/fonts/mgopen/index.en\\n\\n# Usage\\n\\nUse Facetype.js to generate typeface.json fonts: https://gero3.github.io/facetype.js/\\n\\nCollection of Google fonts as typeface data for usage with three.js: https://github.com/components-ai/typefaces'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'examples/fonts/ttf/README.md', 'node_id': 3351935}, 'preview': '# Kenney Fonts\\n\\n## Source\\n\\nhttps://www.kenney.nl/assets/kenney-fonts\\n\\n## License\\n\\nCC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/)'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content=\"Search README, Quickstart, Installation, or Getting Started sections for a quick verification command like 'make check' or 'npm test'.\" additional_kwargs={} response_metadata={} id='99c8b887-7324-441b-b7fe-384122238452'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "testsuite_refined_query": "Search README, Quickstart, Installation, or Getting Started sections for a quick verification command like 'make check' or 'npm test'.",
            "testsuite_command": [
                "git clone --depth=1 https://github.com/mrdoob/three.js.git",
                "npm run test-unit",
                "npx servez -p 8080 --ssl",
                "npm run test-e2e"
            ]
        },
        "env_states": {
            "max_refined_query_loop": 3,
            "env_implement_file_context_query": "OBJECTIVE: Find the most relevant environment configuration files that can help generate an accurate Dockerfile for this project,\nincluding Dockerfiles, dependency files, build configurations, and environment setup files.\n\n<reasoning>\n1. Analyze project characteristics:\n   - Programming language and framework\n   - Dependency management files\n   - Build system and tools\n   - Runtime requirements\n   - Environment configurations\n\n2. Search requirements:\n   - Existing Dockerfiles or containerization files\n   - Dependency files (requirements.txt, package.json, pom.xml, etc.)\n   - Build configuration files (Makefile, CMakeLists.txt, etc.)\n   - Environment configuration files (.env, config files)\n   - Setup and installation scripts\n\n3. Focus areas:\n   - Docker-related files (Dockerfile, docker-compose.yml, .dockerignore)\n   - Package management files (requirements.txt, package.json, go.mod, Cargo.toml, etc.)\n   - Build system files (Makefile, CMakeLists.txt, build.gradle, etc.)\n   - Environment configuration (.env, config.json, application.properties, etc.)\n   - Setup documentation (README.md, INSTALL.md, SETUP.md)\n   - CI/CD configuration files\n</reasoning>\n\nREQUIREMENTS:\n- Return the most relevant environment configuration files for Dockerfile generation\n- Must include complete file content with exact file paths and line numbers\n- Must include dependency files, build configurations, and environment setups\n- Must include any existing Docker-related files\n- Must include setup documentation and installation instructions\n\n<examples>\n<example id=\"python-web-app\">\n<project_context>\nPython Flask web application with requirements.txt\n</project_context>\n\n<ideal_files>\n# File: requirements.txt\nFlask==2.3.3\ngunicorn==21.2.0\npsycopg2-binary==2.9.7\nredis==4.6.0\n\n# File: app.py\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    return 'Hello World!'\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n\n# File: README.md\n## Installation\npip install -r requirements.txt\npython app.py\n</ideal_files>\n</example>\n\n<example id=\"nodejs-api\">\n<project_context>\nNode.js Express API with package.json\n</project_context>\n\n<ideal_files>\n# File: package.json\n{\n  \"name\": \"my-api\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^7.5.0\"\n  }\n}\n\n# File: server.js\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\napp.get('/', (req, res) => {\n  res.json({ message: 'API is running' });\n});\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});\n</ideal_files>\n</example>\n\nSearch priority:\n1. Existing Dockerfiles or containerization files\n2. Dependency management files (requirements.txt, package.json, etc.)\n3. Build configuration files (Makefile, CMakeLists.txt, etc.)\n4. Environment configuration files (.env, config files)\n5. Setup documentation and installation instructions\n\nFind the most relevant environment configuration files with complete context for Dockerfile generation.\n",
            "env_implement_file_context": [
                {
                    "type": "Context",
                    "content": "File: README.md\nLine number range: 61 - 69\nContent:\n61. If everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\n62. \n63. ### Cloning this repository\n64. \n65. Cloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\n66. \n67. ```sh\n68. git clone --depth=1 https://github.com/mrdoob/three.js.git\n69. ```\n",
                    "relative_path": "README.md",
                    "start_line_number": 61,
                    "end_line_number": 69
                },
                {
                    "type": "Context",
                    "content": "File: .github/CONTRIBUTING.md\nLine number range: 1 - 79\nContent:\n1. # Contribution\n2. ## Introduction\n3. \n4. It is assumed that you know a little about Node.js and Git. If not, [here's some help to get started with Git](https://help.github.com/en/github/using-git) and [here’s some help to get started with Node.js.](https://nodejs.org/en/docs/guides/getting-started-guide/)\n5. \n6. * Install [Node.js](https://nodejs.org/)\n7. * Install [Git](https://git-scm.com/)\n8. * [Fork](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) three.js\n9. * Open your OS’s terminal\n10. * Change into the directory you’d like\n11. * Clone your forked repo\n12. \n13.       git clone https://github.com/[yourgithubname]/three.js.git\n14. \n15. * Go into the three.js directory.\n16. \n17.       cd ./three.js\n18. \n19. * Install the dependencies\n20. \n21.       npm ci\n22. \n23. ## Next Steps\n24. \n25. As per the npm standard, ‘start’ is the place to begin the package.\n26. \n27.     npm start\n28. \n29. This script will start a local server similar to [threejs.org](https://threejs.org/), but instead will be hosted on your local machine. Browse to https://localhost:8080/ to check it out. It also automatically creates the `build/three.module.js` script anytime there is a change `src` directory.\n30. \n31. Next scripts run all the appropriate testing.\n32. \n33. - `npm run test` - Lint testing and unit testing (individually being `npm run lint` and `npm run test-unit`)\n34. - `npm run test-e2e` - E2E testing. This one can take quite a long time and installs ~200 MB Chromium browser - it is primarily intended to be run only by GitHub Actions\n35. \n36. The linting is there to keep a consistent code style across all of the code and the testing is there to help catch bugs and check that the code behaves as expected. It is important that neither of these steps comes up with any errors due to your changes.\n37. \n38. Most linting errors can be fixed automatically by running\n39. \n40.     npm run lint-fix\n41. \n42. If you’d like to make a build of the source files (e.g. `build/three.module.js`) run:\n43. \n44.     npm run build\n45. \n46. ## Making changes\n47. \n48. When you’ve decided to make changes, start with the following:\n49. \n50. * Update your local repo\n51. \n52.       git pull https://github.com/mrdoob/three.js.git\n53.       git push\n54. \n55. * Make a new branch from the dev branch\n56. \n57.       git checkout dev\n58.       git branch [mychangesbranch]\n59.       git checkout [mychangesbranch]\n60. \n61. * Add your changes to your commit.\n62. * Push the changes to your forked repo.\n63. * Open a Pull Request (PR)\n64. \n65. ## Important notes:\n66. \n67. * Don't include any build files in your commit.\n68. * Not all new features will need a new example. Simpler features could be incorporated into an existing example. Bigger features may be asked to add an example demonstrating the feature.\n69. * Making changes may require changes to the documentation. To update the docs in other languages, simply copy the English to begin with.\n70. * It's good to also add an example and screenshot for it, for showing how it's used and for end-to-end testing.\n71. * If you modify existing code, run relevant examples to check they didn't break and there wasn't performance regress.\n72. * If you add some assets for the examples (models, textures, sounds, etc), make sure they have a proper license allowing for their use here, less restrictive the better. It is unlikely for large assets to be accepted.\n73. * If some issue is relevant to the patch/feature, please mention it with a hash (e.g. #2774) in a commit message to get cross-reference in GitHub.\n74. * If the end-to-end test failed and you are sure that all is correct, follow the instructions it outputs.\n75. * Once done with a patch/feature do not add more commits to a feature branch.\n76. * Create separate branches per patch or feature.\n77. * If you make a PR but it is not actually ready to be pulled into the dev branch then please [convert it to a draft PR](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/changing-the-stage-of-a-pull-request#converting-a-pull-request-to-a-draft).\n78. \n79. This project is currently contributed mostly via everyone's spare time. Please keep that in mind as it may take some time for the appropriate feedback to get to you. If you are unsure about adding a new feature, it might be better to ask first to see whether other people think it's a good idea.\n",
                    "relative_path": ".github/CONTRIBUTING.md",
                    "start_line_number": 1,
                    "end_line_number": 79
                }
            ],
            "env_implement_write_messages": [
                {
                    "type": "HumanMessage",
                    "content": "content=\"Project Environment Context:\\nFile: README.md\\nLine number range: 61 - 69\\nContent:\\n61. If everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\\n62. \\n63. ### Cloning this repository\\n64. \\n65. Cloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\\n66. \\n67. ```sh\\n68. git clone --depth=1 https://github.com/mrdoob/three.js.git\\n69. ```\\n\\n\\nFile: .github/CONTRIBUTING.md\\nLine number range: 1 - 79\\nContent:\\n1. # Contribution\\n2. ## Introduction\\n3. \\n4. It is assumed that you know a little about Node.js and Git. If not, [here's some help to get started with Git](https://help.github.com/en/github/using-git) and [here’s some help to get started with Node.js.](https://nodejs.org/en/docs/guides/getting-started-guide/)\\n5. \\n6. * Install [Node.js](https://nodejs.org/)\\n7. * Install [Git](https://git-scm.com/)\\n8. * [Fork](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) three.js\\n9. * Open your OS’s terminal\\n10. * Change into the directory you’d like\\n11. * Clone your forked repo\\n12. \\n13.       git clone https://github.com/[yourgithubname]/three.js.git\\n14. \\n15. * Go into the three.js directory.\\n16. \\n17.       cd ./three.js\\n18. \\n19. * Install the dependencies\\n20. \\n21.       npm ci\\n22. \\n23. ## Next Steps\\n24. \\n25. As per the npm standard, ‘start’ is the place to begin the package.\\n26. \\n27.     npm start\\n28. \\n29. This script will start a local server similar to [threejs.org](https://threejs.org/), but instead will be hosted on your local machine. Browse to https://localhost:8080/ to check it out. It also automatically creates the `build/three.module.js` script anytime there is a change `src` directory.\\n30. \\n31. Next scripts run all the appropriate testing.\\n32. \\n33. - `npm run test` - Lint testing and unit testing (individually being `npm run lint` and `npm run test-unit`)\\n34. - `npm run test-e2e` - E2E testing. This one can take quite a long time and installs ~200 MB Chromium browser - it is primarily intended to be run only by GitHub Actions\\n35. \\n36. The linting is there to keep a consistent code style across all of the code and the testing is there to help catch bugs and check that the code behaves as expected. It is important that neither of these steps comes up with any errors due to your changes.\\n37. \\n38. Most linting errors can be fixed automatically by running\\n39. \\n40.     npm run lint-fix\\n41. \\n42. If you’d like to make a build of the source files (e.g. `build/three.module.js`) run:\\n43. \\n44.     npm run build\\n45. \\n46. ## Making changes\\n47. \\n48. When you’ve decided to make changes, start with the following:\\n49. \\n50. * Update your local repo\\n51. \\n52.       git pull https://github.com/mrdoob/three.js.git\\n53.       git push\\n54. \\n55. * Make a new branch from the dev branch\\n56. \\n57.       git checkout dev\\n58.       git branch [mychangesbranch]\\n59.       git checkout [mychangesbranch]\\n60. \\n61. * Add your changes to your commit.\\n62. * Push the changes to your forked repo.\\n63. * Open a Pull Request (PR)\\n64. \\n65. ## Important notes:\\n66. \\n67. * Don't include any build files in your commit.\\n68. * Not all new features will need a new example. Simpler features could be incorporated into an existing example. Bigger features may be asked to add an example demonstrating the feature.\\n69. * Making changes may require changes to the documentation. To update the docs in other languages, simply copy the English to begin with.\\n70. * It's good to also add an example and screenshot for it, for showing how it's used and for end-to-end testing.\\n71. * If you modify existing code, run relevant examples to check they didn't break and there wasn't performance regress.\\n72. * If you add some assets for the examples (models, textures, sounds, etc), make sure they have a proper license allowing for their use here, less restrictive the better. It is unlikely for large assets to be accepted.\\n73. * If some issue is relevant to the patch/feature, please mention it with a hash (e.g. #2774) in a commit message to get cross-reference in GitHub.\\n74. * If the end-to-end test failed and you are sure that all is correct, follow the instructions it outputs.\\n75. * Once done with a patch/feature do not add more commits to a feature branch.\\n76. * Create separate branches per patch or feature.\\n77. * If you make a PR but it is not actually ready to be pulled into the dev branch then please [convert it to a draft PR](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/changing-the-stage-of-a-pull-request#converting-a-pull-request-to-a-draft).\\n78. \\n79. This project is currently contributed mostly via everyone's spare time. Please keep that in mind as it may take some time for the appropriate feedback to get to you. If you are unsure about adding a new feature, it might be better to ask first to see whether other people think it's a good idea.\\n\\n\\n\\nNow generate a complete executable bash script that can successfully set up and configure the environment for this project, especially designed to run inside Docker containers. The bash script should:\\n1. Install the appropriate runtime and dependencies for the project's technology stack\\n2. Install all necessary system packages and tools\\n3. Set up the project directory structure and permissions\\n4. Configure the runtime environment properly\\n5. Set up necessary environment variables and configurations\\n6. Follow bash scripting best practices for error handling and security\\n\\nMake sure the bash script is self-contained and can set up the project environment from scratch in a Docker container environment.\\n\" additional_kwargs={} response_metadata={} id='76611cec-3a13-4792-893c-deefd4432b27'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='```bash\\n#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure script is run as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root (inside a Docker container, this is usually the default).\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y --no-install-recommends \\\\\\n        curl \\\\\\n        git \\\\\\n        build-essential \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-dev \\\\\\n        nodejs \\\\\\n        npm\\n    log \"System dependencies installed successfully.\"\\n}\\n\\n# Install Node.js and npm (if not already installed)\\ninstall_node() {\\n    log \"Ensuring Node.js and npm are installed...\"\\n    if ! command -v node &> /dev/null; then\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n        apt-get install -y nodejs\\n    fi\\n    log \"Node.js version: $(node -v)\"\\n    log \"npm version: $(npm -v)\"\\n}\\n\\n# Set up project directory\\nsetup_project_dir() {\\n    log \"Setting up project directory structure...\"\\n    PROJECT_DIR=\"/usr/src/threejs\"\\n    mkdir -p \"$PROJECT_DIR\"\\n    chmod -R 755 \"$PROJECT_DIR\"\\n    log \"Project directory set up at $PROJECT_DIR.\"\\n}\\n\\n# Clone the repository\\nclone_repo() {\\n    log \"Cloning the repository...\"\\n    if [ -d \"$PROJECT_DIR/.git\" ]; then\\n        warning \"Repository already cloned. Skipping clone step.\"\\n    else\\n        git clone --depth=1 https://github.com/mrdoob/three.js.git \"$PROJECT_DIR\"\\n    fi\\n    log \"Repository cloned successfully.\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    cd \"$PROJECT_DIR\"\\n    npm ci\\n    log \"Project dependencies installed successfully.\"\\n}\\n\\n# Set up environment variables\\nsetup_env() {\\n    log \"Setting up environment variables...\"\\n    export NODE_ENV=production\\n    export PROJECT_DIR=\"/usr/src/threejs\"\\n    log \"Environment variables set.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime() {\\n    log \"Configuring runtime environment...\"\\n    cd \"$PROJECT_DIR\"\\n    npm run build\\n    log \"Runtime environment configured successfully.\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_node\\n    setup_project_dir\\n    clone_repo\\n    install_project_deps\\n    setup_env\\n    configure_runtime\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the development server, run: cd $PROJECT_DIR && npm start\"\\n}\\n\\n# Run main function\\nmain \"$@\"\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 727, 'prompt_tokens': 2440, 'total_tokens': 3167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--598a5a47-8a4f-413d-acb9-86b0f9953133-0' usage_metadata={'input_tokens': 2440, 'output_tokens': 727, 'total_tokens': 3167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_file_messages": [
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_YDHLbj1iXwjfPKjSgPfwrCMb', 'function': {'arguments': '{\"relative_path\":\"prometheus_setup.sh\",\"content\":\"#!/bin/bash\\\\n\\\\n# Exit immediately if a command exits with a non-zero status\\\\nset -e\\\\n\\\\n# Colors for output\\\\nRED=\\'\\\\\\\\033[0;31m\\'\\\\nGREEN=\\'\\\\\\\\033[0;32m\\'\\\\nYELLOW=\\'\\\\\\\\033[1;33m\\'\\\\nNC=\\'\\\\\\\\033[0m\\' # No Color\\\\n\\\\n# Logging functions\\\\nlog() {\\\\n    echo -e \\\\\"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\\\\\"\\\\n}\\\\n\\\\nerror() {\\\\n    echo -e \\\\\"${RED}[ERROR] $1${NC}\\\\\" >&2\\\\n}\\\\n\\\\nwarning() {\\\\n    echo -e \\\\\"${YELLOW}[WARNING] $1${NC}\\\\\"\\\\n}\\\\n\\\\n# Ensure script is run as root (Docker containers typically run as root)\\\\nif [ \\\\\"$(id -u)\\\\\" -ne 0 ]; then\\\\n    error \\\\\"This script must be run as root (inside a Docker container, this is usually the default).\\\\\"\\\\n    exit 1\\\\nfi\\\\n\\\\n# Install system dependencies\\\\ninstall_system_deps() {\\\\n    log \\\\\"Installing system dependencies...\\\\\"\\\\n    apt-get update\\\\n    apt-get install -y --no-install-recommends \\\\\\\\\\\\n        curl \\\\\\\\\\\\n        git \\\\\\\\\\\\n        build-essential \\\\\\\\\\\\n        python3 \\\\\\\\\\\\n        python3-pip \\\\\\\\\\\\n        python3-dev \\\\\\\\\\\\n        nodejs \\\\\\\\\\\\n        npm\\\\n    log \\\\\"System dependencies installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Install Node.js and npm (if not already installed)\\\\ninstall_node() {\\\\n    log \\\\\"Ensuring Node.js and npm are installed...\\\\\"\\\\n    if ! command -v node &> /dev/null; then\\\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\\\n        apt-get install -y nodejs\\\\n    fi\\\\n    log \\\\\"Node.js version: $(node -v)\\\\\"\\\\n    log \\\\\"npm version: $(npm -v)\\\\\"\\\\n}\\\\n\\\\n# Set up project directory\\\\nsetup_project_dir() {\\\\n    log \\\\\"Setting up project directory structure...\\\\\"\\\\n    PROJECT_DIR=\\\\\"/usr/src/threejs\\\\\"\\\\n    mkdir -p \\\\\"$PROJECT_DIR\\\\\"\\\\n    chmod -R 755 \\\\\"$PROJECT_DIR\\\\\"\\\\n    log \\\\\"Project directory set up at $PROJECT_DIR.\\\\\"\\\\n}\\\\n\\\\n# Clone the repository\\\\nclone_repo() {\\\\n    log \\\\\"Cloning the repository...\\\\\"\\\\n    if [ -d \\\\\"$PROJECT_DIR/.git\\\\\" ]; then\\\\n        warning \\\\\"Repository already cloned. Skipping clone step.\\\\\"\\\\n    else\\\\n        git clone --depth=1 https://github.com/mrdoob/three.js.git \\\\\"$PROJECT_DIR\\\\\"\\\\n    fi\\\\n    log \\\\\"Repository cloned successfully.\\\\\"\\\\n}\\\\n\\\\n# Install project dependencies\\\\ninstall_project_deps() {\\\\n    log \\\\\"Installing project dependencies...\\\\\"\\\\n    cd \\\\\"$PROJECT_DIR\\\\\"\\\\n    npm ci\\\\n    log \\\\\"Project dependencies installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Set up environment variables\\\\nsetup_env() {\\\\n    log \\\\\"Setting up environment variables...\\\\\"\\\\n    export NODE_ENV=production\\\\n    export PROJECT_DIR=\\\\\"/usr/src/threejs\\\\\"\\\\n    log \\\\\"Environment variables set.\\\\\"\\\\n}\\\\n\\\\n# Configure runtime environment\\\\nconfigure_runtime() {\\\\n    log \\\\\"Configuring runtime environment...\\\\\"\\\\n    cd \\\\\"$PROJECT_DIR\\\\\"\\\\n    npm run build\\\\n    log \\\\\"Runtime environment configured successfully.\\\\\"\\\\n}\\\\n\\\\n# Main setup function\\\\nmain() {\\\\n    log \\\\\"Starting project environment setup...\\\\\"\\\\n\\\\n    install_system_deps\\\\n    install_node\\\\n    setup_project_dir\\\\n    clone_repo\\\\n    install_project_deps\\\\n    setup_env\\\\n    configure_runtime\\\\n\\\\n    log \\\\\"Project environment setup completed successfully!\\\\\"\\\\n    log \\\\\"To start the development server, run: cd $PROJECT_DIR && npm start\\\\\"\\\\n}\\\\n\\\\n# Run main function\\\\nmain \\\\\"$@\\\\\"\"}', 'name': 'create_file'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 865, 'prompt_tokens': 27852, 'total_tokens': 28717, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--cafe9c78-38af-47ad-872a-21960cb35140-0' tool_calls=[{'name': 'create_file', 'args': {'relative_path': 'prometheus_setup.sh', 'content': '#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure script is run as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root (inside a Docker container, this is usually the default).\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y --no-install-recommends \\\\\\n        curl \\\\\\n        git \\\\\\n        build-essential \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-dev \\\\\\n        nodejs \\\\\\n        npm\\n    log \"System dependencies installed successfully.\"\\n}\\n\\n# Install Node.js and npm (if not already installed)\\ninstall_node() {\\n    log \"Ensuring Node.js and npm are installed...\"\\n    if ! command -v node &> /dev/null; then\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n        apt-get install -y nodejs\\n    fi\\n    log \"Node.js version: $(node -v)\"\\n    log \"npm version: $(npm -v)\"\\n}\\n\\n# Set up project directory\\nsetup_project_dir() {\\n    log \"Setting up project directory structure...\"\\n    PROJECT_DIR=\"/usr/src/threejs\"\\n    mkdir -p \"$PROJECT_DIR\"\\n    chmod -R 755 \"$PROJECT_DIR\"\\n    log \"Project directory set up at $PROJECT_DIR.\"\\n}\\n\\n# Clone the repository\\nclone_repo() {\\n    log \"Cloning the repository...\"\\n    if [ -d \"$PROJECT_DIR/.git\" ]; then\\n        warning \"Repository already cloned. Skipping clone step.\"\\n    else\\n        git clone --depth=1 https://github.com/mrdoob/three.js.git \"$PROJECT_DIR\"\\n    fi\\n    log \"Repository cloned successfully.\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    cd \"$PROJECT_DIR\"\\n    npm ci\\n    log \"Project dependencies installed successfully.\"\\n}\\n\\n# Set up environment variables\\nsetup_env() {\\n    log \"Setting up environment variables...\"\\n    export NODE_ENV=production\\n    export PROJECT_DIR=\"/usr/src/threejs\"\\n    log \"Environment variables set.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime() {\\n    log \"Configuring runtime environment...\"\\n    cd \"$PROJECT_DIR\"\\n    npm run build\\n    log \"Runtime environment configured successfully.\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_node\\n    setup_project_dir\\n    clone_repo\\n    install_project_deps\\n    setup_env\\n    configure_runtime\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the development server, run: cd $PROJECT_DIR && npm start\"\\n}\\n\\n# Run main function\\nmain \"$@\"'}, 'id': 'call_YDHLbj1iXwjfPKjSgPfwrCMb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 27852, 'output_tokens': 865, 'total_tokens': 28717, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='The file prometheus_setup.sh has been created.' name='create_file' id='fedde4bb-0ca3-47ef-8c9f-66686c7394d1' tool_call_id='call_YDHLbj1iXwjfPKjSgPfwrCMb'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='The bash script has been saved at the root of the project with the relative path:\\n\\n`prometheus_setup.sh`' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 28734, 'total_tokens': 28759, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 28672}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--6158d370-e693-4744-a0c8-d197d6521cac-0' usage_metadata={'input_tokens': 28734, 'output_tokens': 25, 'total_tokens': 28759, 'input_token_details': {'audio': 0, 'cache_read': 28672}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_execute_messages": [],
            "env_implement_bash_content": "diff --git a/prometheus.Dockerfile b/prometheus.Dockerfile\nnew file mode 100644\nindex 0000000000..1616a72824\n--- /dev/null\n+++ b/prometheus.Dockerfile\n@@ -0,0 +1,22 @@\n+FROM ubuntu:24.04\n+\n+# Avoid timezone prompts during package installation\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV TZ=UTC\n+\n+# Set working directory\n+WORKDIR /app\n+\n+# Install essential build and development tools\n+RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     wget     python3     python3-pip     python3-dev     python3-venv     nodejs     npm     default-jdk     gcc     g++     gdb     postgresql-client     mysql-client     sqlite3     iputils-ping     vim     nano     zip     unzip     ca-certificates     gnupg     lsb-release\n+\n+RUN mkdir -p /etc/apt/keyrings     && curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg     && echo     \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu     $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n+\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+RUN apt-get clean\n+RUN rm -rf /var/lib/apt/lists/*\n+RUN ln -s /usr/bin/python3 /usr/bin/python\n+\n+# Copy project files\n+COPY . /app/\ndiff --git a/prometheus_setup.sh b/prometheus_setup.sh\nnew file mode 100644\nindex 0000000000..e71123cb6b\n--- /dev/null\n+++ b/prometheus_setup.sh\n@@ -0,0 +1,119 @@\n+#!/bin/bash\n+\n+# Exit immediately if a command exits with a non-zero status\n+set -e\n+\n+# Colors for output\n+RED='\\033[0;31m'\n+GREEN='\\033[0;32m'\n+YELLOW='\\033[1;33m'\n+NC='\\033[0m' # No Color\n+\n+# Logging functions\n+log() {\n+    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n+}\n+\n+error() {\n+    echo -e \"${RED}[ERROR] $1${NC}\" >&2\n+}\n+\n+warning() {\n+    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n+}\n+\n+# Ensure script is run as root (Docker containers typically run as root)\n+if [ \"$(id -u)\" -ne 0 ]; then\n+    error \"This script must be run as root (inside a Docker container, this is usually the default).\"\n+    exit 1\n+fi\n+\n+# Install system dependencies\n+install_system_deps() {\n+    log \"Installing system dependencies...\"\n+    apt-get update\n+    apt-get install -y --no-install-recommends \\\n+        curl \\\n+        git \\\n+        build-essential \\\n+        python3 \\\n+        python3-pip \\\n+        python3-dev \\\n+        nodejs \\\n+        npm\n+    log \"System dependencies installed successfully.\"\n+}\n+\n+# Install Node.js and npm (if not already installed)\n+install_node() {\n+    log \"Ensuring Node.js and npm are installed...\"\n+    if ! command -v node &> /dev/null; then\n+        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\n+        apt-get install -y nodejs\n+    fi\n+    log \"Node.js version: $(node -v)\"\n+    log \"npm version: $(npm -v)\"\n+}\n+\n+# Set up project directory\n+setup_project_dir() {\n+    log \"Setting up project directory structure...\"\n+    PROJECT_DIR=\"/usr/src/threejs\"\n+    mkdir -p \"$PROJECT_DIR\"\n+    chmod -R 755 \"$PROJECT_DIR\"\n+    log \"Project directory set up at $PROJECT_DIR.\"\n+}\n+\n+# Clone the repository\n+clone_repo() {\n+    log \"Cloning the repository...\"\n+    if [ -d \"$PROJECT_DIR/.git\" ]; then\n+        warning \"Repository already cloned. Skipping clone step.\"\n+    else\n+        git clone --depth=1 https://github.com/mrdoob/three.js.git \"$PROJECT_DIR\"\n+    fi\n+    log \"Repository cloned successfully.\"\n+}\n+\n+# Install project dependencies\n+install_project_deps() {\n+    log \"Installing project dependencies...\"\n+    cd \"$PROJECT_DIR\"\n+    npm ci\n+    log \"Project dependencies installed successfully.\"\n+}\n+\n+# Set up environment variables\n+setup_env() {\n+    log \"Setting up environment variables...\"\n+    export NODE_ENV=production\n+    export PROJECT_DIR=\"/usr/src/threejs\"\n+    log \"Environment variables set.\"\n+}\n+\n+# Configure runtime environment\n+configure_runtime() {\n+    log \"Configuring runtime environment...\"\n+    cd \"$PROJECT_DIR\"\n+    npm run build\n+    log \"Runtime environment configured successfully.\"\n+}\n+\n+# Main setup function\n+main() {\n+    log \"Starting project environment setup...\"\n+\n+    install_system_deps\n+    install_node\n+    setup_project_dir\n+    clone_repo\n+    install_project_deps\n+    setup_env\n+    configure_runtime\n+\n+    log \"Project environment setup completed successfully!\"\n+    log \"To start the development server, run: cd $PROJECT_DIR && npm start\"\n+}\n+\n+# Run main function\n+main \"$@\"\n\\ No newline at end of file\ndiff --git a/prometheus_testsuite_commands.txt b/prometheus_testsuite_commands.txt\nnew file mode 100644\nindex 0000000000..c9db53de7e\n--- /dev/null\n+++ b/prometheus_testsuite_commands.txt\n@@ -0,0 +1,4 @@\n+git clone --depth=1 https://github.com/mrdoob/three.js.git\n+npm run test-unit\n+npx servez -p 8080 --ssl\n+npm run test-e2e\n",
            "env_implement_bash_path": "prometheus_setup.sh"
        },
        "timestamp": "2025-10-18T10:00:40.627675"
    },
    "svelte": {
        "project_name": "svelte",
        "project_repo_url": "https://github.com/sveltejs/svelte",
        "success": true,
        "playground_path": "/tmp/tmpbobziwix/svelte",
        "container_info": null,
        "testsuite_states": {
            "testsuite_max_refined_query_loop": 4,
            "testsuite_context_provider_messages": [
                {
                    "type": "SystemMessage",
                    "content": "content=\"You are to discover ONE minimal, safe, and quick verification shell command from README/docs to confirm the environment/setup works (e.g., '<tool> --version', '<package> --help', 'make check', 'pytest -q'). Avoid destructive or long-running commands.\" additional_kwargs={} response_metadata={} id='df63aae7-298d-459e-8ef9-b66eb3b91505'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Find one quick verification command from README/docs for this repository.' additional_kwargs={} response_metadata={} id='0363e295-9c39-45a1-b0a4-7559d522a7e7'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_wf2iRzI0lgHocux2eAFzFRvY', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'find_file_node_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 5490, 'total_tokens': 5510, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ca21ebe5-3206-4cb7-8d8f-d432ff2c9235-0' tool_calls=[{'name': 'find_file_node_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_wf2iRzI0lgHocux2eAFzFRvY', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5490, 'output_tokens': 20, 'total_tokens': 5510, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content=\"Result 1:\\nFileNode: {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3453105}\\n\\n\\nResult 2:\\nFileNode: {'basename': 'README.md', 'relative_path': 'packages/svelte/README.md', 'node_id': 3453984}\\n\\n\\nResult 3:\\nFileNode: {'basename': 'README.md', 'relative_path': 'packages/svelte/tests/README.md', 'node_id': 3454218}\\n\\n\\nResult 4:\\nFileNode: {'basename': 'README.md', 'relative_path': '.changeset/README.md', 'node_id': 3569467}\" name='find_file_node_with_basename' id='8c2227bd-6a9a-49f9-8624-73dd6626ae0c' tool_call_id='call_wf2iRzI0lgHocux2eAFzFRvY' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3453105}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/svelte/README.md', 'node_id': 3453984}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/svelte/tests/README.md', 'node_id': 3454218}}, {'FileNode': {'basename': 'README.md', 'relative_path': '.changeset/README.md', 'node_id': 3569467}}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_yAv7uuE5ZLJOykteT4cpfChO', 'function': {'arguments': '{\"relative_path\":\"README.md\"}', 'name': 'preview_file_content_with_relative_path'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 5657, 'total_tokens': 5678, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5376}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--5ff03cbb-caf9-4f01-b250-6c073e317712-0' tool_calls=[{'name': 'preview_file_content_with_relative_path', 'args': {'relative_path': 'README.md'}, 'id': 'call_yAv7uuE5ZLJOykteT4cpfChO', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5657, 'output_tokens': 21, 'total_tokens': 5678, 'input_token_details': {'audio': 0, 'cache_read': 5376}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3453105}\\npreview: <a href=\"https://svelte.dev\">\\n\\t<picture>\\n\\t\\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/banner_dark.png\">\\n\\t\\t<img src=\"assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\\n\\t</picture>\\n</a>\\n\\n[![License](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\\n\\n## What is Svelte?\\n\\nSvelte is a new way to build web applications. It\\'s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\\n\\nLearn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\\n\\n## Supporting Svelte\\n\\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you\\'d like to support their efforts, please consider:\\n\\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\\n\\nFunds donated via Open Collective will be used for compensating expenses related to Svelte\\'s development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte\\'s development more directly.\\n\\n## Roadmap\\n\\nYou may view [our roadmap](https://svelte.dev/roadmap) if you\\'d like to see what we\\'re currently working on.\\n\\n## Contributing\\n\\nPlease see the [Contributing Guide](CONTRIBUTING.md) and the [`svelte`](packages/svelte) package for information on contributing to Svelte.\\n\\n## Is svelte.dev down?\\n\\nProbably not, but it\\'s possible. If you can\\'t seem to access any `.dev` sites, check out [this SuperUser question and answer](https://superuser.com/q/1413402).\\n\\n## License\\n\\n[MIT](LICENSE.md)' name='preview_file_content_with_relative_path' id='52db3b37-1745-4200-a1ab-22f5a4f7c28a' tool_call_id='call_yAv7uuE5ZLJOykteT4cpfChO' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3453105}, 'preview': '<a href=\"https://svelte.dev\">\\n\\t<picture>\\n\\t\\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/banner_dark.png\">\\n\\t\\t<img src=\"assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\\n\\t</picture>\\n</a>\\n\\n[![License](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\\n\\n## What is Svelte?\\n\\nSvelte is a new way to build web applications. It\\'s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\\n\\nLearn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\\n\\n## Supporting Svelte\\n\\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you\\'d like to support their efforts, please consider:\\n\\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\\n\\nFunds donated via Open Collective will be used for compensating expenses related to Svelte\\'s development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte\\'s development more directly.\\n\\n## Roadmap\\n\\nYou may view [our roadmap](https://svelte.dev/roadmap) if you\\'d like to see what we\\'re currently working on.\\n\\n## Contributing\\n\\nPlease see the [Contributing Guide](CONTRIBUTING.md) and the [`svelte`](packages/svelte) package for information on contributing to Svelte.\\n\\n## Is svelte.dev down?\\n\\nProbably not, but it\\'s possible. If you can\\'t seem to access any `.dev` sites, check out [this SuperUser question and answer](https://superuser.com/q/1413402).\\n\\n## License\\n\\n[MIT](LICENSE.md)'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_SSK4WP3yPo8l6VIcZjSDozic', 'function': {'arguments': '{\"relative_path\":\"packages/svelte/README.md\"}', 'name': 'preview_file_content_with_relative_path'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 6142, 'total_tokens': 6167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5632}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b7542a62-abc4-419f-9e90-fee9e743f0a9-0' tool_calls=[{'name': 'preview_file_content_with_relative_path', 'args': {'relative_path': 'packages/svelte/README.md'}, 'id': 'call_SSK4WP3yPo8l6VIcZjSDozic', 'type': 'tool_call'}] usage_metadata={'input_tokens': 6142, 'output_tokens': 25, 'total_tokens': 6167, 'input_token_details': {'audio': 0, 'cache_read': 5632}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/svelte/README.md\\', \\'node_id\\': 3453984}\\npreview: <a href=\"https://svelte.dev\">\\n\\t<picture>\\n\\t\\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"../../assets/banner_dark.png\">\\n\\t\\t<img src=\"../../assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\\n\\t</picture>\\n</a>\\n\\n[![npm version](https://img.shields.io/npm/v/svelte.svg)](https://www.npmjs.com/package/svelte) [![license](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\\n\\n## What is Svelte?\\n\\nSvelte is a new way to build web applications. It\\'s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\\n\\nLearn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\\n\\n## Getting started\\n\\nYou can play around with Svelte in the [tutorial](https://svelte.dev/tutorial), [examples](https://svelte.dev/examples), and [REPL](https://svelte.dev/repl).\\n\\nWhen you\\'re ready to build a full-fledge application, we recommend using [SvelteKit](https://svelte.dev/docs/kit):\\n\\n```sh\\nnpx sv create my-app\\ncd my-app\\nnpm install\\nnpm run dev\\n```\\n\\nSee [the SvelteKit documentation](https://svelte.dev/docs/kit) to learn more.\\n\\n## Changelog\\n\\n[The Changelog for this package is available on GitHub](https://github.com/sveltejs/svelte/blob/main/packages/svelte/CHANGELOG.md).\\n\\n## Supporting Svelte\\n\\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you\\'d like to support their efforts, please consider:\\n\\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\\n\\nFunds donated via Open Collective will be used for compensating expenses related to Svelte\\'s development.' name='preview_file_content_with_relative_path' id='35256caf-57da-4287-81f7-3bf944a893ad' tool_call_id='call_SSK4WP3yPo8l6VIcZjSDozic' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'packages/svelte/README.md', 'node_id': 3453984}, 'preview': '<a href=\"https://svelte.dev\">\\n\\t<picture>\\n\\t\\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"../../assets/banner_dark.png\">\\n\\t\\t<img src=\"../../assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\\n\\t</picture>\\n</a>\\n\\n[![npm version](https://img.shields.io/npm/v/svelte.svg)](https://www.npmjs.com/package/svelte) [![license](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\\n\\n## What is Svelte?\\n\\nSvelte is a new way to build web applications. It\\'s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\\n\\nLearn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\\n\\n## Getting started\\n\\nYou can play around with Svelte in the [tutorial](https://svelte.dev/tutorial), [examples](https://svelte.dev/examples), and [REPL](https://svelte.dev/repl).\\n\\nWhen you\\'re ready to build a full-fledge application, we recommend using [SvelteKit](https://svelte.dev/docs/kit):\\n\\n```sh\\nnpx sv create my-app\\ncd my-app\\nnpm install\\nnpm run dev\\n```\\n\\nSee [the SvelteKit documentation](https://svelte.dev/docs/kit) to learn more.\\n\\n## Changelog\\n\\n[The Changelog for this package is available on GitHub](https://github.com/sveltejs/svelte/blob/main/packages/svelte/CHANGELOG.md).\\n\\n## Supporting Svelte\\n\\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you\\'d like to support their efforts, please consider:\\n\\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\\n\\nFunds donated via Open Collective will be used for compensating expenses related to Svelte\\'s development.'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content=\"Search the main README.md and the 'Getting Started' section in the documentation for a quick verification command.\" additional_kwargs={} response_metadata={} id='04c80b77-dfb9-42ef-8872-9a215aab565d'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "testsuite_refined_query": "Search the main README.md and the 'Getting Started' section in the documentation for a quick verification command.",
            "testsuite_command": [
                "npx sv --version"
            ]
        },
        "env_states": {
            "max_refined_query_loop": 3,
            "env_implement_file_context_query": "OBJECTIVE: Find the most relevant environment configuration files that can help generate an accurate Dockerfile for this project,\nincluding Dockerfiles, dependency files, build configurations, and environment setup files.\n\n<reasoning>\n1. Analyze project characteristics:\n   - Programming language and framework\n   - Dependency management files\n   - Build system and tools\n   - Runtime requirements\n   - Environment configurations\n\n2. Search requirements:\n   - Existing Dockerfiles or containerization files\n   - Dependency files (requirements.txt, package.json, pom.xml, etc.)\n   - Build configuration files (Makefile, CMakeLists.txt, etc.)\n   - Environment configuration files (.env, config files)\n   - Setup and installation scripts\n\n3. Focus areas:\n   - Docker-related files (Dockerfile, docker-compose.yml, .dockerignore)\n   - Package management files (requirements.txt, package.json, go.mod, Cargo.toml, etc.)\n   - Build system files (Makefile, CMakeLists.txt, build.gradle, etc.)\n   - Environment configuration (.env, config.json, application.properties, etc.)\n   - Setup documentation (README.md, INSTALL.md, SETUP.md)\n   - CI/CD configuration files\n</reasoning>\n\nREQUIREMENTS:\n- Return the most relevant environment configuration files for Dockerfile generation\n- Must include complete file content with exact file paths and line numbers\n- Must include dependency files, build configurations, and environment setups\n- Must include any existing Docker-related files\n- Must include setup documentation and installation instructions\n\n<examples>\n<example id=\"python-web-app\">\n<project_context>\nPython Flask web application with requirements.txt\n</project_context>\n\n<ideal_files>\n# File: requirements.txt\nFlask==2.3.3\ngunicorn==21.2.0\npsycopg2-binary==2.9.7\nredis==4.6.0\n\n# File: app.py\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    return 'Hello World!'\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n\n# File: README.md\n## Installation\npip install -r requirements.txt\npython app.py\n</ideal_files>\n</example>\n\n<example id=\"nodejs-api\">\n<project_context>\nNode.js Express API with package.json\n</project_context>\n\n<ideal_files>\n# File: package.json\n{\n  \"name\": \"my-api\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^7.5.0\"\n  }\n}\n\n# File: server.js\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\napp.get('/', (req, res) => {\n  res.json({ message: 'API is running' });\n});\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});\n</ideal_files>\n</example>\n\nSearch priority:\n1. Existing Dockerfiles or containerization files\n2. Dependency management files (requirements.txt, package.json, etc.)\n3. Build configuration files (Makefile, CMakeLists.txt, etc.)\n4. Environment configuration files (.env, config files)\n5. Setup documentation and installation instructions\n\nFind the most relevant environment configuration files with complete context for Dockerfile generation.\n",
            "env_implement_file_context": [
                {
                    "type": "Context",
                    "content": "File: pnpm-lock.yaml\nLine number range: 1 - 1000\nContent:\n1. lockfileVersion: '9.0'\n2. \n3. settings:\n4.   autoInstallPeers: true\n5.   excludeLinksFromLockfile: false\n6. \n7. importers:\n8. \n9.   .:\n10.     devDependencies:\n11.       '@changesets/cli':\n12.         specifier: ^2.29.7\n13.         version: 2.29.7(@types/node@20.19.17)\n14.       '@sveltejs/eslint-config':\n15.         specifier: ^8.3.3\n16.         version: 8.3.3(@stylistic/eslint-plugin-js@1.8.0(eslint@9.9.1))(eslint-config-prettier@9.1.0(eslint@9.9.1))(eslint-plugin-n@17.16.1(eslint@9.9.1)(typescript@5.5.4))(eslint-plugin-svelte@3.11.0(eslint@9.9.1)(svelte@packages+svelte))(eslint@9.9.1)(typescript-eslint@8.26.0(eslint@9.9.1)(typescript@5.5.4))(typescript@5.5.4)\n17.       '@svitejs/changesets-changelog-github-compact':\n18.         specifier: ^1.1.0\n19.         version: 1.1.0\n20.       '@types/node':\n21.         specifier: ^20.11.5\n22.         version: 20.19.17\n23.       '@types/picomatch':\n24.         specifier: ^4.0.2\n25.         version: 4.0.2\n26.       '@vitest/coverage-v8':\n27.         specifier: ^2.1.9\n28.         version: 2.1.9(vitest@2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\n29.       eslint:\n30.         specifier: ^9.9.1\n31.         version: 9.9.1\n32.       eslint-plugin-lube:\n33.         specifier: ^0.4.3\n34.         version: 0.4.3\n35.       eslint-plugin-svelte:\n36.         specifier: ^3.11.0\n37.         version: 3.11.0(eslint@9.9.1)(svelte@packages+svelte)\n38.       jsdom:\n39.         specifier: 25.0.1\n40.         version: 25.0.1\n41.       playwright:\n42.         specifier: ^1.46.1\n43.         version: 1.46.1\n44.       prettier:\n45.         specifier: ^3.2.4\n46.         version: 3.2.4\n47.       prettier-plugin-svelte:\n48.         specifier: ^3.4.0\n49.         version: 3.4.0(prettier@3.2.4)(svelte@packages+svelte)\n50.       svelte:\n51.         specifier: workspace:^\n52.         version: link:packages/svelte\n53.       typescript:\n54.         specifier: ^5.5.4\n55.         version: 5.5.4\n56.       typescript-eslint:\n57.         specifier: ^8.24.0\n58.         version: 8.26.0(eslint@9.9.1)(typescript@5.5.4)\n59.       v8-natives:\n60.         specifier: ^1.2.5\n61.         version: 1.2.5\n62.       vitest:\n63.         specifier: ^2.1.9\n64.         version: 2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\n65. \n66.   packages/svelte:\n67.     dependencies:\n68.       '@jridgewell/remapping':\n69.         specifier: ^2.3.4\n70.         version: 2.3.4\n71.       '@jridgewell/sourcemap-codec':\n72.         specifier: ^1.5.0\n73.         version: 1.5.0\n74.       '@sveltejs/acorn-typescript':\n75.         specifier: ^1.0.5\n76.         version: 1.0.5(acorn@8.15.0)\n77.       '@types/estree':\n78.         specifier: ^1.0.5\n79.         version: 1.0.8\n80.       acorn:\n81.         specifier: ^8.12.1\n82.         version: 8.15.0\n83.       aria-query:\n84.         specifier: ^5.3.1\n85.         version: 5.3.1\n86.       axobject-query:\n87.         specifier: ^4.1.0\n88.         version: 4.1.0\n89.       clsx:\n90.         specifier: ^2.1.1\n91.         version: 2.1.1\n92.       esm-env:\n93.         specifier: ^1.2.1\n94.         version: 1.2.1\n95.       esrap:\n96.         specifier: ^2.1.0\n97.         version: 2.1.0\n98.       is-reference:\n99.         specifier: ^3.0.3\n100.         version: 3.0.3\n101.       locate-character:\n102.         specifier: ^3.0.0\n103.         version: 3.0.0\n104.       magic-string:\n105.         specifier: ^0.30.11\n106.         version: 0.30.17\n107.       zimmerframe:\n108.         specifier: ^1.1.2\n109.         version: 1.1.2\n110.     devDependencies:\n111.       '@jridgewell/trace-mapping':\n112.         specifier: ^0.3.25\n113.         version: 0.3.31\n114.       '@playwright/test':\n115.         specifier: ^1.46.1\n116.         version: 1.46.1\n117.       '@rollup/plugin-commonjs':\n118.         specifier: ^28.0.1\n119.         version: 28.0.1(rollup@4.50.1)\n120.       '@rollup/plugin-node-resolve':\n121.         specifier: ^15.3.0\n122.         version: 15.3.0(rollup@4.50.1)\n123.       '@rollup/plugin-terser':\n124.         specifier: ^0.4.4\n125.         version: 0.4.4(rollup@4.50.1)\n126.       '@rollup/plugin-virtual':\n127.         specifier: ^3.0.2\n128.         version: 3.0.2(rollup@4.50.1)\n129.       '@types/aria-query':\n130.         specifier: ^5.0.4\n131.         version: 5.0.4\n132.       '@types/node':\n133.         specifier: ^20.11.5\n134.         version: 20.19.17\n135.       dts-buddy:\n136.         specifier: ^0.5.5\n137.         version: 0.5.5(typescript@5.5.4)\n138.       esbuild:\n139.         specifier: ^0.25.10\n140.         version: 0.25.10\n141.       rollup:\n142.         specifier: ^4.22.4\n143.         version: 4.50.1\n144.       source-map:\n145.         specifier: ^0.7.4\n146.         version: 0.7.4\n147.       tinyglobby:\n148.         specifier: ^0.2.12\n149.         version: 0.2.15\n150.       typescript:\n151.         specifier: ^5.5.4\n152.         version: 5.5.4\n153.       vitest:\n154.         specifier: ^2.1.9\n155.         version: 2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\n156. \n157.   playgrounds/sandbox:\n158.     devDependencies:\n159.       '@sveltejs/vite-plugin-svelte':\n160.         specifier: ^6.2.0\n161.         version: 6.2.0(svelte@packages+svelte)(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\n162.       '@types/node':\n163.         specifier: ^24.5.2\n164.         version: 24.5.2\n165.       polka:\n166.         specifier: ^1.0.0-next.25\n167.         version: 1.0.0-next.25\n168.       svelte:\n169.         specifier: workspace:*\n170.         version: link:../../packages/svelte\n171.       tinyglobby:\n172.         specifier: ^0.2.12\n173.         version: 0.2.15\n174.       vite:\n175.         specifier: ^7.1.5\n176.         version: 7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\n177.       vite-plugin-devtools-json:\n178.         specifier: ^1.0.0\n179.         version: 1.0.0(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\n180.       vite-plugin-inspect:\n181.         specifier: ^11.3.3\n182.         version: 11.3.3(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\n183. \n184. packages:\n185. \n186.   '@aashutoshrathi/word-wrap@1.2.6':\n187.     resolution: {integrity: sha512-1Yjs2SvM8TflER/OD3cOjhWWOZb58A2t7wpE2S9XfBYTiIl+XFhQG2bjy4Pu1I+EAlCNUzRDYDdFwFYUKvXcIA==}\n188.     engines: {node: '>=0.10.0'}\n189. \n190.   '@ampproject/remapping@2.3.0':\n191.     resolution: {integrity: sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==}\n192.     engines: {node: '>=6.0.0'}\n193. \n194.   '@babel/helper-string-parser@7.24.8':\n195.     resolution: {integrity: sha512-pO9KhhRcuUyGnJWwyEgnRJTSIZHiT+vMD0kPeD+so0l7mxkMT19g3pjY9GTnHySck/hDzq+dtW/4VgnMkippsQ==}\n196.     engines: {node: '>=6.9.0'}\n197. \n198.   '@babel/helper-validator-identifier@7.24.7':\n199.     resolution: {integrity: sha512-rR+PBcQ1SMQDDyF6X0wxtG8QyLCgUB0eRAGguqRLfkCA87l7yAP7ehq8SNj96OOGTO8OBV70KhuFYcIkHXOg0w==}\n200.     engines: {node: '>=6.9.0'}\n201. \n202.   '@babel/parser@7.25.4':\n203.     resolution: {integrity: sha512-nq+eWrOgdtu3jG5Os4TQP3x3cLA8hR8TvJNjD8vnPa20WGycimcparWnLK4jJhElTK6SDyuJo1weMKO/5LpmLA==}\n204.     engines: {node: '>=6.0.0'}\n205.     hasBin: true\n206. \n207.   '@babel/runtime@7.23.8':\n208.     resolution: {integrity: sha512-Y7KbAP984rn1VGMbGqKmBLio9V7y5Je9GvU4rQPCPinCyNfUcToxIXl06d59URp/F3LwinvODxab5N/G6qggkw==}\n209.     engines: {node: '>=6.9.0'}\n210. \n211.   '@babel/types@7.25.4':\n212.     resolution: {integrity: sha512-zQ1ijeeCXVEh+aNL0RlmkPkG8HUiDcU2pzQQFjtbntgAczRASFzj4H+6+bV+dy1ntKR14I/DypeuRG1uma98iQ==}\n213.     engines: {node: '>=6.9.0'}\n214. \n215.   '@bcoe/v8-coverage@0.2.3':\n216.     resolution: {integrity: sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==}\n217. \n218.   '@changesets/apply-release-plan@7.0.13':\n219.     resolution: {integrity: sha512-BIW7bofD2yAWoE8H4V40FikC+1nNFEKBisMECccS16W1rt6qqhNTBDmIw5HaqmMgtLNz9e7oiALiEUuKrQ4oHg==}\n220. \n221.   '@changesets/assemble-release-plan@6.0.9':\n222.     resolution: {integrity: sha512-tPgeeqCHIwNo8sypKlS3gOPmsS3wP0zHt67JDuL20P4QcXiw/O4Hl7oXiuLnP9yg+rXLQ2sScdV1Kkzde61iSQ==}\n223. \n224.   '@changesets/changelog-git@0.2.1':\n225.     resolution: {integrity: sha512-x/xEleCFLH28c3bQeQIyeZf8lFXyDFVn1SgcBiR2Tw/r4IAWlk1fzxCEZ6NxQAjF2Nwtczoen3OA2qR+UawQ8Q==}\n226. \n227.   '@changesets/cli@2.29.7':\n228.     resolution: {integrity: sha512-R7RqWoaksyyKXbKXBTbT4REdy22yH81mcFK6sWtqSanxUCbUi9Uf+6aqxZtDQouIqPdem2W56CdxXgsxdq7FLQ==}\n229.     hasBin: true\n230. \n231.   '@changesets/config@3.1.1':\n232.     resolution: {integrity: sha512-bd+3Ap2TKXxljCggI0mKPfzCQKeV/TU4yO2h2C6vAihIo8tzseAn2e7klSuiyYYXvgu53zMN1OeYMIQkaQoWnA==}\n233. \n234.   '@changesets/errors@0.2.0':\n235.     resolution: {integrity: sha512-6BLOQUscTpZeGljvyQXlWOItQyU71kCdGz7Pi8H8zdw6BI0g3m43iL4xKUVPWtG+qrrL9DTjpdn8eYuCQSRpow==}\n236. \n237.   '@changesets/get-dependents-graph@2.1.3':\n238.     resolution: {integrity: sha512-gphr+v0mv2I3Oxt19VdWRRUxq3sseyUpX9DaHpTUmLj92Y10AGy+XOtV+kbM6L/fDcpx7/ISDFK6T8A/P3lOdQ==}\n239. \n240.   '@changesets/get-github-info@0.5.2':\n241.     resolution: {integrity: sha512-JppheLu7S114aEs157fOZDjFqUDpm7eHdq5E8SSR0gUBTEK0cNSHsrSR5a66xs0z3RWuo46QvA3vawp8BxDHvg==}\n242. \n243.   '@changesets/get-release-plan@4.0.13':\n244.     resolution: {integrity: sha512-DWG1pus72FcNeXkM12tx+xtExyH/c9I1z+2aXlObH3i9YA7+WZEVaiHzHl03thpvAgWTRaH64MpfHxozfF7Dvg==}\n245. \n246.   '@changesets/get-version-range-type@0.4.0':\n247.     resolution: {integrity: sha512-hwawtob9DryoGTpixy1D3ZXbGgJu1Rhr+ySH2PvTLHvkZuQ7sRT4oQwMh0hbqZH1weAooedEjRsbrWcGLCeyVQ==}\n248. \n249.   '@changesets/git@3.0.4':\n250.     resolution: {integrity: sha512-BXANzRFkX+XcC1q/d27NKvlJ1yf7PSAgi8JG6dt8EfbHFHi4neau7mufcSca5zRhwOL8j9s6EqsxmT+s+/E6Sw==}\n251. \n252.   '@changesets/logger@0.1.1':\n253.     resolution: {integrity: sha512-OQtR36ZlnuTxKqoW4Sv6x5YIhOmClRd5pWsjZsddYxpWs517R0HkyiefQPIytCVh4ZcC5x9XaG8KTdd5iRQUfg==}\n254. \n255.   '@changesets/parse@0.4.1':\n256.     resolution: {integrity: sha512-iwksMs5Bf/wUItfcg+OXrEpravm5rEd9Bf4oyIPL4kVTmJQ7PNDSd6MDYkpSJR1pn7tz/k8Zf2DhTCqX08Ou+Q==}\n257. \n258.   '@changesets/pre@2.0.2':\n259.     resolution: {integrity: sha512-HaL/gEyFVvkf9KFg6484wR9s0qjAXlZ8qWPDkTyKF6+zqjBe/I2mygg3MbpZ++hdi0ToqNUF8cjj7fBy0dg8Ug==}\n260. \n261.   '@changesets/read@0.6.5':\n262.     resolution: {integrity: sha512-UPzNGhsSjHD3Veb0xO/MwvasGe8eMyNrR/sT9gR8Q3DhOQZirgKhhXv/8hVsI0QpPjR004Z9iFxoJU6in3uGMg==}\n263. \n264.   '@changesets/should-skip-package@0.1.2':\n265.     resolution: {integrity: sha512-qAK/WrqWLNCP22UDdBTMPH5f41elVDlsNyat180A33dWxuUDyNpg6fPi/FyTZwRriVjg0L8gnjJn2F9XAoF0qw==}\n266. \n267.   '@changesets/types@4.1.0':\n268.     resolution: {integrity: sha512-LDQvVDv5Kb50ny2s25Fhm3d9QSZimsoUGBsUioj6MC3qbMUCuC8GPIvk/M6IvXx3lYhAs0lwWUQLb+VIEUCECw==}\n269. \n270.   '@changesets/types@6.1.0':\n271.     resolution: {integrity: sha512-rKQcJ+o1nKNgeoYRHKOS07tAMNd3YSN0uHaJOZYjBAgxfV7TUE7JE+z4BzZdQwb5hKaYbayKN5KrYV7ODb2rAA==}\n272. \n273.   '@changesets/write@0.4.0':\n274.     resolution: {integrity: sha512-CdTLvIOPiCNuH71pyDu3rA+Q0n65cmAbXnwWH84rKGiFumFzkmHNT8KHTMEchcxN+Kl8I54xGUhJ7l3E7X396Q==}\n275. \n276.   '@esbuild/aix-ppc64@0.21.5':\n277.     resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}\n278.     engines: {node: '>=12'}\n279.     cpu: [ppc64]\n280.     os: [aix]\n281. \n282.   '@esbuild/aix-ppc64@0.25.10':\n283.     resolution: {integrity: sha512-0NFWnA+7l41irNuaSVlLfgNT12caWJVLzp5eAVhZ0z1qpxbockccEt3s+149rE64VUI3Ml2zt8Nv5JVc4QXTsw==}\n284.     engines: {node: '>=18'}\n285.     cpu: [ppc64]\n286.     os: [aix]\n287. \n288.   '@esbuild/android-arm64@0.21.5':\n289.     resolution: {integrity: sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==}\n290.     engines: {node: '>=12'}\n291.     cpu: [arm64]\n292.     os: [android]\n293. \n294.   '@esbuild/android-arm64@0.25.10':\n295.     resolution: {integrity: sha512-LSQa7eDahypv/VO6WKohZGPSJDq5OVOo3UoFR1E4t4Gj1W7zEQMUhI+lo81H+DtB+kP+tDgBp+M4oNCwp6kffg==}\n296.     engines: {node: '>=18'}\n297.     cpu: [arm64]\n298.     os: [android]\n299. \n300.   '@esbuild/android-arm@0.21.5':\n301.     resolution: {integrity: sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==}\n302.     engines: {node: '>=12'}\n303.     cpu: [arm]\n304.     os: [android]\n305. \n306.   '@esbuild/android-arm@0.25.10':\n307.     resolution: {integrity: sha512-dQAxF1dW1C3zpeCDc5KqIYuZ1tgAdRXNoZP7vkBIRtKZPYe2xVr/d3SkirklCHudW1B45tGiUlz2pUWDfbDD4w==}\n308.     engines: {node: '>=18'}\n309.     cpu: [arm]\n310.     os: [android]\n311. \n312.   '@esbuild/android-x64@0.21.5':\n313.     resolution: {integrity: sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==}\n314.     engines: {node: '>=12'}\n315.     cpu: [x64]\n316.     os: [android]\n317. \n318.   '@esbuild/android-x64@0.25.10':\n319.     resolution: {integrity: sha512-MiC9CWdPrfhibcXwr39p9ha1x0lZJ9KaVfvzA0Wxwz9ETX4v5CHfF09bx935nHlhi+MxhA63dKRRQLiVgSUtEg==}\n320.     engines: {node: '>=18'}\n321.     cpu: [x64]\n322.     os: [android]\n323. \n324.   '@esbuild/darwin-arm64@0.21.5':\n325.     resolution: {integrity: sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==}\n326.     engines: {node: '>=12'}\n327.     cpu: [arm64]\n328.     os: [darwin]\n329. \n330.   '@esbuild/darwin-arm64@0.25.10':\n331.     resolution: {integrity: sha512-JC74bdXcQEpW9KkV326WpZZjLguSZ3DfS8wrrvPMHgQOIEIG/sPXEN/V8IssoJhbefLRcRqw6RQH2NnpdprtMA==}\n332.     engines: {node: '>=18'}\n333.     cpu: [arm64]\n334.     os: [darwin]\n335. \n336.   '@esbuild/darwin-x64@0.21.5':\n337.     resolution: {integrity: sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==}\n338.     engines: {node: '>=12'}\n339.     cpu: [x64]\n340.     os: [darwin]\n341. \n342.   '@esbuild/darwin-x64@0.25.10':\n343.     resolution: {integrity: sha512-tguWg1olF6DGqzws97pKZ8G2L7Ig1vjDmGTwcTuYHbuU6TTjJe5FXbgs5C1BBzHbJ2bo1m3WkQDbWO2PvamRcg==}\n344.     engines: {node: '>=18'}\n345.     cpu: [x64]\n346.     os: [darwin]\n347. \n348.   '@esbuild/freebsd-arm64@0.21.5':\n349.     resolution: {integrity: sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==}\n350.     engines: {node: '>=12'}\n351.     cpu: [arm64]\n352.     os: [freebsd]\n353. \n354.   '@esbuild/freebsd-arm64@0.25.10':\n355.     resolution: {integrity: sha512-3ZioSQSg1HT2N05YxeJWYR+Libe3bREVSdWhEEgExWaDtyFbbXWb49QgPvFH8u03vUPX10JhJPcz7s9t9+boWg==}\n356.     engines: {node: '>=18'}\n357.     cpu: [arm64]\n358.     os: [freebsd]\n359. \n360.   '@esbuild/freebsd-x64@0.21.5':\n361.     resolution: {integrity: sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==}\n362.     engines: {node: '>=12'}\n363.     cpu: [x64]\n364.     os: [freebsd]\n365. \n366.   '@esbuild/freebsd-x64@0.25.10':\n367.     resolution: {integrity: sha512-LLgJfHJk014Aa4anGDbh8bmI5Lk+QidDmGzuC2D+vP7mv/GeSN+H39zOf7pN5N8p059FcOfs2bVlrRr4SK9WxA==}\n368.     engines: {node: '>=18'}\n369.     cpu: [x64]\n370.     os: [freebsd]\n371. \n372.   '@esbuild/linux-arm64@0.21.5':\n373.     resolution: {integrity: sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==}\n374.     engines: {node: '>=12'}\n375.     cpu: [arm64]\n376.     os: [linux]\n377. \n378.   '@esbuild/linux-arm64@0.25.10':\n379.     resolution: {integrity: sha512-5luJWN6YKBsawd5f9i4+c+geYiVEw20FVW5x0v1kEMWNq8UctFjDiMATBxLvmmHA4bf7F6hTRaJgtghFr9iziQ==}\n380.     engines: {node: '>=18'}\n381.     cpu: [arm64]\n382.     os: [linux]\n383. \n384.   '@esbuild/linux-arm@0.21.5':\n385.     resolution: {integrity: sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==}\n386.     engines: {node: '>=12'}\n387.     cpu: [arm]\n388.     os: [linux]\n389. \n390.   '@esbuild/linux-arm@0.25.10':\n391.     resolution: {integrity: sha512-oR31GtBTFYCqEBALI9r6WxoU/ZofZl962pouZRTEYECvNF/dtXKku8YXcJkhgK/beU+zedXfIzHijSRapJY3vg==}\n392.     engines: {node: '>=18'}\n393.     cpu: [arm]\n394.     os: [linux]\n395. \n396.   '@esbuild/linux-ia32@0.21.5':\n397.     resolution: {integrity: sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==}\n398.     engines: {node: '>=12'}\n399.     cpu: [ia32]\n400.     os: [linux]\n401. \n402.   '@esbuild/linux-ia32@0.25.10':\n403.     resolution: {integrity: sha512-NrSCx2Kim3EnnWgS4Txn0QGt0Xipoumb6z6sUtl5bOEZIVKhzfyp/Lyw4C1DIYvzeW/5mWYPBFJU3a/8Yr75DQ==}\n404.     engines: {node: '>=18'}\n405.     cpu: [ia32]\n406.     os: [linux]\n407. \n408.   '@esbuild/linux-loong64@0.21.5':\n409.     resolution: {integrity: sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==}\n410.     engines: {node: '>=12'}\n411.     cpu: [loong64]\n412.     os: [linux]\n413. \n414.   '@esbuild/linux-loong64@0.25.10':\n415.     resolution: {integrity: sha512-xoSphrd4AZda8+rUDDfD9J6FUMjrkTz8itpTITM4/xgerAZZcFW7Dv+sun7333IfKxGG8gAq+3NbfEMJfiY+Eg==}\n416.     engines: {node: '>=18'}\n417.     cpu: [loong64]\n418.     os: [linux]\n419. \n420.   '@esbuild/linux-mips64el@0.21.5':\n421.     resolution: {integrity: sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==}\n422.     engines: {node: '>=12'}\n423.     cpu: [mips64el]\n424.     os: [linux]\n425. \n426.   '@esbuild/linux-mips64el@0.25.10':\n427.     resolution: {integrity: sha512-ab6eiuCwoMmYDyTnyptoKkVS3k8fy/1Uvq7Dj5czXI6DF2GqD2ToInBI0SHOp5/X1BdZ26RKc5+qjQNGRBelRA==}\n428.     engines: {node: '>=18'}\n429.     cpu: [mips64el]\n430.     os: [linux]\n431. \n432.   '@esbuild/linux-ppc64@0.21.5':\n433.     resolution: {integrity: sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==}\n434.     engines: {node: '>=12'}\n435.     cpu: [ppc64]\n436.     os: [linux]\n437. \n438.   '@esbuild/linux-ppc64@0.25.10':\n439.     resolution: {integrity: sha512-NLinzzOgZQsGpsTkEbdJTCanwA5/wozN9dSgEl12haXJBzMTpssebuXR42bthOF3z7zXFWH1AmvWunUCkBE4EA==}\n440.     engines: {node: '>=18'}\n441.     cpu: [ppc64]\n442.     os: [linux]\n443. \n444.   '@esbuild/linux-riscv64@0.21.5':\n445.     resolution: {integrity: sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==}\n446.     engines: {node: '>=12'}\n447.     cpu: [riscv64]\n448.     os: [linux]\n449. \n450.   '@esbuild/linux-riscv64@0.25.10':\n451.     resolution: {integrity: sha512-FE557XdZDrtX8NMIeA8LBJX3dC2M8VGXwfrQWU7LB5SLOajfJIxmSdyL/gU1m64Zs9CBKvm4UAuBp5aJ8OgnrA==}\n452.     engines: {node: '>=18'}\n453.     cpu: [riscv64]\n454.     os: [linux]\n455. \n456.   '@esbuild/linux-s390x@0.21.5':\n457.     resolution: {integrity: sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==}\n458.     engines: {node: '>=12'}\n459.     cpu: [s390x]\n460.     os: [linux]\n461. \n462.   '@esbuild/linux-s390x@0.25.10':\n463.     resolution: {integrity: sha512-3BBSbgzuB9ajLoVZk0mGu+EHlBwkusRmeNYdqmznmMc9zGASFjSsxgkNsqmXugpPk00gJ0JNKh/97nxmjctdew==}\n464.     engines: {node: '>=18'}\n465.     cpu: [s390x]\n466.     os: [linux]\n467. \n468.   '@esbuild/linux-x64@0.21.5':\n469.     resolution: {integrity: sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==}\n470.     engines: {node: '>=12'}\n471.     cpu: [x64]\n472.     os: [linux]\n473. \n474.   '@esbuild/linux-x64@0.25.10':\n475.     resolution: {integrity: sha512-QSX81KhFoZGwenVyPoberggdW1nrQZSvfVDAIUXr3WqLRZGZqWk/P4T8p2SP+de2Sr5HPcvjhcJzEiulKgnxtA==}\n476.     engines: {node: '>=18'}\n477.     cpu: [x64]\n478.     os: [linux]\n479. \n480.   '@esbuild/netbsd-arm64@0.25.10':\n481.     resolution: {integrity: sha512-AKQM3gfYfSW8XRk8DdMCzaLUFB15dTrZfnX8WXQoOUpUBQ+NaAFCP1kPS/ykbbGYz7rxn0WS48/81l9hFl3u4A==}\n482.     engines: {node: '>=18'}\n483.     cpu: [arm64]\n484.     os: [netbsd]\n485. \n486.   '@esbuild/netbsd-x64@0.21.5':\n487.     resolution: {integrity: sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==}\n488.     engines: {node: '>=12'}\n489.     cpu: [x64]\n490.     os: [netbsd]\n491. \n492.   '@esbuild/netbsd-x64@0.25.10':\n493.     resolution: {integrity: sha512-7RTytDPGU6fek/hWuN9qQpeGPBZFfB4zZgcz2VK2Z5VpdUxEI8JKYsg3JfO0n/Z1E/6l05n0unDCNc4HnhQGig==}\n494.     engines: {node: '>=18'}\n495.     cpu: [x64]\n496.     os: [netbsd]\n497. \n498.   '@esbuild/openbsd-arm64@0.25.10':\n499.     resolution: {integrity: sha512-5Se0VM9Wtq797YFn+dLimf2Zx6McttsH2olUBsDml+lm0GOCRVebRWUvDtkY4BWYv/3NgzS8b/UM3jQNh5hYyw==}\n500.     engines: {node: '>=18'}\n501.     cpu: [arm64]\n502.     os: [openbsd]\n503. \n504.   '@esbuild/openbsd-x64@0.21.5':\n505.     resolution: {integrity: sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==}\n506.     engines: {node: '>=12'}\n507.     cpu: [x64]\n508.     os: [openbsd]\n509. \n510.   '@esbuild/openbsd-x64@0.25.10':\n511.     resolution: {integrity: sha512-XkA4frq1TLj4bEMB+2HnI0+4RnjbuGZfet2gs/LNs5Hc7D89ZQBHQ0gL2ND6Lzu1+QVkjp3x1gIcPKzRNP8bXw==}\n512.     engines: {node: '>=18'}\n513.     cpu: [x64]\n514.     os: [openbsd]\n515. \n516.   '@esbuild/openharmony-arm64@0.25.10':\n517.     resolution: {integrity: sha512-AVTSBhTX8Y/Fz6OmIVBip9tJzZEUcY8WLh7I59+upa5/GPhh2/aM6bvOMQySspnCCHvFi79kMtdJS1w0DXAeag==}\n518.     engines: {node: '>=18'}\n519.     cpu: [arm64]\n520.     os: [openharmony]\n521. \n522.   '@esbuild/sunos-x64@0.21.5':\n523.     resolution: {integrity: sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==}\n524.     engines: {node: '>=12'}\n525.     cpu: [x64]\n526.     os: [sunos]\n527. \n528.   '@esbuild/sunos-x64@0.25.10':\n529.     resolution: {integrity: sha512-fswk3XT0Uf2pGJmOpDB7yknqhVkJQkAQOcW/ccVOtfx05LkbWOaRAtn5SaqXypeKQra1QaEa841PgrSL9ubSPQ==}\n530.     engines: {node: '>=18'}\n531.     cpu: [x64]\n532.     os: [sunos]\n533. \n534.   '@esbuild/win32-arm64@0.21.5':\n535.     resolution: {integrity: sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==}\n536.     engines: {node: '>=12'}\n537.     cpu: [arm64]\n538.     os: [win32]\n539. \n540.   '@esbuild/win32-arm64@0.25.10':\n541.     resolution: {integrity: sha512-ah+9b59KDTSfpaCg6VdJoOQvKjI33nTaQr4UluQwW7aEwZQsbMCfTmfEO4VyewOxx4RaDT/xCy9ra2GPWmO7Kw==}\n542.     engines: {node: '>=18'}\n543.     cpu: [arm64]\n544.     os: [win32]\n545. \n546.   '@esbuild/win32-ia32@0.21.5':\n547.     resolution: {integrity: sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==}\n548.     engines: {node: '>=12'}\n549.     cpu: [ia32]\n550.     os: [win32]\n551. \n552.   '@esbuild/win32-ia32@0.25.10':\n553.     resolution: {integrity: sha512-QHPDbKkrGO8/cz9LKVnJU22HOi4pxZnZhhA2HYHez5Pz4JeffhDjf85E57Oyco163GnzNCVkZK0b/n4Y0UHcSw==}\n554.     engines: {node: '>=18'}\n555.     cpu: [ia32]\n556.     os: [win32]\n557. \n558.   '@esbuild/win32-x64@0.21.5':\n559.     resolution: {integrity: sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==}\n560.     engines: {node: '>=12'}\n561.     cpu: [x64]\n562.     os: [win32]\n563. \n564.   '@esbuild/win32-x64@0.25.10':\n565.     resolution: {integrity: sha512-9KpxSVFCu0iK1owoez6aC/s/EdUQLDN3adTxGCqxMVhrPDj6bt5dbrHDXUuq+Bs2vATFBBrQS5vdQ/Ed2P+nbw==}\n566.     engines: {node: '>=18'}\n567.     cpu: [x64]\n568.     os: [win32]\n569. \n570.   '@eslint-community/eslint-utils@4.9.0':\n571.     resolution: {integrity: sha512-ayVFHdtZ+hsq1t2Dy24wCmGXGe4q9Gu3smhLYALJrr473ZH27MsnSL+LKUlimp4BWJqMDMLmPpx/Q9R3OAlL4g==}\n572.     engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n573.     peerDependencies:\n574.       eslint: ^6.0.0 || ^7.0.0 || >=8.0.0\n575. \n576.   '@eslint-community/regexpp@4.12.1':\n577.     resolution: {integrity: sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==}\n578.     engines: {node: ^12.0.0 || ^14.0.0 || >=16.0.0}\n579. \n580.   '@eslint/config-array@0.18.0':\n581.     resolution: {integrity: sha512-fTxvnS1sRMu3+JjXwJG0j/i4RT9u4qJ+lqS/yCGap4lH4zZGzQ7tu+xZqQmcMZq5OBZDL4QRxQzRjkWcGt8IVw==}\n582.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n583. \n584.   '@eslint/eslintrc@3.1.0':\n585.     resolution: {integrity: sha512-4Bfj15dVJdoy3RfZmmo86RK1Fwzn6SstsvK9JS+BaVKqC6QQQQyXekNaC+g+LKNgkQ+2VhGAzm6hO40AhMR3zQ==}\n586.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n587. \n588.   '@eslint/js@9.9.1':\n589.     resolution: {integrity: sha512-xIDQRsfg5hNBqHz04H1R3scSVwmI+KUbqjsQKHKQ1DAUSaUjYPReZZmS/5PNiKu1fUvzDd6H7DEDKACSEhu+TQ==}\n590.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n591. \n592.   '@eslint/object-schema@2.1.4':\n593.     resolution: {integrity: sha512-BsWiH1yFGjXXS2yvrf5LyuoSIIbPrGUWob917o+BTKuZ7qJdxX8aJLRxs1fS9n6r7vESrq1OUqb68dANcFXuQQ==}\n594.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n595. \n596.   '@humanwhocodes/module-importer@1.0.1':\n597.     resolution: {integrity: sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==}\n598.     engines: {node: '>=12.22'}\n599. \n600.   '@humanwhocodes/retry@0.3.0':\n601.     resolution: {integrity: sha512-d2CGZR2o7fS6sWB7DG/3a95bGKQyHMACZ5aW8qGkkqQpUoZV6C0X7Pc7l4ZNMZkfNBf4VWNe9E1jRsf0G146Ew==}\n602.     engines: {node: '>=18.18'}\n603. \n604.   '@inquirer/external-editor@1.0.2':\n605.     resolution: {integrity: sha512-yy9cOoBnx58TlsPrIxauKIFQTiyH+0MK4e97y4sV9ERbI+zDxw7i2hxHLCIEGIE/8PPvDxGhgzIOTSOWcs6/MQ==}\n606.     engines: {node: '>=18'}\n607.     peerDependencies:\n608.       '@types/node': '>=18'\n609.     peerDependenciesMeta:\n610.       '@types/node':\n611.         optional: true\n612. \n613.   '@isaacs/cliui@8.0.2':\n614.     resolution: {integrity: sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==}\n615.     engines: {node: '>=12'}\n616. \n617.   '@istanbuljs/schema@0.1.3':\n618.     resolution: {integrity: sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==}\n619.     engines: {node: '>=8'}\n620. \n621.   '@jridgewell/gen-mapping@0.3.5':\n622.     resolution: {integrity: sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==}\n623.     engines: {node: '>=6.0.0'}\n624. \n625.   '@jridgewell/remapping@2.3.4':\n626.     resolution: {integrity: sha512-aG+WvAz17rhbzhKNkSeMLgbkPPK82ovXdONvmucbGhUqcroRFLLVhoGAk4xEI17gHpXgNX3sr0/B1ybRUsbEWw==}\n627. \n628.   '@jridgewell/resolve-uri@3.1.1':\n629.     resolution: {integrity: sha512-dSYZh7HhCDtCKm4QakX0xFpsRDqjjtZf/kjI/v3T3Nwt5r8/qz/M19F9ySyOqU94SXBmeG9ttTul+YnR4LOxFA==}\n630.     engines: {node: '>=6.0.0'}\n631. \n632.   '@jridgewell/set-array@1.2.1':\n633.     resolution: {integrity: sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==}\n634.     engines: {node: '>=6.0.0'}\n635. \n636.   '@jridgewell/source-map@0.3.6':\n637.     resolution: {integrity: sha512-1ZJTZebgqllO79ue2bm3rIGud/bOe0pP5BjSRCRxxYkEZS8STV7zN84UBbiYu7jy+eCKSnVIUgoWWE/tt+shMQ==}\n638. \n639.   '@jridgewell/sourcemap-codec@1.5.0':\n640.     resolution: {integrity: sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==}\n641. \n642.   '@jridgewell/trace-mapping@0.3.31':\n643.     resolution: {integrity: sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==}\n644. \n645.   '@manypkg/find-root@1.1.0':\n646.     resolution: {integrity: sha512-mki5uBvhHzO8kYYix/WRy2WX8S3B5wdVSc9D6KcU5lQNglP2yt58/VfLuAK49glRXChosY8ap2oJ1qgma3GUVA==}\n647. \n648.   '@manypkg/get-packages@1.1.3':\n649.     resolution: {integrity: sha512-fo+QhuU3qE/2TQMQmbVMqaQ6EWbMhi4ABWP+O4AM1NqPBuy0OrApV5LO6BrrgnhtAHS2NH6RrVk9OL181tTi8A==}\n650. \n651.   '@nodelib/fs.scandir@2.1.5':\n652.     resolution: {integrity: sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==}\n653.     engines: {node: '>= 8'}\n654. \n655.   '@nodelib/fs.stat@2.0.5':\n656.     resolution: {integrity: sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==}\n657.     engines: {node: '>= 8'}\n658. \n659.   '@nodelib/fs.walk@1.2.8':\n660.     resolution: {integrity: sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==}\n661.     engines: {node: '>= 8'}\n662. \n663.   '@pkgjs/parseargs@0.11.0':\n664.     resolution: {integrity: sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==}\n665.     engines: {node: '>=14'}\n666. \n667.   '@playwright/test@1.46.1':\n668.     resolution: {integrity: sha512-Fq6SwLujA/DOIvNC2EL/SojJnkKf/rAwJ//APpJJHRyMi1PdKrY3Az+4XNQ51N4RTbItbIByQ0jgd1tayq1aeA==}\n669.     engines: {node: '>=18'}\n670.     hasBin: true\n671. \n672.   '@polka/url@1.0.0-next.25':\n673.     resolution: {integrity: sha512-j7P6Rgr3mmtdkeDGTe0E/aYyWEWVtc5yFXtHCRHs28/jptDEWfaVOc5T7cblqy1XKPPfCxJc/8DwQ5YgLOZOVQ==}\n674. \n675.   '@rollup/plugin-commonjs@28.0.1':\n676.     resolution: {integrity: sha512-+tNWdlWKbpB3WgBN7ijjYkq9X5uhjmcvyjEght4NmH5fAU++zfQzAJ6wumLS+dNcvwEZhKx2Z+skY8m7v0wGSA==}\n677.     engines: {node: '>=16.0.0 || 14 >= 14.17'}\n678.     peerDependencies:\n679.       rollup: ^2.68.0||^3.0.0||^4.0.0\n680.     peerDependenciesMeta:\n681.       rollup:\n682.         optional: true\n683. \n684.   '@rollup/plugin-node-resolve@15.3.0':\n685.     resolution: {integrity: sha512-9eO5McEICxMzJpDW9OnMYSv4Sta3hmt7VtBFz5zR9273suNOydOyq/FrGeGy+KsTRFm8w0SLVhzig2ILFT63Ag==}\n686.     engines: {node: '>=14.0.0'}\n687.     peerDependencies:\n688.       rollup: ^2.78.0||^3.0.0||^4.0.0\n689.     peerDependenciesMeta:\n690.       rollup:\n691.         optional: true\n692. \n693.   '@rollup/plugin-terser@0.4.4':\n694.     resolution: {integrity: sha512-XHeJC5Bgvs8LfukDwWZp7yeqin6ns8RTl2B9avbejt6tZqsqvVoWI7ZTQrcNsfKEDWBTnTxM8nMDkO2IFFbd0A==}\n695.     engines: {node: '>=14.0.0'}\n696.     peerDependencies:\n697.       rollup: ^2.0.0||^3.0.0||^4.0.0\n698.     peerDependenciesMeta:\n699.       rollup:\n700.         optional: true\n701. \n702.   '@rollup/plugin-virtual@3.0.2':\n703.     resolution: {integrity: sha512-10monEYsBp3scM4/ND4LNH5Rxvh3e/cVeL3jWTgZ2SrQ+BmUoQcopVQvnaMcOnykb1VkxUFuDAN+0FnpTFRy2A==}\n704.     engines: {node: '>=14.0.0'}\n705.     peerDependencies:\n706.       rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\n707.     peerDependenciesMeta:\n708.       rollup:\n709.         optional: true\n710. \n711.   '@rollup/pluginutils@5.1.0':\n712.     resolution: {integrity: sha512-XTIWOPPcpvyKI6L1NHo0lFlCyznUEyPmPY1mc3KpPVDYulHSTvyeLNVW00QTLIAFNhR3kYnJTQHeGqU4M3n09g==}\n713.     engines: {node: '>=14.0.0'}\n714.     peerDependencies:\n715.       rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\n716.     peerDependenciesMeta:\n717.       rollup:\n718.         optional: true\n719. \n720.   '@rollup/rollup-android-arm-eabi@4.50.1':\n721.     resolution: {integrity: sha512-HJXwzoZN4eYTdD8bVV22DN8gsPCAj3V20NHKOs8ezfXanGpmVPR7kalUHd+Y31IJp9stdB87VKPFbsGY3H/2ag==}\n722.     cpu: [arm]\n723.     os: [android]\n724. \n725.   '@rollup/rollup-android-arm64@4.50.1':\n726.     resolution: {integrity: sha512-PZlsJVcjHfcH53mOImyt3bc97Ep3FJDXRpk9sMdGX0qgLmY0EIWxCag6EigerGhLVuL8lDVYNnSo8qnTElO4xw==}\n727.     cpu: [arm64]\n728.     os: [android]\n729. \n730.   '@rollup/rollup-darwin-arm64@4.50.1':\n731.     resolution: {integrity: sha512-xc6i2AuWh++oGi4ylOFPmzJOEeAa2lJeGUGb4MudOtgfyyjr4UPNK+eEWTPLvmPJIY/pgw6ssFIox23SyrkkJw==}\n732.     cpu: [arm64]\n733.     os: [darwin]\n734. \n735.   '@rollup/rollup-darwin-x64@4.50.1':\n736.     resolution: {integrity: sha512-2ofU89lEpDYhdLAbRdeyz/kX3Y2lpYc6ShRnDjY35bZhd2ipuDMDi6ZTQ9NIag94K28nFMofdnKeHR7BT0CATw==}\n737.     cpu: [x64]\n738.     os: [darwin]\n739. \n740.   '@rollup/rollup-freebsd-arm64@4.50.1':\n741.     resolution: {integrity: sha512-wOsE6H2u6PxsHY/BeFHA4VGQN3KUJFZp7QJBmDYI983fgxq5Th8FDkVuERb2l9vDMs1D5XhOrhBrnqcEY6l8ZA==}\n742.     cpu: [arm64]\n743.     os: [freebsd]\n744. \n745.   '@rollup/rollup-freebsd-x64@4.50.1':\n746.     resolution: {integrity: sha512-A/xeqaHTlKbQggxCqispFAcNjycpUEHP52mwMQZUNqDUJFFYtPHCXS1VAG29uMlDzIVr+i00tSFWFLivMcoIBQ==}\n747.     cpu: [x64]\n748.     os: [freebsd]\n749. \n750.   '@rollup/rollup-linux-arm-gnueabihf@4.50.1':\n751.     resolution: {integrity: sha512-54v4okehwl5TaSIkpp97rAHGp7t3ghinRd/vyC1iXqXMfjYUTm7TfYmCzXDoHUPTTf36L8pr0E7YsD3CfB3ZDg==}\n752.     cpu: [arm]\n753.     os: [linux]\n754. \n755.   '@rollup/rollup-linux-arm-musleabihf@4.50.1':\n756.     resolution: {integrity: sha512-p/LaFyajPN/0PUHjv8TNyxLiA7RwmDoVY3flXHPSzqrGcIp/c2FjwPPP5++u87DGHtw+5kSH5bCJz0mvXngYxw==}\n757.     cpu: [arm]\n758.     os: [linux]\n759. \n760.   '@rollup/rollup-linux-arm64-gnu@4.50.1':\n761.     resolution: {integrity: sha512-2AbMhFFkTo6Ptna1zO7kAXXDLi7H9fGTbVaIq2AAYO7yzcAsuTNWPHhb2aTA6GPiP+JXh85Y8CiS54iZoj4opw==}\n762.     cpu: [arm64]\n763.     os: [linux]\n764. \n765.   '@rollup/rollup-linux-arm64-musl@4.50.1':\n766.     resolution: {integrity: sha512-Cgef+5aZwuvesQNw9eX7g19FfKX5/pQRIyhoXLCiBOrWopjo7ycfB292TX9MDcDijiuIJlx1IzJz3IoCPfqs9w==}\n767.     cpu: [arm64]\n768.     os: [linux]\n769. \n770.   '@rollup/rollup-linux-loongarch64-gnu@4.50.1':\n771.     resolution: {integrity: sha512-RPhTwWMzpYYrHrJAS7CmpdtHNKtt2Ueo+BlLBjfZEhYBhK00OsEqM08/7f+eohiF6poe0YRDDd8nAvwtE/Y62Q==}\n772.     cpu: [loong64]\n773.     os: [linux]\n774. \n775.   '@rollup/rollup-linux-ppc64-gnu@4.50.1':\n776.     resolution: {integrity: sha512-eSGMVQw9iekut62O7eBdbiccRguuDgiPMsw++BVUg+1K7WjZXHOg/YOT9SWMzPZA+w98G+Fa1VqJgHZOHHnY0Q==}\n777.     cpu: [ppc64]\n778.     os: [linux]\n779. \n780.   '@rollup/rollup-linux-riscv64-gnu@4.50.1':\n781.     resolution: {integrity: sha512-S208ojx8a4ciIPrLgazF6AgdcNJzQE4+S9rsmOmDJkusvctii+ZvEuIC4v/xFqzbuP8yDjn73oBlNDgF6YGSXQ==}\n782.     cpu: [riscv64]\n783.     os: [linux]\n784. \n785.   '@rollup/rollup-linux-riscv64-musl@4.50.1':\n786.     resolution: {integrity: sha512-3Ag8Ls1ggqkGUvSZWYcdgFwriy2lWo+0QlYgEFra/5JGtAd6C5Hw59oojx1DeqcA2Wds2ayRgvJ4qxVTzCHgzg==}\n787.     cpu: [riscv64]\n788.     os: [linux]\n789. \n790.   '@rollup/rollup-linux-s390x-gnu@4.50.1':\n791.     resolution: {integrity: sha512-t9YrKfaxCYe7l7ldFERE1BRg/4TATxIg+YieHQ966jwvo7ddHJxPj9cNFWLAzhkVsbBvNA4qTbPVNsZKBO4NSg==}\n792.     cpu: [s390x]\n793.     os: [linux]\n794. \n795.   '@rollup/rollup-linux-x64-gnu@4.50.1':\n796.     resolution: {integrity: sha512-MCgtFB2+SVNuQmmjHf+wfI4CMxy3Tk8XjA5Z//A0AKD7QXUYFMQcns91K6dEHBvZPCnhJSyDWLApk40Iq/H3tA==}\n797.     cpu: [x64]\n798.     os: [linux]\n799. \n800.   '@rollup/rollup-linux-x64-musl@4.50.1':\n801.     resolution: {integrity: sha512-nEvqG+0jeRmqaUMuwzlfMKwcIVffy/9KGbAGyoa26iu6eSngAYQ512bMXuqqPrlTyfqdlB9FVINs93j534UJrg==}\n802.     cpu: [x64]\n803.     os: [linux]\n804. \n805.   '@rollup/rollup-openharmony-arm64@4.50.1':\n806.     resolution: {integrity: sha512-RDsLm+phmT3MJd9SNxA9MNuEAO/J2fhW8GXk62G/B4G7sLVumNFbRwDL6v5NrESb48k+QMqdGbHgEtfU0LCpbA==}\n807.     cpu: [arm64]\n808.     os: [openharmony]\n809. \n810.   '@rollup/rollup-win32-arm64-msvc@4.50.1':\n811.     resolution: {integrity: sha512-hpZB/TImk2FlAFAIsoElM3tLzq57uxnGYwplg6WDyAxbYczSi8O2eQ+H2Lx74504rwKtZ3N2g4bCUkiamzS6TQ==}\n812.     cpu: [arm64]\n813.     os: [win32]\n814. \n815.   '@rollup/rollup-win32-ia32-msvc@4.50.1':\n816.     resolution: {integrity: sha512-SXjv8JlbzKM0fTJidX4eVsH+Wmnp0/WcD8gJxIZyR6Gay5Qcsmdbi9zVtnbkGPG8v2vMR1AD06lGWy5FLMcG7A==}\n817.     cpu: [ia32]\n818.     os: [win32]\n819. \n820.   '@rollup/rollup-win32-x64-msvc@4.50.1':\n821.     resolution: {integrity: sha512-StxAO/8ts62KZVRAm4JZYq9+NqNsV7RvimNK+YM7ry//zebEH6meuugqW/P5OFUCjyQgui+9fUxT6d5NShvMvA==}\n822.     cpu: [x64]\n823.     os: [win32]\n824. \n825.   '@stylistic/eslint-plugin-js@1.8.0':\n826.     resolution: {integrity: sha512-jdvnzt+pZPg8TfclZlTZPiUbbima93ylvQ+wNgHLNmup3obY6heQvgewSu9i2CfS61BnRByv+F9fxQLPoNeHag==}\n827.     engines: {node: ^16.0.0 || >=18.0.0}\n828.     peerDependencies:\n829.       eslint: '>=8.40.0'\n830. \n831.   '@sveltejs/acorn-typescript@1.0.5':\n832.     resolution: {integrity: sha512-IwQk4yfwLdibDlrXVE04jTZYlLnwsTT2PIOQQGNLWfjavGifnk1JD1LcZjZaBTRcxZu2FfPfNLOE04DSu9lqtQ==}\n833.     peerDependencies:\n834.       acorn: ^8.9.0\n835. \n836.   '@sveltejs/eslint-config@8.3.3':\n837.     resolution: {integrity: sha512-vkrQgEmhokFEOpuTo7NlVXJJMJJGNzxjmkQCTkHSwIOdzQSUukDIJ4038IjdcnIERSIlo4OpLAydWLx52BVyQA==}\n838.     peerDependencies:\n839.       '@stylistic/eslint-plugin-js': '>= 1'\n840.       eslint: '>= 9'\n841.       eslint-config-prettier: '>= 9'\n842.       eslint-plugin-n: '>= 17'\n843.       eslint-plugin-svelte: '>= 3'\n844.       typescript: '>= 5'\n845.       typescript-eslint: '>= 8'\n846. \n847.   '@sveltejs/vite-plugin-svelte-inspector@5.0.1':\n848.     resolution: {integrity: sha512-ubWshlMk4bc8mkwWbg6vNvCeT7lGQojE3ijDh3QTR6Zr/R+GXxsGbyH4PExEPpiFmqPhYiVSVmHBjUcVc1JIrA==}\n849.     engines: {node: ^20.19 || ^22.12 || >=24}\n850.     peerDependencies:\n851.       '@sveltejs/vite-plugin-svelte': ^6.0.0-next.0\n852.       svelte: ^5.0.0\n853.       vite: ^6.3.0 || ^7.0.0\n854. \n855.   '@sveltejs/vite-plugin-svelte@6.2.0':\n856.     resolution: {integrity: sha512-nJsV36+o7rZUDlrnSduMNl11+RoDE1cKqOI0yUEBCcqFoAZOk47TwD3dPKS2WmRutke9StXnzsPBslY7prDM9w==}\n857.     engines: {node: ^20.19 || ^22.12 || >=24}\n858.     peerDependencies:\n859.       svelte: ^5.0.0\n860.       vite: ^6.3.0 || ^7.0.0\n861. \n862.   '@svitejs/changesets-changelog-github-compact@1.1.0':\n863.     resolution: {integrity: sha512-qhUGGDHcpbY2zpjW3SwqchuW8J/5EzlPFud7xNntHKA7f3a/mx5+g+ruJKFHSAiVZYo30PALt+AyhmPUNKH/Og==}\n864.     engines: {node: ^14.13.1 || ^16.0.0 || >=18}\n865. \n866.   '@types/aria-query@5.0.4':\n867.     resolution: {integrity: sha512-rfT93uj5s0PRL7EzccGMs3brplhcrghnDoV26NqKhCAS1hVo+WdNsPvE/yb6ilfr5hi2MEk6d5EWJTKdxg8jVw==}\n868. \n869.   '@types/eslint@8.56.12':\n870.     resolution: {integrity: sha512-03ruubjWyOHlmljCVoxSuNDdmfZDzsrrz0P2LeJsOXr+ZwFQ+0yQIwNCwt/GYhV7Z31fgtXJTAEs+FYlEL851g==}\n871. \n872.   '@types/estree@1.0.8':\n873.     resolution: {integrity: sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==}\n874. \n875.   '@types/json-schema@7.0.15':\n876.     resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}\n877. \n878.   '@types/node@12.20.55':\n879.     resolution: {integrity: sha512-J8xLz7q2OFulZ2cyGTLE1TbbZcjpno7FaN6zdJNrgAdrJ+DZzh/uFR6YrTb4C+nXakvud8Q4+rbhoIWlYQbUFQ==}\n880. \n881.   '@types/node@20.19.17':\n882.     resolution: {integrity: sha512-gfehUI8N1z92kygssiuWvLiwcbOB3IRktR6hTDgJlXMYh5OvkPSRmgfoBUmfZt+vhwJtX7v1Yw4KvvAf7c5QKQ==}\n883. \n884.   '@types/node@24.5.2':\n885.     resolution: {integrity: sha512-FYxk1I7wPv3K2XBaoyH2cTnocQEu8AOZ60hPbsyukMPLv5/5qr7V1i8PLHdl6Zf87I+xZXFvPCXYjiTFq+YSDQ==}\n886. \n887.   '@types/picomatch@4.0.2':\n888.     resolution: {integrity: sha512-qHHxQ+P9PysNEGbALT8f8YOSHW0KJu6l2xU8DYY0fu/EmGxXdVnuTLvFUvBgPJMSqXq29SYHveejeAha+4AYgA==}\n889. \n890.   '@types/resolve@1.20.2':\n891.     resolution: {integrity: sha512-60BCwRFOZCQhDncwQdxxeOEEkbc5dIMccYLwbxsS4TUNeVECQ/pBJ0j09mrHOl/JJvpRPGwO9SvE4nR2Nb/a4Q==}\n892. \n893.   '@typescript-eslint/eslint-plugin@8.26.0':\n894.     resolution: {integrity: sha512-cLr1J6pe56zjKYajK6SSSre6nl1Gj6xDp1TY0trpgPzjVbgDwd09v2Ws37LABxzkicmUjhEeg/fAUjPJJB1v5Q==}\n895.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n896.     peerDependencies:\n897.       '@typescript-eslint/parser': ^8.0.0 || ^8.0.0-alpha.0\n898.       eslint: ^8.57.0 || ^9.0.0\n899.       typescript: '>=4.8.4 <5.9.0'\n900. \n901.   '@typescript-eslint/parser@8.26.0':\n902.     resolution: {integrity: sha512-mNtXP9LTVBy14ZF3o7JG69gRPBK/2QWtQd0j0oH26HcY/foyJJau6pNUez7QrM5UHnSvwlQcJXKsk0I99B9pOA==}\n903.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n904.     peerDependencies:\n905.       eslint: ^8.57.0 || ^9.0.0\n906.       typescript: '>=4.8.4 <5.9.0'\n907. \n908.   '@typescript-eslint/project-service@8.43.0':\n909.     resolution: {integrity: sha512-htB/+D/BIGoNTQYffZw4uM4NzzuolCoaA/BusuSIcC8YjmBYQioew5VUZAYdAETPjeed0hqCaW7EHg+Robq8uw==}\n910.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n911.     peerDependencies:\n912.       typescript: '>=4.8.4 <6.0.0'\n913. \n914.   '@typescript-eslint/scope-manager@8.26.0':\n915.     resolution: {integrity: sha512-E0ntLvsfPqnPwng8b8y4OGuzh/iIOm2z8U3S9zic2TeMLW61u5IH2Q1wu0oSTkfrSzwbDJIB/Lm8O3//8BWMPA==}\n916.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n917. \n918.   '@typescript-eslint/scope-manager@8.43.0':\n919.     resolution: {integrity: sha512-daSWlQ87ZhsjrbMLvpuuMAt3y4ba57AuvadcR7f3nl8eS3BjRc8L9VLxFLk92RL5xdXOg6IQ+qKjjqNEimGuAg==}\n920.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n921. \n922.   '@typescript-eslint/tsconfig-utils@8.43.0':\n923.     resolution: {integrity: sha512-ALC2prjZcj2YqqL5X/bwWQmHA2em6/94GcbB/KKu5SX3EBDOsqztmmX1kMkvAJHzxk7TazKzJfFiEIagNV3qEA==}\n924.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n925.     peerDependencies:\n926.       typescript: '>=4.8.4 <6.0.0'\n927. \n928.   '@typescript-eslint/type-utils@8.26.0':\n929.     resolution: {integrity: sha512-ruk0RNChLKz3zKGn2LwXuVoeBcUMh+jaqzN461uMMdxy5H9epZqIBtYj7UiPXRuOpaALXGbmRuZQhmwHhaS04Q==}\n930.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n931.     peerDependencies:\n932.       eslint: ^8.57.0 || ^9.0.0\n933.       typescript: '>=4.8.4 <5.9.0'\n934. \n935.   '@typescript-eslint/types@8.26.0':\n936.     resolution: {integrity: sha512-89B1eP3tnpr9A8L6PZlSjBvnJhWXtYfZhECqlBl1D9Lme9mHO6iWlsprBtVenQvY1HMhax1mWOjhtL3fh/u+pA==}\n937.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n938. \n939.   '@typescript-eslint/types@8.43.0':\n940.     resolution: {integrity: sha512-vQ2FZaxJpydjSZJKiSW/LJsabFFvV7KgLC5DiLhkBcykhQj8iK9BOaDmQt74nnKdLvceM5xmhaTF+pLekrxEkw==}\n941.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n942. \n943.   '@typescript-eslint/typescript-estree@8.26.0':\n944.     resolution: {integrity: sha512-tiJ1Hvy/V/oMVRTbEOIeemA2XoylimlDQ03CgPPNaHYZbpsc78Hmngnt+WXZfJX1pjQ711V7g0H7cSJThGYfPQ==}\n945.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n946.     peerDependencies:\n947.       typescript: '>=4.8.4 <5.9.0'\n948. \n949.   '@typescript-eslint/typescript-estree@8.43.0':\n950.     resolution: {integrity: sha512-7Vv6zlAhPb+cvEpP06WXXy/ZByph9iL6BQRBDj4kmBsW98AqEeQHlj/13X+sZOrKSo9/rNKH4Ul4f6EICREFdw==}\n951.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n952.     peerDependencies:\n953.       typescript: '>=4.8.4 <6.0.0'\n954. \n955.   '@typescript-eslint/utils@8.26.0':\n956.     resolution: {integrity: sha512-2L2tU3FVwhvU14LndnQCA2frYC8JnPDVKyQtWFPf8IYFMt/ykEN1bPolNhNbCVgOmdzTlWdusCTKA/9nKrf8Ig==}\n957.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n958.     peerDependencies:\n959.       eslint: ^8.57.0 || ^9.0.0\n960.       typescript: '>=4.8.4 <5.9.0'\n961. \n962.   '@typescript-eslint/utils@8.43.0':\n963.     resolution: {integrity: sha512-S1/tEmkUeeswxd0GGcnwuVQPFWo8NzZTOMxCvw8BX7OMxnNae+i8Tm7REQen/SwUIPoPqfKn7EaZ+YLpiB3k9g==}\n964.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n965.     peerDependencies:\n966.       eslint: ^8.57.0 || ^9.0.0\n967.       typescript: '>=4.8.4 <6.0.0'\n968. \n969.   '@typescript-eslint/visitor-keys@8.26.0':\n970.     resolution: {integrity: sha512-2z8JQJWAzPdDd51dRQ/oqIJxe99/hoLIqmf8RMCAJQtYDc535W/Jt2+RTP4bP0aKeBG1F65yjIZuczOXCmbWwg==}\n971.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n972. \n973.   '@typescript-eslint/visitor-keys@8.43.0':\n974.     resolution: {integrity: sha512-T+S1KqRD4sg/bHfLwrpF/K3gQLBM1n7Rp7OjjikjTEssI2YJzQpi5WXoynOaQ93ERIuq3O8RBTOUYDKszUCEHw==}\n975.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n976. \n977.   '@vitest/coverage-v8@2.1.9':\n978.     resolution: {integrity: sha512-Z2cOr0ksM00MpEfyVE8KXIYPEcBFxdbLSs56L8PO0QQMxt/6bDj45uQfxoc96v05KW3clk7vvgP0qfDit9DmfQ==}\n979.     peerDependencies:\n980.       '@vitest/browser': 2.1.9\n981.       vitest: 2.1.9\n982.     peerDependenciesMeta:\n983.       '@vitest/browser':\n984.         optional: true\n985. \n986.   '@vitest/expect@2.1.9':\n987.     resolution: {integrity: sha512-UJCIkTBenHeKT1TTlKMJWy1laZewsRIzYighyYiJKZreqtdxSos/S1t+ktRMQWu2CKqaarrkeszJx1cgC5tGZw==}\n988. \n989.   '@vitest/mocker@2.1.9':\n990.     resolution: {integrity: sha512-tVL6uJgoUdi6icpxmdrn5YNo3g3Dxv+IHJBr0GXHaEdTcw3F+cPKnsXFhli6nO+f/6SDKPHEK1UN+k+TQv0Ehg==}\n991.     peerDependencies:\n992.       msw: ^2.4.9\n993.       vite: ^5.0.0\n994.     peerDependenciesMeta:\n995.       msw:\n996.         optional: true\n997.       vite:\n998.         optional: true\n999. \n1000.   '@vitest/pretty-format@2.1.9':\n",
                    "relative_path": "pnpm-lock.yaml",
                    "start_line_number": 1,
                    "end_line_number": 1000
                },
                {
                    "type": "Context",
                    "content": "File: pnpm-workspace.yaml\nLine number range: 1 - 3\nContent:\n1. packages:\n2.   - 'packages/*'\n3.   - 'playgrounds/*'\n",
                    "relative_path": "pnpm-workspace.yaml",
                    "start_line_number": 1,
                    "end_line_number": 3
                },
                {
                    "type": "Context",
                    "content": "File: README.md\nLine number range: 1 - 38\nContent:\n1. <a href=\"https://svelte.dev\">\n2. \t<picture>\n3. \t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/banner_dark.png\">\n4. \t\t<img src=\"assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\n5. \t</picture>\n6. </a>\n7. \n8. [![License](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\n9. \n10. ## What is Svelte?\n11. \n12. Svelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\n13. \n14. Learn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\n15. \n16. ## Supporting Svelte\n17. \n18. Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:\n19. \n20. - [Becoming a backer on Open Collective](https://opencollective.com/svelte).\n21. \n22. Funds donated via Open Collective will be used for compensating expenses related to Svelte's development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte's development more directly.\n23. \n24. ## Roadmap\n25. \n26. You may view [our roadmap](https://svelte.dev/roadmap) if you'd like to see what we're currently working on.\n27. \n28. ## Contributing\n29. \n30. Please see the [Contributing Guide](CONTRIBUTING.md) and the [`svelte`](packages/svelte) package for information on contributing to Svelte.\n31. \n32. ## Is svelte.dev down?\n33. \n34. Probably not, but it's possible. If you can't seem to access any `.dev` sites, check out [this SuperUser question and answer](https://superuser.com/q/1413402).\n35. \n36. ## License\n37. \n38. [MIT](LICENSE.md)\n",
                    "relative_path": "README.md",
                    "start_line_number": 1,
                    "end_line_number": 38
                }
            ],
            "env_implement_write_messages": [
                {
                    "type": "HumanMessage",
                    "content": "content='Project Environment Context:\\nFile: pnpm-lock.yaml\\nLine number range: 1 - 1000\\nContent:\\n1. lockfileVersion: \\'9.0\\'\\n2. \\n3. settings:\\n4.   autoInstallPeers: true\\n5.   excludeLinksFromLockfile: false\\n6. \\n7. importers:\\n8. \\n9.   .:\\n10.     devDependencies:\\n11.       \\'@changesets/cli\\':\\n12.         specifier: ^2.29.7\\n13.         version: 2.29.7(@types/node@20.19.17)\\n14.       \\'@sveltejs/eslint-config\\':\\n15.         specifier: ^8.3.3\\n16.         version: 8.3.3(@stylistic/eslint-plugin-js@1.8.0(eslint@9.9.1))(eslint-config-prettier@9.1.0(eslint@9.9.1))(eslint-plugin-n@17.16.1(eslint@9.9.1)(typescript@5.5.4))(eslint-plugin-svelte@3.11.0(eslint@9.9.1)(svelte@packages+svelte))(eslint@9.9.1)(typescript-eslint@8.26.0(eslint@9.9.1)(typescript@5.5.4))(typescript@5.5.4)\\n17.       \\'@svitejs/changesets-changelog-github-compact\\':\\n18.         specifier: ^1.1.0\\n19.         version: 1.1.0\\n20.       \\'@types/node\\':\\n21.         specifier: ^20.11.5\\n22.         version: 20.19.17\\n23.       \\'@types/picomatch\\':\\n24.         specifier: ^4.0.2\\n25.         version: 4.0.2\\n26.       \\'@vitest/coverage-v8\\':\\n27.         specifier: ^2.1.9\\n28.         version: 2.1.9(vitest@2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\\n29.       eslint:\\n30.         specifier: ^9.9.1\\n31.         version: 9.9.1\\n32.       eslint-plugin-lube:\\n33.         specifier: ^0.4.3\\n34.         version: 0.4.3\\n35.       eslint-plugin-svelte:\\n36.         specifier: ^3.11.0\\n37.         version: 3.11.0(eslint@9.9.1)(svelte@packages+svelte)\\n38.       jsdom:\\n39.         specifier: 25.0.1\\n40.         version: 25.0.1\\n41.       playwright:\\n42.         specifier: ^1.46.1\\n43.         version: 1.46.1\\n44.       prettier:\\n45.         specifier: ^3.2.4\\n46.         version: 3.2.4\\n47.       prettier-plugin-svelte:\\n48.         specifier: ^3.4.0\\n49.         version: 3.4.0(prettier@3.2.4)(svelte@packages+svelte)\\n50.       svelte:\\n51.         specifier: workspace:^\\n52.         version: link:packages/svelte\\n53.       typescript:\\n54.         specifier: ^5.5.4\\n55.         version: 5.5.4\\n56.       typescript-eslint:\\n57.         specifier: ^8.24.0\\n58.         version: 8.26.0(eslint@9.9.1)(typescript@5.5.4)\\n59.       v8-natives:\\n60.         specifier: ^1.2.5\\n61.         version: 1.2.5\\n62.       vitest:\\n63.         specifier: ^2.1.9\\n64.         version: 2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\\n65. \\n66.   packages/svelte:\\n67.     dependencies:\\n68.       \\'@jridgewell/remapping\\':\\n69.         specifier: ^2.3.4\\n70.         version: 2.3.4\\n71.       \\'@jridgewell/sourcemap-codec\\':\\n72.         specifier: ^1.5.0\\n73.         version: 1.5.0\\n74.       \\'@sveltejs/acorn-typescript\\':\\n75.         specifier: ^1.0.5\\n76.         version: 1.0.5(acorn@8.15.0)\\n77.       \\'@types/estree\\':\\n78.         specifier: ^1.0.5\\n79.         version: 1.0.8\\n80.       acorn:\\n81.         specifier: ^8.12.1\\n82.         version: 8.15.0\\n83.       aria-query:\\n84.         specifier: ^5.3.1\\n85.         version: 5.3.1\\n86.       axobject-query:\\n87.         specifier: ^4.1.0\\n88.         version: 4.1.0\\n89.       clsx:\\n90.         specifier: ^2.1.1\\n91.         version: 2.1.1\\n92.       esm-env:\\n93.         specifier: ^1.2.1\\n94.         version: 1.2.1\\n95.       esrap:\\n96.         specifier: ^2.1.0\\n97.         version: 2.1.0\\n98.       is-reference:\\n99.         specifier: ^3.0.3\\n100.         version: 3.0.3\\n101.       locate-character:\\n102.         specifier: ^3.0.0\\n103.         version: 3.0.0\\n104.       magic-string:\\n105.         specifier: ^0.30.11\\n106.         version: 0.30.17\\n107.       zimmerframe:\\n108.         specifier: ^1.1.2\\n109.         version: 1.1.2\\n110.     devDependencies:\\n111.       \\'@jridgewell/trace-mapping\\':\\n112.         specifier: ^0.3.25\\n113.         version: 0.3.31\\n114.       \\'@playwright/test\\':\\n115.         specifier: ^1.46.1\\n116.         version: 1.46.1\\n117.       \\'@rollup/plugin-commonjs\\':\\n118.         specifier: ^28.0.1\\n119.         version: 28.0.1(rollup@4.50.1)\\n120.       \\'@rollup/plugin-node-resolve\\':\\n121.         specifier: ^15.3.0\\n122.         version: 15.3.0(rollup@4.50.1)\\n123.       \\'@rollup/plugin-terser\\':\\n124.         specifier: ^0.4.4\\n125.         version: 0.4.4(rollup@4.50.1)\\n126.       \\'@rollup/plugin-virtual\\':\\n127.         specifier: ^3.0.2\\n128.         version: 3.0.2(rollup@4.50.1)\\n129.       \\'@types/aria-query\\':\\n130.         specifier: ^5.0.4\\n131.         version: 5.0.4\\n132.       \\'@types/node\\':\\n133.         specifier: ^20.11.5\\n134.         version: 20.19.17\\n135.       dts-buddy:\\n136.         specifier: ^0.5.5\\n137.         version: 0.5.5(typescript@5.5.4)\\n138.       esbuild:\\n139.         specifier: ^0.25.10\\n140.         version: 0.25.10\\n141.       rollup:\\n142.         specifier: ^4.22.4\\n143.         version: 4.50.1\\n144.       source-map:\\n145.         specifier: ^0.7.4\\n146.         version: 0.7.4\\n147.       tinyglobby:\\n148.         specifier: ^0.2.12\\n149.         version: 0.2.15\\n150.       typescript:\\n151.         specifier: ^5.5.4\\n152.         version: 5.5.4\\n153.       vitest:\\n154.         specifier: ^2.1.9\\n155.         version: 2.1.9(@types/node@20.19.17)(jsdom@25.0.1)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\\n156. \\n157.   playgrounds/sandbox:\\n158.     devDependencies:\\n159.       \\'@sveltejs/vite-plugin-svelte\\':\\n160.         specifier: ^6.2.0\\n161.         version: 6.2.0(svelte@packages+svelte)(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\\n162.       \\'@types/node\\':\\n163.         specifier: ^24.5.2\\n164.         version: 24.5.2\\n165.       polka:\\n166.         specifier: ^1.0.0-next.25\\n167.         version: 1.0.0-next.25\\n168.       svelte:\\n169.         specifier: workspace:*\\n170.         version: link:../../packages/svelte\\n171.       tinyglobby:\\n172.         specifier: ^0.2.12\\n173.         version: 0.2.15\\n174.       vite:\\n175.         specifier: ^7.1.5\\n176.         version: 7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0)\\n177.       vite-plugin-devtools-json:\\n178.         specifier: ^1.0.0\\n179.         version: 1.0.0(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\\n180.       vite-plugin-inspect:\\n181.         specifier: ^11.3.3\\n182.         version: 11.3.3(vite@7.1.5(@types/node@24.5.2)(lightningcss@1.23.0)(sass@1.70.0)(terser@5.27.0))\\n183. \\n184. packages:\\n185. \\n186.   \\'@aashutoshrathi/word-wrap@1.2.6\\':\\n187.     resolution: {integrity: sha512-1Yjs2SvM8TflER/OD3cOjhWWOZb58A2t7wpE2S9XfBYTiIl+XFhQG2bjy4Pu1I+EAlCNUzRDYDdFwFYUKvXcIA==}\\n188.     engines: {node: \\'>=0.10.0\\'}\\n189. \\n190.   \\'@ampproject/remapping@2.3.0\\':\\n191.     resolution: {integrity: sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==}\\n192.     engines: {node: \\'>=6.0.0\\'}\\n193. \\n194.   \\'@babel/helper-string-parser@7.24.8\\':\\n195.     resolution: {integrity: sha512-pO9KhhRcuUyGnJWwyEgnRJTSIZHiT+vMD0kPeD+so0l7mxkMT19g3pjY9GTnHySck/hDzq+dtW/4VgnMkippsQ==}\\n196.     engines: {node: \\'>=6.9.0\\'}\\n197. \\n198.   \\'@babel/helper-validator-identifier@7.24.7\\':\\n199.     resolution: {integrity: sha512-rR+PBcQ1SMQDDyF6X0wxtG8QyLCgUB0eRAGguqRLfkCA87l7yAP7ehq8SNj96OOGTO8OBV70KhuFYcIkHXOg0w==}\\n200.     engines: {node: \\'>=6.9.0\\'}\\n201. \\n202.   \\'@babel/parser@7.25.4\\':\\n203.     resolution: {integrity: sha512-nq+eWrOgdtu3jG5Os4TQP3x3cLA8hR8TvJNjD8vnPa20WGycimcparWnLK4jJhElTK6SDyuJo1weMKO/5LpmLA==}\\n204.     engines: {node: \\'>=6.0.0\\'}\\n205.     hasBin: true\\n206. \\n207.   \\'@babel/runtime@7.23.8\\':\\n208.     resolution: {integrity: sha512-Y7KbAP984rn1VGMbGqKmBLio9V7y5Je9GvU4rQPCPinCyNfUcToxIXl06d59URp/F3LwinvODxab5N/G6qggkw==}\\n209.     engines: {node: \\'>=6.9.0\\'}\\n210. \\n211.   \\'@babel/types@7.25.4\\':\\n212.     resolution: {integrity: sha512-zQ1ijeeCXVEh+aNL0RlmkPkG8HUiDcU2pzQQFjtbntgAczRASFzj4H+6+bV+dy1ntKR14I/DypeuRG1uma98iQ==}\\n213.     engines: {node: \\'>=6.9.0\\'}\\n214. \\n215.   \\'@bcoe/v8-coverage@0.2.3\\':\\n216.     resolution: {integrity: sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==}\\n217. \\n218.   \\'@changesets/apply-release-plan@7.0.13\\':\\n219.     resolution: {integrity: sha512-BIW7bofD2yAWoE8H4V40FikC+1nNFEKBisMECccS16W1rt6qqhNTBDmIw5HaqmMgtLNz9e7oiALiEUuKrQ4oHg==}\\n220. \\n221.   \\'@changesets/assemble-release-plan@6.0.9\\':\\n222.     resolution: {integrity: sha512-tPgeeqCHIwNo8sypKlS3gOPmsS3wP0zHt67JDuL20P4QcXiw/O4Hl7oXiuLnP9yg+rXLQ2sScdV1Kkzde61iSQ==}\\n223. \\n224.   \\'@changesets/changelog-git@0.2.1\\':\\n225.     resolution: {integrity: sha512-x/xEleCFLH28c3bQeQIyeZf8lFXyDFVn1SgcBiR2Tw/r4IAWlk1fzxCEZ6NxQAjF2Nwtczoen3OA2qR+UawQ8Q==}\\n226. \\n227.   \\'@changesets/cli@2.29.7\\':\\n228.     resolution: {integrity: sha512-R7RqWoaksyyKXbKXBTbT4REdy22yH81mcFK6sWtqSanxUCbUi9Uf+6aqxZtDQouIqPdem2W56CdxXgsxdq7FLQ==}\\n229.     hasBin: true\\n230. \\n231.   \\'@changesets/config@3.1.1\\':\\n232.     resolution: {integrity: sha512-bd+3Ap2TKXxljCggI0mKPfzCQKeV/TU4yO2h2C6vAihIo8tzseAn2e7klSuiyYYXvgu53zMN1OeYMIQkaQoWnA==}\\n233. \\n234.   \\'@changesets/errors@0.2.0\\':\\n235.     resolution: {integrity: sha512-6BLOQUscTpZeGljvyQXlWOItQyU71kCdGz7Pi8H8zdw6BI0g3m43iL4xKUVPWtG+qrrL9DTjpdn8eYuCQSRpow==}\\n236. \\n237.   \\'@changesets/get-dependents-graph@2.1.3\\':\\n238.     resolution: {integrity: sha512-gphr+v0mv2I3Oxt19VdWRRUxq3sseyUpX9DaHpTUmLj92Y10AGy+XOtV+kbM6L/fDcpx7/ISDFK6T8A/P3lOdQ==}\\n239. \\n240.   \\'@changesets/get-github-info@0.5.2\\':\\n241.     resolution: {integrity: sha512-JppheLu7S114aEs157fOZDjFqUDpm7eHdq5E8SSR0gUBTEK0cNSHsrSR5a66xs0z3RWuo46QvA3vawp8BxDHvg==}\\n242. \\n243.   \\'@changesets/get-release-plan@4.0.13\\':\\n244.     resolution: {integrity: sha512-DWG1pus72FcNeXkM12tx+xtExyH/c9I1z+2aXlObH3i9YA7+WZEVaiHzHl03thpvAgWTRaH64MpfHxozfF7Dvg==}\\n245. \\n246.   \\'@changesets/get-version-range-type@0.4.0\\':\\n247.     resolution: {integrity: sha512-hwawtob9DryoGTpixy1D3ZXbGgJu1Rhr+ySH2PvTLHvkZuQ7sRT4oQwMh0hbqZH1weAooedEjRsbrWcGLCeyVQ==}\\n248. \\n249.   \\'@changesets/git@3.0.4\\':\\n250.     resolution: {integrity: sha512-BXANzRFkX+XcC1q/d27NKvlJ1yf7PSAgi8JG6dt8EfbHFHi4neau7mufcSca5zRhwOL8j9s6EqsxmT+s+/E6Sw==}\\n251. \\n252.   \\'@changesets/logger@0.1.1\\':\\n253.     resolution: {integrity: sha512-OQtR36ZlnuTxKqoW4Sv6x5YIhOmClRd5pWsjZsddYxpWs517R0HkyiefQPIytCVh4ZcC5x9XaG8KTdd5iRQUfg==}\\n254. \\n255.   \\'@changesets/parse@0.4.1\\':\\n256.     resolution: {integrity: sha512-iwksMs5Bf/wUItfcg+OXrEpravm5rEd9Bf4oyIPL4kVTmJQ7PNDSd6MDYkpSJR1pn7tz/k8Zf2DhTCqX08Ou+Q==}\\n257. \\n258.   \\'@changesets/pre@2.0.2\\':\\n259.     resolution: {integrity: sha512-HaL/gEyFVvkf9KFg6484wR9s0qjAXlZ8qWPDkTyKF6+zqjBe/I2mygg3MbpZ++hdi0ToqNUF8cjj7fBy0dg8Ug==}\\n260. \\n261.   \\'@changesets/read@0.6.5\\':\\n262.     resolution: {integrity: sha512-UPzNGhsSjHD3Veb0xO/MwvasGe8eMyNrR/sT9gR8Q3DhOQZirgKhhXv/8hVsI0QpPjR004Z9iFxoJU6in3uGMg==}\\n263. \\n264.   \\'@changesets/should-skip-package@0.1.2\\':\\n265.     resolution: {integrity: sha512-qAK/WrqWLNCP22UDdBTMPH5f41elVDlsNyat180A33dWxuUDyNpg6fPi/FyTZwRriVjg0L8gnjJn2F9XAoF0qw==}\\n266. \\n267.   \\'@changesets/types@4.1.0\\':\\n268.     resolution: {integrity: sha512-LDQvVDv5Kb50ny2s25Fhm3d9QSZimsoUGBsUioj6MC3qbMUCuC8GPIvk/M6IvXx3lYhAs0lwWUQLb+VIEUCECw==}\\n269. \\n270.   \\'@changesets/types@6.1.0\\':\\n271.     resolution: {integrity: sha512-rKQcJ+o1nKNgeoYRHKOS07tAMNd3YSN0uHaJOZYjBAgxfV7TUE7JE+z4BzZdQwb5hKaYbayKN5KrYV7ODb2rAA==}\\n272. \\n273.   \\'@changesets/write@0.4.0\\':\\n274.     resolution: {integrity: sha512-CdTLvIOPiCNuH71pyDu3rA+Q0n65cmAbXnwWH84rKGiFumFzkmHNT8KHTMEchcxN+Kl8I54xGUhJ7l3E7X396Q==}\\n275. \\n276.   \\'@esbuild/aix-ppc64@0.21.5\\':\\n277.     resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}\\n278.     engines: {node: \\'>=12\\'}\\n279.     cpu: [ppc64]\\n280.     os: [aix]\\n281. \\n282.   \\'@esbuild/aix-ppc64@0.25.10\\':\\n283.     resolution: {integrity: sha512-0NFWnA+7l41irNuaSVlLfgNT12caWJVLzp5eAVhZ0z1qpxbockccEt3s+149rE64VUI3Ml2zt8Nv5JVc4QXTsw==}\\n284.     engines: {node: \\'>=18\\'}\\n285.     cpu: [ppc64]\\n286.     os: [aix]\\n287. \\n288.   \\'@esbuild/android-arm64@0.21.5\\':\\n289.     resolution: {integrity: sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==}\\n290.     engines: {node: \\'>=12\\'}\\n291.     cpu: [arm64]\\n292.     os: [android]\\n293. \\n294.   \\'@esbuild/android-arm64@0.25.10\\':\\n295.     resolution: {integrity: sha512-LSQa7eDahypv/VO6WKohZGPSJDq5OVOo3UoFR1E4t4Gj1W7zEQMUhI+lo81H+DtB+kP+tDgBp+M4oNCwp6kffg==}\\n296.     engines: {node: \\'>=18\\'}\\n297.     cpu: [arm64]\\n298.     os: [android]\\n299. \\n300.   \\'@esbuild/android-arm@0.21.5\\':\\n301.     resolution: {integrity: sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==}\\n302.     engines: {node: \\'>=12\\'}\\n303.     cpu: [arm]\\n304.     os: [android]\\n305. \\n306.   \\'@esbuild/android-arm@0.25.10\\':\\n307.     resolution: {integrity: sha512-dQAxF1dW1C3zpeCDc5KqIYuZ1tgAdRXNoZP7vkBIRtKZPYe2xVr/d3SkirklCHudW1B45tGiUlz2pUWDfbDD4w==}\\n308.     engines: {node: \\'>=18\\'}\\n309.     cpu: [arm]\\n310.     os: [android]\\n311. \\n312.   \\'@esbuild/android-x64@0.21.5\\':\\n313.     resolution: {integrity: sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==}\\n314.     engines: {node: \\'>=12\\'}\\n315.     cpu: [x64]\\n316.     os: [android]\\n317. \\n318.   \\'@esbuild/android-x64@0.25.10\\':\\n319.     resolution: {integrity: sha512-MiC9CWdPrfhibcXwr39p9ha1x0lZJ9KaVfvzA0Wxwz9ETX4v5CHfF09bx935nHlhi+MxhA63dKRRQLiVgSUtEg==}\\n320.     engines: {node: \\'>=18\\'}\\n321.     cpu: [x64]\\n322.     os: [android]\\n323. \\n324.   \\'@esbuild/darwin-arm64@0.21.5\\':\\n325.     resolution: {integrity: sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==}\\n326.     engines: {node: \\'>=12\\'}\\n327.     cpu: [arm64]\\n328.     os: [darwin]\\n329. \\n330.   \\'@esbuild/darwin-arm64@0.25.10\\':\\n331.     resolution: {integrity: sha512-JC74bdXcQEpW9KkV326WpZZjLguSZ3DfS8wrrvPMHgQOIEIG/sPXEN/V8IssoJhbefLRcRqw6RQH2NnpdprtMA==}\\n332.     engines: {node: \\'>=18\\'}\\n333.     cpu: [arm64]\\n334.     os: [darwin]\\n335. \\n336.   \\'@esbuild/darwin-x64@0.21.5\\':\\n337.     resolution: {integrity: sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==}\\n338.     engines: {node: \\'>=12\\'}\\n339.     cpu: [x64]\\n340.     os: [darwin]\\n341. \\n342.   \\'@esbuild/darwin-x64@0.25.10\\':\\n343.     resolution: {integrity: sha512-tguWg1olF6DGqzws97pKZ8G2L7Ig1vjDmGTwcTuYHbuU6TTjJe5FXbgs5C1BBzHbJ2bo1m3WkQDbWO2PvamRcg==}\\n344.     engines: {node: \\'>=18\\'}\\n345.     cpu: [x64]\\n346.     os: [darwin]\\n347. \\n348.   \\'@esbuild/freebsd-arm64@0.21.5\\':\\n349.     resolution: {integrity: sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==}\\n350.     engines: {node: \\'>=12\\'}\\n351.     cpu: [arm64]\\n352.     os: [freebsd]\\n353. \\n354.   \\'@esbuild/freebsd-arm64@0.25.10\\':\\n355.     resolution: {integrity: sha512-3ZioSQSg1HT2N05YxeJWYR+Libe3bREVSdWhEEgExWaDtyFbbXWb49QgPvFH8u03vUPX10JhJPcz7s9t9+boWg==}\\n356.     engines: {node: \\'>=18\\'}\\n357.     cpu: [arm64]\\n358.     os: [freebsd]\\n359. \\n360.   \\'@esbuild/freebsd-x64@0.21.5\\':\\n361.     resolution: {integrity: sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==}\\n362.     engines: {node: \\'>=12\\'}\\n363.     cpu: [x64]\\n364.     os: [freebsd]\\n365. \\n366.   \\'@esbuild/freebsd-x64@0.25.10\\':\\n367.     resolution: {integrity: sha512-LLgJfHJk014Aa4anGDbh8bmI5Lk+QidDmGzuC2D+vP7mv/GeSN+H39zOf7pN5N8p059FcOfs2bVlrRr4SK9WxA==}\\n368.     engines: {node: \\'>=18\\'}\\n369.     cpu: [x64]\\n370.     os: [freebsd]\\n371. \\n372.   \\'@esbuild/linux-arm64@0.21.5\\':\\n373.     resolution: {integrity: sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==}\\n374.     engines: {node: \\'>=12\\'}\\n375.     cpu: [arm64]\\n376.     os: [linux]\\n377. \\n378.   \\'@esbuild/linux-arm64@0.25.10\\':\\n379.     resolution: {integrity: sha512-5luJWN6YKBsawd5f9i4+c+geYiVEw20FVW5x0v1kEMWNq8UctFjDiMATBxLvmmHA4bf7F6hTRaJgtghFr9iziQ==}\\n380.     engines: {node: \\'>=18\\'}\\n381.     cpu: [arm64]\\n382.     os: [linux]\\n383. \\n384.   \\'@esbuild/linux-arm@0.21.5\\':\\n385.     resolution: {integrity: sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==}\\n386.     engines: {node: \\'>=12\\'}\\n387.     cpu: [arm]\\n388.     os: [linux]\\n389. \\n390.   \\'@esbuild/linux-arm@0.25.10\\':\\n391.     resolution: {integrity: sha512-oR31GtBTFYCqEBALI9r6WxoU/ZofZl962pouZRTEYECvNF/dtXKku8YXcJkhgK/beU+zedXfIzHijSRapJY3vg==}\\n392.     engines: {node: \\'>=18\\'}\\n393.     cpu: [arm]\\n394.     os: [linux]\\n395. \\n396.   \\'@esbuild/linux-ia32@0.21.5\\':\\n397.     resolution: {integrity: sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==}\\n398.     engines: {node: \\'>=12\\'}\\n399.     cpu: [ia32]\\n400.     os: [linux]\\n401. \\n402.   \\'@esbuild/linux-ia32@0.25.10\\':\\n403.     resolution: {integrity: sha512-NrSCx2Kim3EnnWgS4Txn0QGt0Xipoumb6z6sUtl5bOEZIVKhzfyp/Lyw4C1DIYvzeW/5mWYPBFJU3a/8Yr75DQ==}\\n404.     engines: {node: \\'>=18\\'}\\n405.     cpu: [ia32]\\n406.     os: [linux]\\n407. \\n408.   \\'@esbuild/linux-loong64@0.21.5\\':\\n409.     resolution: {integrity: sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==}\\n410.     engines: {node: \\'>=12\\'}\\n411.     cpu: [loong64]\\n412.     os: [linux]\\n413. \\n414.   \\'@esbuild/linux-loong64@0.25.10\\':\\n415.     resolution: {integrity: sha512-xoSphrd4AZda8+rUDDfD9J6FUMjrkTz8itpTITM4/xgerAZZcFW7Dv+sun7333IfKxGG8gAq+3NbfEMJfiY+Eg==}\\n416.     engines: {node: \\'>=18\\'}\\n417.     cpu: [loong64]\\n418.     os: [linux]\\n419. \\n420.   \\'@esbuild/linux-mips64el@0.21.5\\':\\n421.     resolution: {integrity: sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==}\\n422.     engines: {node: \\'>=12\\'}\\n423.     cpu: [mips64el]\\n424.     os: [linux]\\n425. \\n426.   \\'@esbuild/linux-mips64el@0.25.10\\':\\n427.     resolution: {integrity: sha512-ab6eiuCwoMmYDyTnyptoKkVS3k8fy/1Uvq7Dj5czXI6DF2GqD2ToInBI0SHOp5/X1BdZ26RKc5+qjQNGRBelRA==}\\n428.     engines: {node: \\'>=18\\'}\\n429.     cpu: [mips64el]\\n430.     os: [linux]\\n431. \\n432.   \\'@esbuild/linux-ppc64@0.21.5\\':\\n433.     resolution: {integrity: sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==}\\n434.     engines: {node: \\'>=12\\'}\\n435.     cpu: [ppc64]\\n436.     os: [linux]\\n437. \\n438.   \\'@esbuild/linux-ppc64@0.25.10\\':\\n439.     resolution: {integrity: sha512-NLinzzOgZQsGpsTkEbdJTCanwA5/wozN9dSgEl12haXJBzMTpssebuXR42bthOF3z7zXFWH1AmvWunUCkBE4EA==}\\n440.     engines: {node: \\'>=18\\'}\\n441.     cpu: [ppc64]\\n442.     os: [linux]\\n443. \\n444.   \\'@esbuild/linux-riscv64@0.21.5\\':\\n445.     resolution: {integrity: sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==}\\n446.     engines: {node: \\'>=12\\'}\\n447.     cpu: [riscv64]\\n448.     os: [linux]\\n449. \\n450.   \\'@esbuild/linux-riscv64@0.25.10\\':\\n451.     resolution: {integrity: sha512-FE557XdZDrtX8NMIeA8LBJX3dC2M8VGXwfrQWU7LB5SLOajfJIxmSdyL/gU1m64Zs9CBKvm4UAuBp5aJ8OgnrA==}\\n452.     engines: {node: \\'>=18\\'}\\n453.     cpu: [riscv64]\\n454.     os: [linux]\\n455. \\n456.   \\'@esbuild/linux-s390x@0.21.5\\':\\n457.     resolution: {integrity: sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==}\\n458.     engines: {node: \\'>=12\\'}\\n459.     cpu: [s390x]\\n460.     os: [linux]\\n461. \\n462.   \\'@esbuild/linux-s390x@0.25.10\\':\\n463.     resolution: {integrity: sha512-3BBSbgzuB9ajLoVZk0mGu+EHlBwkusRmeNYdqmznmMc9zGASFjSsxgkNsqmXugpPk00gJ0JNKh/97nxmjctdew==}\\n464.     engines: {node: \\'>=18\\'}\\n465.     cpu: [s390x]\\n466.     os: [linux]\\n467. \\n468.   \\'@esbuild/linux-x64@0.21.5\\':\\n469.     resolution: {integrity: sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==}\\n470.     engines: {node: \\'>=12\\'}\\n471.     cpu: [x64]\\n472.     os: [linux]\\n473. \\n474.   \\'@esbuild/linux-x64@0.25.10\\':\\n475.     resolution: {integrity: sha512-QSX81KhFoZGwenVyPoberggdW1nrQZSvfVDAIUXr3WqLRZGZqWk/P4T8p2SP+de2Sr5HPcvjhcJzEiulKgnxtA==}\\n476.     engines: {node: \\'>=18\\'}\\n477.     cpu: [x64]\\n478.     os: [linux]\\n479. \\n480.   \\'@esbuild/netbsd-arm64@0.25.10\\':\\n481.     resolution: {integrity: sha512-AKQM3gfYfSW8XRk8DdMCzaLUFB15dTrZfnX8WXQoOUpUBQ+NaAFCP1kPS/ykbbGYz7rxn0WS48/81l9hFl3u4A==}\\n482.     engines: {node: \\'>=18\\'}\\n483.     cpu: [arm64]\\n484.     os: [netbsd]\\n485. \\n486.   \\'@esbuild/netbsd-x64@0.21.5\\':\\n487.     resolution: {integrity: sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==}\\n488.     engines: {node: \\'>=12\\'}\\n489.     cpu: [x64]\\n490.     os: [netbsd]\\n491. \\n492.   \\'@esbuild/netbsd-x64@0.25.10\\':\\n493.     resolution: {integrity: sha512-7RTytDPGU6fek/hWuN9qQpeGPBZFfB4zZgcz2VK2Z5VpdUxEI8JKYsg3JfO0n/Z1E/6l05n0unDCNc4HnhQGig==}\\n494.     engines: {node: \\'>=18\\'}\\n495.     cpu: [x64]\\n496.     os: [netbsd]\\n497. \\n498.   \\'@esbuild/openbsd-arm64@0.25.10\\':\\n499.     resolution: {integrity: sha512-5Se0VM9Wtq797YFn+dLimf2Zx6McttsH2olUBsDml+lm0GOCRVebRWUvDtkY4BWYv/3NgzS8b/UM3jQNh5hYyw==}\\n500.     engines: {node: \\'>=18\\'}\\n501.     cpu: [arm64]\\n502.     os: [openbsd]\\n503. \\n504.   \\'@esbuild/openbsd-x64@0.21.5\\':\\n505.     resolution: {integrity: sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==}\\n506.     engines: {node: \\'>=12\\'}\\n507.     cpu: [x64]\\n508.     os: [openbsd]\\n509. \\n510.   \\'@esbuild/openbsd-x64@0.25.10\\':\\n511.     resolution: {integrity: sha512-XkA4frq1TLj4bEMB+2HnI0+4RnjbuGZfet2gs/LNs5Hc7D89ZQBHQ0gL2ND6Lzu1+QVkjp3x1gIcPKzRNP8bXw==}\\n512.     engines: {node: \\'>=18\\'}\\n513.     cpu: [x64]\\n514.     os: [openbsd]\\n515. \\n516.   \\'@esbuild/openharmony-arm64@0.25.10\\':\\n517.     resolution: {integrity: sha512-AVTSBhTX8Y/Fz6OmIVBip9tJzZEUcY8WLh7I59+upa5/GPhh2/aM6bvOMQySspnCCHvFi79kMtdJS1w0DXAeag==}\\n518.     engines: {node: \\'>=18\\'}\\n519.     cpu: [arm64]\\n520.     os: [openharmony]\\n521. \\n522.   \\'@esbuild/sunos-x64@0.21.5\\':\\n523.     resolution: {integrity: sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==}\\n524.     engines: {node: \\'>=12\\'}\\n525.     cpu: [x64]\\n526.     os: [sunos]\\n527. \\n528.   \\'@esbuild/sunos-x64@0.25.10\\':\\n529.     resolution: {integrity: sha512-fswk3XT0Uf2pGJmOpDB7yknqhVkJQkAQOcW/ccVOtfx05LkbWOaRAtn5SaqXypeKQra1QaEa841PgrSL9ubSPQ==}\\n530.     engines: {node: \\'>=18\\'}\\n531.     cpu: [x64]\\n532.     os: [sunos]\\n533. \\n534.   \\'@esbuild/win32-arm64@0.21.5\\':\\n535.     resolution: {integrity: sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==}\\n536.     engines: {node: \\'>=12\\'}\\n537.     cpu: [arm64]\\n538.     os: [win32]\\n539. \\n540.   \\'@esbuild/win32-arm64@0.25.10\\':\\n541.     resolution: {integrity: sha512-ah+9b59KDTSfpaCg6VdJoOQvKjI33nTaQr4UluQwW7aEwZQsbMCfTmfEO4VyewOxx4RaDT/xCy9ra2GPWmO7Kw==}\\n542.     engines: {node: \\'>=18\\'}\\n543.     cpu: [arm64]\\n544.     os: [win32]\\n545. \\n546.   \\'@esbuild/win32-ia32@0.21.5\\':\\n547.     resolution: {integrity: sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==}\\n548.     engines: {node: \\'>=12\\'}\\n549.     cpu: [ia32]\\n550.     os: [win32]\\n551. \\n552.   \\'@esbuild/win32-ia32@0.25.10\\':\\n553.     resolution: {integrity: sha512-QHPDbKkrGO8/cz9LKVnJU22HOi4pxZnZhhA2HYHez5Pz4JeffhDjf85E57Oyco163GnzNCVkZK0b/n4Y0UHcSw==}\\n554.     engines: {node: \\'>=18\\'}\\n555.     cpu: [ia32]\\n556.     os: [win32]\\n557. \\n558.   \\'@esbuild/win32-x64@0.21.5\\':\\n559.     resolution: {integrity: sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==}\\n560.     engines: {node: \\'>=12\\'}\\n561.     cpu: [x64]\\n562.     os: [win32]\\n563. \\n564.   \\'@esbuild/win32-x64@0.25.10\\':\\n565.     resolution: {integrity: sha512-9KpxSVFCu0iK1owoez6aC/s/EdUQLDN3adTxGCqxMVhrPDj6bt5dbrHDXUuq+Bs2vATFBBrQS5vdQ/Ed2P+nbw==}\\n566.     engines: {node: \\'>=18\\'}\\n567.     cpu: [x64]\\n568.     os: [win32]\\n569. \\n570.   \\'@eslint-community/eslint-utils@4.9.0\\':\\n571.     resolution: {integrity: sha512-ayVFHdtZ+hsq1t2Dy24wCmGXGe4q9Gu3smhLYALJrr473ZH27MsnSL+LKUlimp4BWJqMDMLmPpx/Q9R3OAlL4g==}\\n572.     engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\\n573.     peerDependencies:\\n574.       eslint: ^6.0.0 || ^7.0.0 || >=8.0.0\\n575. \\n576.   \\'@eslint-community/regexpp@4.12.1\\':\\n577.     resolution: {integrity: sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==}\\n578.     engines: {node: ^12.0.0 || ^14.0.0 || >=16.0.0}\\n579. \\n580.   \\'@eslint/config-array@0.18.0\\':\\n581.     resolution: {integrity: sha512-fTxvnS1sRMu3+JjXwJG0j/i4RT9u4qJ+lqS/yCGap4lH4zZGzQ7tu+xZqQmcMZq5OBZDL4QRxQzRjkWcGt8IVw==}\\n582.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n583. \\n584.   \\'@eslint/eslintrc@3.1.0\\':\\n585.     resolution: {integrity: sha512-4Bfj15dVJdoy3RfZmmo86RK1Fwzn6SstsvK9JS+BaVKqC6QQQQyXekNaC+g+LKNgkQ+2VhGAzm6hO40AhMR3zQ==}\\n586.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n587. \\n588.   \\'@eslint/js@9.9.1\\':\\n589.     resolution: {integrity: sha512-xIDQRsfg5hNBqHz04H1R3scSVwmI+KUbqjsQKHKQ1DAUSaUjYPReZZmS/5PNiKu1fUvzDd6H7DEDKACSEhu+TQ==}\\n590.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n591. \\n592.   \\'@eslint/object-schema@2.1.4\\':\\n593.     resolution: {integrity: sha512-BsWiH1yFGjXXS2yvrf5LyuoSIIbPrGUWob917o+BTKuZ7qJdxX8aJLRxs1fS9n6r7vESrq1OUqb68dANcFXuQQ==}\\n594.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n595. \\n596.   \\'@humanwhocodes/module-importer@1.0.1\\':\\n597.     resolution: {integrity: sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==}\\n598.     engines: {node: \\'>=12.22\\'}\\n599. \\n600.   \\'@humanwhocodes/retry@0.3.0\\':\\n601.     resolution: {integrity: sha512-d2CGZR2o7fS6sWB7DG/3a95bGKQyHMACZ5aW8qGkkqQpUoZV6C0X7Pc7l4ZNMZkfNBf4VWNe9E1jRsf0G146Ew==}\\n602.     engines: {node: \\'>=18.18\\'}\\n603. \\n604.   \\'@inquirer/external-editor@1.0.2\\':\\n605.     resolution: {integrity: sha512-yy9cOoBnx58TlsPrIxauKIFQTiyH+0MK4e97y4sV9ERbI+zDxw7i2hxHLCIEGIE/8PPvDxGhgzIOTSOWcs6/MQ==}\\n606.     engines: {node: \\'>=18\\'}\\n607.     peerDependencies:\\n608.       \\'@types/node\\': \\'>=18\\'\\n609.     peerDependenciesMeta:\\n610.       \\'@types/node\\':\\n611.         optional: true\\n612. \\n613.   \\'@isaacs/cliui@8.0.2\\':\\n614.     resolution: {integrity: sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==}\\n615.     engines: {node: \\'>=12\\'}\\n616. \\n617.   \\'@istanbuljs/schema@0.1.3\\':\\n618.     resolution: {integrity: sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==}\\n619.     engines: {node: \\'>=8\\'}\\n620. \\n621.   \\'@jridgewell/gen-mapping@0.3.5\\':\\n622.     resolution: {integrity: sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==}\\n623.     engines: {node: \\'>=6.0.0\\'}\\n624. \\n625.   \\'@jridgewell/remapping@2.3.4\\':\\n626.     resolution: {integrity: sha512-aG+WvAz17rhbzhKNkSeMLgbkPPK82ovXdONvmucbGhUqcroRFLLVhoGAk4xEI17gHpXgNX3sr0/B1ybRUsbEWw==}\\n627. \\n628.   \\'@jridgewell/resolve-uri@3.1.1\\':\\n629.     resolution: {integrity: sha512-dSYZh7HhCDtCKm4QakX0xFpsRDqjjtZf/kjI/v3T3Nwt5r8/qz/M19F9ySyOqU94SXBmeG9ttTul+YnR4LOxFA==}\\n630.     engines: {node: \\'>=6.0.0\\'}\\n631. \\n632.   \\'@jridgewell/set-array@1.2.1\\':\\n633.     resolution: {integrity: sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==}\\n634.     engines: {node: \\'>=6.0.0\\'}\\n635. \\n636.   \\'@jridgewell/source-map@0.3.6\\':\\n637.     resolution: {integrity: sha512-1ZJTZebgqllO79ue2bm3rIGud/bOe0pP5BjSRCRxxYkEZS8STV7zN84UBbiYu7jy+eCKSnVIUgoWWE/tt+shMQ==}\\n638. \\n639.   \\'@jridgewell/sourcemap-codec@1.5.0\\':\\n640.     resolution: {integrity: sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==}\\n641. \\n642.   \\'@jridgewell/trace-mapping@0.3.31\\':\\n643.     resolution: {integrity: sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==}\\n644. \\n645.   \\'@manypkg/find-root@1.1.0\\':\\n646.     resolution: {integrity: sha512-mki5uBvhHzO8kYYix/WRy2WX8S3B5wdVSc9D6KcU5lQNglP2yt58/VfLuAK49glRXChosY8ap2oJ1qgma3GUVA==}\\n647. \\n648.   \\'@manypkg/get-packages@1.1.3\\':\\n649.     resolution: {integrity: sha512-fo+QhuU3qE/2TQMQmbVMqaQ6EWbMhi4ABWP+O4AM1NqPBuy0OrApV5LO6BrrgnhtAHS2NH6RrVk9OL181tTi8A==}\\n650. \\n651.   \\'@nodelib/fs.scandir@2.1.5\\':\\n652.     resolution: {integrity: sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==}\\n653.     engines: {node: \\'>= 8\\'}\\n654. \\n655.   \\'@nodelib/fs.stat@2.0.5\\':\\n656.     resolution: {integrity: sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==}\\n657.     engines: {node: \\'>= 8\\'}\\n658. \\n659.   \\'@nodelib/fs.walk@1.2.8\\':\\n660.     resolution: {integrity: sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==}\\n661.     engines: {node: \\'>= 8\\'}\\n662. \\n663.   \\'@pkgjs/parseargs@0.11.0\\':\\n664.     resolution: {integrity: sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==}\\n665.     engines: {node: \\'>=14\\'}\\n666. \\n667.   \\'@playwright/test@1.46.1\\':\\n668.     resolution: {integrity: sha512-Fq6SwLujA/DOIvNC2EL/SojJnkKf/rAwJ//APpJJHRyMi1PdKrY3Az+4XNQ51N4RTbItbIByQ0jgd1tayq1aeA==}\\n669.     engines: {node: \\'>=18\\'}\\n670.     hasBin: true\\n671. \\n672.   \\'@polka/url@1.0.0-next.25\\':\\n673.     resolution: {integrity: sha512-j7P6Rgr3mmtdkeDGTe0E/aYyWEWVtc5yFXtHCRHs28/jptDEWfaVOc5T7cblqy1XKPPfCxJc/8DwQ5YgLOZOVQ==}\\n674. \\n675.   \\'@rollup/plugin-commonjs@28.0.1\\':\\n676.     resolution: {integrity: sha512-+tNWdlWKbpB3WgBN7ijjYkq9X5uhjmcvyjEght4NmH5fAU++zfQzAJ6wumLS+dNcvwEZhKx2Z+skY8m7v0wGSA==}\\n677.     engines: {node: \\'>=16.0.0 || 14 >= 14.17\\'}\\n678.     peerDependencies:\\n679.       rollup: ^2.68.0||^3.0.0||^4.0.0\\n680.     peerDependenciesMeta:\\n681.       rollup:\\n682.         optional: true\\n683. \\n684.   \\'@rollup/plugin-node-resolve@15.3.0\\':\\n685.     resolution: {integrity: sha512-9eO5McEICxMzJpDW9OnMYSv4Sta3hmt7VtBFz5zR9273suNOydOyq/FrGeGy+KsTRFm8w0SLVhzig2ILFT63Ag==}\\n686.     engines: {node: \\'>=14.0.0\\'}\\n687.     peerDependencies:\\n688.       rollup: ^2.78.0||^3.0.0||^4.0.0\\n689.     peerDependenciesMeta:\\n690.       rollup:\\n691.         optional: true\\n692. \\n693.   \\'@rollup/plugin-terser@0.4.4\\':\\n694.     resolution: {integrity: sha512-XHeJC5Bgvs8LfukDwWZp7yeqin6ns8RTl2B9avbejt6tZqsqvVoWI7ZTQrcNsfKEDWBTnTxM8nMDkO2IFFbd0A==}\\n695.     engines: {node: \\'>=14.0.0\\'}\\n696.     peerDependencies:\\n697.       rollup: ^2.0.0||^3.0.0||^4.0.0\\n698.     peerDependenciesMeta:\\n699.       rollup:\\n700.         optional: true\\n701. \\n702.   \\'@rollup/plugin-virtual@3.0.2\\':\\n703.     resolution: {integrity: sha512-10monEYsBp3scM4/ND4LNH5Rxvh3e/cVeL3jWTgZ2SrQ+BmUoQcopVQvnaMcOnykb1VkxUFuDAN+0FnpTFRy2A==}\\n704.     engines: {node: \\'>=14.0.0\\'}\\n705.     peerDependencies:\\n706.       rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\\n707.     peerDependenciesMeta:\\n708.       rollup:\\n709.         optional: true\\n710. \\n711.   \\'@rollup/pluginutils@5.1.0\\':\\n712.     resolution: {integrity: sha512-XTIWOPPcpvyKI6L1NHo0lFlCyznUEyPmPY1mc3KpPVDYulHSTvyeLNVW00QTLIAFNhR3kYnJTQHeGqU4M3n09g==}\\n713.     engines: {node: \\'>=14.0.0\\'}\\n714.     peerDependencies:\\n715.       rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\\n716.     peerDependenciesMeta:\\n717.       rollup:\\n718.         optional: true\\n719. \\n720.   \\'@rollup/rollup-android-arm-eabi@4.50.1\\':\\n721.     resolution: {integrity: sha512-HJXwzoZN4eYTdD8bVV22DN8gsPCAj3V20NHKOs8ezfXanGpmVPR7kalUHd+Y31IJp9stdB87VKPFbsGY3H/2ag==}\\n722.     cpu: [arm]\\n723.     os: [android]\\n724. \\n725.   \\'@rollup/rollup-android-arm64@4.50.1\\':\\n726.     resolution: {integrity: sha512-PZlsJVcjHfcH53mOImyt3bc97Ep3FJDXRpk9sMdGX0qgLmY0EIWxCag6EigerGhLVuL8lDVYNnSo8qnTElO4xw==}\\n727.     cpu: [arm64]\\n728.     os: [android]\\n729. \\n730.   \\'@rollup/rollup-darwin-arm64@4.50.1\\':\\n731.     resolution: {integrity: sha512-xc6i2AuWh++oGi4ylOFPmzJOEeAa2lJeGUGb4MudOtgfyyjr4UPNK+eEWTPLvmPJIY/pgw6ssFIox23SyrkkJw==}\\n732.     cpu: [arm64]\\n733.     os: [darwin]\\n734. \\n735.   \\'@rollup/rollup-darwin-x64@4.50.1\\':\\n736.     resolution: {integrity: sha512-2ofU89lEpDYhdLAbRdeyz/kX3Y2lpYc6ShRnDjY35bZhd2ipuDMDi6ZTQ9NIag94K28nFMofdnKeHR7BT0CATw==}\\n737.     cpu: [x64]\\n738.     os: [darwin]\\n739. \\n740.   \\'@rollup/rollup-freebsd-arm64@4.50.1\\':\\n741.     resolution: {integrity: sha512-wOsE6H2u6PxsHY/BeFHA4VGQN3KUJFZp7QJBmDYI983fgxq5Th8FDkVuERb2l9vDMs1D5XhOrhBrnqcEY6l8ZA==}\\n742.     cpu: [arm64]\\n743.     os: [freebsd]\\n744. \\n745.   \\'@rollup/rollup-freebsd-x64@4.50.1\\':\\n746.     resolution: {integrity: sha512-A/xeqaHTlKbQggxCqispFAcNjycpUEHP52mwMQZUNqDUJFFYtPHCXS1VAG29uMlDzIVr+i00tSFWFLivMcoIBQ==}\\n747.     cpu: [x64]\\n748.     os: [freebsd]\\n749. \\n750.   \\'@rollup/rollup-linux-arm-gnueabihf@4.50.1\\':\\n751.     resolution: {integrity: sha512-54v4okehwl5TaSIkpp97rAHGp7t3ghinRd/vyC1iXqXMfjYUTm7TfYmCzXDoHUPTTf36L8pr0E7YsD3CfB3ZDg==}\\n752.     cpu: [arm]\\n753.     os: [linux]\\n754. \\n755.   \\'@rollup/rollup-linux-arm-musleabihf@4.50.1\\':\\n756.     resolution: {integrity: sha512-p/LaFyajPN/0PUHjv8TNyxLiA7RwmDoVY3flXHPSzqrGcIp/c2FjwPPP5++u87DGHtw+5kSH5bCJz0mvXngYxw==}\\n757.     cpu: [arm]\\n758.     os: [linux]\\n759. \\n760.   \\'@rollup/rollup-linux-arm64-gnu@4.50.1\\':\\n761.     resolution: {integrity: sha512-2AbMhFFkTo6Ptna1zO7kAXXDLi7H9fGTbVaIq2AAYO7yzcAsuTNWPHhb2aTA6GPiP+JXh85Y8CiS54iZoj4opw==}\\n762.     cpu: [arm64]\\n763.     os: [linux]\\n764. \\n765.   \\'@rollup/rollup-linux-arm64-musl@4.50.1\\':\\n766.     resolution: {integrity: sha512-Cgef+5aZwuvesQNw9eX7g19FfKX5/pQRIyhoXLCiBOrWopjo7ycfB292TX9MDcDijiuIJlx1IzJz3IoCPfqs9w==}\\n767.     cpu: [arm64]\\n768.     os: [linux]\\n769. \\n770.   \\'@rollup/rollup-linux-loongarch64-gnu@4.50.1\\':\\n771.     resolution: {integrity: sha512-RPhTwWMzpYYrHrJAS7CmpdtHNKtt2Ueo+BlLBjfZEhYBhK00OsEqM08/7f+eohiF6poe0YRDDd8nAvwtE/Y62Q==}\\n772.     cpu: [loong64]\\n773.     os: [linux]\\n774. \\n775.   \\'@rollup/rollup-linux-ppc64-gnu@4.50.1\\':\\n776.     resolution: {integrity: sha512-eSGMVQw9iekut62O7eBdbiccRguuDgiPMsw++BVUg+1K7WjZXHOg/YOT9SWMzPZA+w98G+Fa1VqJgHZOHHnY0Q==}\\n777.     cpu: [ppc64]\\n778.     os: [linux]\\n779. \\n780.   \\'@rollup/rollup-linux-riscv64-gnu@4.50.1\\':\\n781.     resolution: {integrity: sha512-S208ojx8a4ciIPrLgazF6AgdcNJzQE4+S9rsmOmDJkusvctii+ZvEuIC4v/xFqzbuP8yDjn73oBlNDgF6YGSXQ==}\\n782.     cpu: [riscv64]\\n783.     os: [linux]\\n784. \\n785.   \\'@rollup/rollup-linux-riscv64-musl@4.50.1\\':\\n786.     resolution: {integrity: sha512-3Ag8Ls1ggqkGUvSZWYcdgFwriy2lWo+0QlYgEFra/5JGtAd6C5Hw59oojx1DeqcA2Wds2ayRgvJ4qxVTzCHgzg==}\\n787.     cpu: [riscv64]\\n788.     os: [linux]\\n789. \\n790.   \\'@rollup/rollup-linux-s390x-gnu@4.50.1\\':\\n791.     resolution: {integrity: sha512-t9YrKfaxCYe7l7ldFERE1BRg/4TATxIg+YieHQ966jwvo7ddHJxPj9cNFWLAzhkVsbBvNA4qTbPVNsZKBO4NSg==}\\n792.     cpu: [s390x]\\n793.     os: [linux]\\n794. \\n795.   \\'@rollup/rollup-linux-x64-gnu@4.50.1\\':\\n796.     resolution: {integrity: sha512-MCgtFB2+SVNuQmmjHf+wfI4CMxy3Tk8XjA5Z//A0AKD7QXUYFMQcns91K6dEHBvZPCnhJSyDWLApk40Iq/H3tA==}\\n797.     cpu: [x64]\\n798.     os: [linux]\\n799. \\n800.   \\'@rollup/rollup-linux-x64-musl@4.50.1\\':\\n801.     resolution: {integrity: sha512-nEvqG+0jeRmqaUMuwzlfMKwcIVffy/9KGbAGyoa26iu6eSngAYQ512bMXuqqPrlTyfqdlB9FVINs93j534UJrg==}\\n802.     cpu: [x64]\\n803.     os: [linux]\\n804. \\n805.   \\'@rollup/rollup-openharmony-arm64@4.50.1\\':\\n806.     resolution: {integrity: sha512-RDsLm+phmT3MJd9SNxA9MNuEAO/J2fhW8GXk62G/B4G7sLVumNFbRwDL6v5NrESb48k+QMqdGbHgEtfU0LCpbA==}\\n807.     cpu: [arm64]\\n808.     os: [openharmony]\\n809. \\n810.   \\'@rollup/rollup-win32-arm64-msvc@4.50.1\\':\\n811.     resolution: {integrity: sha512-hpZB/TImk2FlAFAIsoElM3tLzq57uxnGYwplg6WDyAxbYczSi8O2eQ+H2Lx74504rwKtZ3N2g4bCUkiamzS6TQ==}\\n812.     cpu: [arm64]\\n813.     os: [win32]\\n814. \\n815.   \\'@rollup/rollup-win32-ia32-msvc@4.50.1\\':\\n816.     resolution: {integrity: sha512-SXjv8JlbzKM0fTJidX4eVsH+Wmnp0/WcD8gJxIZyR6Gay5Qcsmdbi9zVtnbkGPG8v2vMR1AD06lGWy5FLMcG7A==}\\n817.     cpu: [ia32]\\n818.     os: [win32]\\n819. \\n820.   \\'@rollup/rollup-win32-x64-msvc@4.50.1\\':\\n821.     resolution: {integrity: sha512-StxAO/8ts62KZVRAm4JZYq9+NqNsV7RvimNK+YM7ry//zebEH6meuugqW/P5OFUCjyQgui+9fUxT6d5NShvMvA==}\\n822.     cpu: [x64]\\n823.     os: [win32]\\n824. \\n825.   \\'@stylistic/eslint-plugin-js@1.8.0\\':\\n826.     resolution: {integrity: sha512-jdvnzt+pZPg8TfclZlTZPiUbbima93ylvQ+wNgHLNmup3obY6heQvgewSu9i2CfS61BnRByv+F9fxQLPoNeHag==}\\n827.     engines: {node: ^16.0.0 || >=18.0.0}\\n828.     peerDependencies:\\n829.       eslint: \\'>=8.40.0\\'\\n830. \\n831.   \\'@sveltejs/acorn-typescript@1.0.5\\':\\n832.     resolution: {integrity: sha512-IwQk4yfwLdibDlrXVE04jTZYlLnwsTT2PIOQQGNLWfjavGifnk1JD1LcZjZaBTRcxZu2FfPfNLOE04DSu9lqtQ==}\\n833.     peerDependencies:\\n834.       acorn: ^8.9.0\\n835. \\n836.   \\'@sveltejs/eslint-config@8.3.3\\':\\n837.     resolution: {integrity: sha512-vkrQgEmhokFEOpuTo7NlVXJJMJJGNzxjmkQCTkHSwIOdzQSUukDIJ4038IjdcnIERSIlo4OpLAydWLx52BVyQA==}\\n838.     peerDependencies:\\n839.       \\'@stylistic/eslint-plugin-js\\': \\'>= 1\\'\\n840.       eslint: \\'>= 9\\'\\n841.       eslint-config-prettier: \\'>= 9\\'\\n842.       eslint-plugin-n: \\'>= 17\\'\\n843.       eslint-plugin-svelte: \\'>= 3\\'\\n844.       typescript: \\'>= 5\\'\\n845.       typescript-eslint: \\'>= 8\\'\\n846. \\n847.   \\'@sveltejs/vite-plugin-svelte-inspector@5.0.1\\':\\n848.     resolution: {integrity: sha512-ubWshlMk4bc8mkwWbg6vNvCeT7lGQojE3ijDh3QTR6Zr/R+GXxsGbyH4PExEPpiFmqPhYiVSVmHBjUcVc1JIrA==}\\n849.     engines: {node: ^20.19 || ^22.12 || >=24}\\n850.     peerDependencies:\\n851.       \\'@sveltejs/vite-plugin-svelte\\': ^6.0.0-next.0\\n852.       svelte: ^5.0.0\\n853.       vite: ^6.3.0 || ^7.0.0\\n854. \\n855.   \\'@sveltejs/vite-plugin-svelte@6.2.0\\':\\n856.     resolution: {integrity: sha512-nJsV36+o7rZUDlrnSduMNl11+RoDE1cKqOI0yUEBCcqFoAZOk47TwD3dPKS2WmRutke9StXnzsPBslY7prDM9w==}\\n857.     engines: {node: ^20.19 || ^22.12 || >=24}\\n858.     peerDependencies:\\n859.       svelte: ^5.0.0\\n860.       vite: ^6.3.0 || ^7.0.0\\n861. \\n862.   \\'@svitejs/changesets-changelog-github-compact@1.1.0\\':\\n863.     resolution: {integrity: sha512-qhUGGDHcpbY2zpjW3SwqchuW8J/5EzlPFud7xNntHKA7f3a/mx5+g+ruJKFHSAiVZYo30PALt+AyhmPUNKH/Og==}\\n864.     engines: {node: ^14.13.1 || ^16.0.0 || >=18}\\n865. \\n866.   \\'@types/aria-query@5.0.4\\':\\n867.     resolution: {integrity: sha512-rfT93uj5s0PRL7EzccGMs3brplhcrghnDoV26NqKhCAS1hVo+WdNsPvE/yb6ilfr5hi2MEk6d5EWJTKdxg8jVw==}\\n868. \\n869.   \\'@types/eslint@8.56.12\\':\\n870.     resolution: {integrity: sha512-03ruubjWyOHlmljCVoxSuNDdmfZDzsrrz0P2LeJsOXr+ZwFQ+0yQIwNCwt/GYhV7Z31fgtXJTAEs+FYlEL851g==}\\n871. \\n872.   \\'@types/estree@1.0.8\\':\\n873.     resolution: {integrity: sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==}\\n874. \\n875.   \\'@types/json-schema@7.0.15\\':\\n876.     resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}\\n877. \\n878.   \\'@types/node@12.20.55\\':\\n879.     resolution: {integrity: sha512-J8xLz7q2OFulZ2cyGTLE1TbbZcjpno7FaN6zdJNrgAdrJ+DZzh/uFR6YrTb4C+nXakvud8Q4+rbhoIWlYQbUFQ==}\\n880. \\n881.   \\'@types/node@20.19.17\\':\\n882.     resolution: {integrity: sha512-gfehUI8N1z92kygssiuWvLiwcbOB3IRktR6hTDgJlXMYh5OvkPSRmgfoBUmfZt+vhwJtX7v1Yw4KvvAf7c5QKQ==}\\n883. \\n884.   \\'@types/node@24.5.2\\':\\n885.     resolution: {integrity: sha512-FYxk1I7wPv3K2XBaoyH2cTnocQEu8AOZ60hPbsyukMPLv5/5qr7V1i8PLHdl6Zf87I+xZXFvPCXYjiTFq+YSDQ==}\\n886. \\n887.   \\'@types/picomatch@4.0.2\\':\\n888.     resolution: {integrity: sha512-qHHxQ+P9PysNEGbALT8f8YOSHW0KJu6l2xU8DYY0fu/EmGxXdVnuTLvFUvBgPJMSqXq29SYHveejeAha+4AYgA==}\\n889. \\n890.   \\'@types/resolve@1.20.2\\':\\n891.     resolution: {integrity: sha512-60BCwRFOZCQhDncwQdxxeOEEkbc5dIMccYLwbxsS4TUNeVECQ/pBJ0j09mrHOl/JJvpRPGwO9SvE4nR2Nb/a4Q==}\\n892. \\n893.   \\'@typescript-eslint/eslint-plugin@8.26.0\\':\\n894.     resolution: {integrity: sha512-cLr1J6pe56zjKYajK6SSSre6nl1Gj6xDp1TY0trpgPzjVbgDwd09v2Ws37LABxzkicmUjhEeg/fAUjPJJB1v5Q==}\\n895.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n896.     peerDependencies:\\n897.       \\'@typescript-eslint/parser\\': ^8.0.0 || ^8.0.0-alpha.0\\n898.       eslint: ^8.57.0 || ^9.0.0\\n899.       typescript: \\'>=4.8.4 <5.9.0\\'\\n900. \\n901.   \\'@typescript-eslint/parser@8.26.0\\':\\n902.     resolution: {integrity: sha512-mNtXP9LTVBy14ZF3o7JG69gRPBK/2QWtQd0j0oH26HcY/foyJJau6pNUez7QrM5UHnSvwlQcJXKsk0I99B9pOA==}\\n903.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n904.     peerDependencies:\\n905.       eslint: ^8.57.0 || ^9.0.0\\n906.       typescript: \\'>=4.8.4 <5.9.0\\'\\n907. \\n908.   \\'@typescript-eslint/project-service@8.43.0\\':\\n909.     resolution: {integrity: sha512-htB/+D/BIGoNTQYffZw4uM4NzzuolCoaA/BusuSIcC8YjmBYQioew5VUZAYdAETPjeed0hqCaW7EHg+Robq8uw==}\\n910.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n911.     peerDependencies:\\n912.       typescript: \\'>=4.8.4 <6.0.0\\'\\n913. \\n914.   \\'@typescript-eslint/scope-manager@8.26.0\\':\\n915.     resolution: {integrity: sha512-E0ntLvsfPqnPwng8b8y4OGuzh/iIOm2z8U3S9zic2TeMLW61u5IH2Q1wu0oSTkfrSzwbDJIB/Lm8O3//8BWMPA==}\\n916.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n917. \\n918.   \\'@typescript-eslint/scope-manager@8.43.0\\':\\n919.     resolution: {integrity: sha512-daSWlQ87ZhsjrbMLvpuuMAt3y4ba57AuvadcR7f3nl8eS3BjRc8L9VLxFLk92RL5xdXOg6IQ+qKjjqNEimGuAg==}\\n920.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n921. \\n922.   \\'@typescript-eslint/tsconfig-utils@8.43.0\\':\\n923.     resolution: {integrity: sha512-ALC2prjZcj2YqqL5X/bwWQmHA2em6/94GcbB/KKu5SX3EBDOsqztmmX1kMkvAJHzxk7TazKzJfFiEIagNV3qEA==}\\n924.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n925.     peerDependencies:\\n926.       typescript: \\'>=4.8.4 <6.0.0\\'\\n927. \\n928.   \\'@typescript-eslint/type-utils@8.26.0\\':\\n929.     resolution: {integrity: sha512-ruk0RNChLKz3zKGn2LwXuVoeBcUMh+jaqzN461uMMdxy5H9epZqIBtYj7UiPXRuOpaALXGbmRuZQhmwHhaS04Q==}\\n930.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n931.     peerDependencies:\\n932.       eslint: ^8.57.0 || ^9.0.0\\n933.       typescript: \\'>=4.8.4 <5.9.0\\'\\n934. \\n935.   \\'@typescript-eslint/types@8.26.0\\':\\n936.     resolution: {integrity: sha512-89B1eP3tnpr9A8L6PZlSjBvnJhWXtYfZhECqlBl1D9Lme9mHO6iWlsprBtVenQvY1HMhax1mWOjhtL3fh/u+pA==}\\n937.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n938. \\n939.   \\'@typescript-eslint/types@8.43.0\\':\\n940.     resolution: {integrity: sha512-vQ2FZaxJpydjSZJKiSW/LJsabFFvV7KgLC5DiLhkBcykhQj8iK9BOaDmQt74nnKdLvceM5xmhaTF+pLekrxEkw==}\\n941.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n942. \\n943.   \\'@typescript-eslint/typescript-estree@8.26.0\\':\\n944.     resolution: {integrity: sha512-tiJ1Hvy/V/oMVRTbEOIeemA2XoylimlDQ03CgPPNaHYZbpsc78Hmngnt+WXZfJX1pjQ711V7g0H7cSJThGYfPQ==}\\n945.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n946.     peerDependencies:\\n947.       typescript: \\'>=4.8.4 <5.9.0\\'\\n948. \\n949.   \\'@typescript-eslint/typescript-estree@8.43.0\\':\\n950.     resolution: {integrity: sha512-7Vv6zlAhPb+cvEpP06WXXy/ZByph9iL6BQRBDj4kmBsW98AqEeQHlj/13X+sZOrKSo9/rNKH4Ul4f6EICREFdw==}\\n951.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n952.     peerDependencies:\\n953.       typescript: \\'>=4.8.4 <6.0.0\\'\\n954. \\n955.   \\'@typescript-eslint/utils@8.26.0\\':\\n956.     resolution: {integrity: sha512-2L2tU3FVwhvU14LndnQCA2frYC8JnPDVKyQtWFPf8IYFMt/ykEN1bPolNhNbCVgOmdzTlWdusCTKA/9nKrf8Ig==}\\n957.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n958.     peerDependencies:\\n959.       eslint: ^8.57.0 || ^9.0.0\\n960.       typescript: \\'>=4.8.4 <5.9.0\\'\\n961. \\n962.   \\'@typescript-eslint/utils@8.43.0\\':\\n963.     resolution: {integrity: sha512-S1/tEmkUeeswxd0GGcnwuVQPFWo8NzZTOMxCvw8BX7OMxnNae+i8Tm7REQen/SwUIPoPqfKn7EaZ+YLpiB3k9g==}\\n964.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n965.     peerDependencies:\\n966.       eslint: ^8.57.0 || ^9.0.0\\n967.       typescript: \\'>=4.8.4 <6.0.0\\'\\n968. \\n969.   \\'@typescript-eslint/visitor-keys@8.26.0\\':\\n970.     resolution: {integrity: sha512-2z8JQJWAzPdDd51dRQ/oqIJxe99/hoLIqmf8RMCAJQtYDc535W/Jt2+RTP4bP0aKeBG1F65yjIZuczOXCmbWwg==}\\n971.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n972. \\n973.   \\'@typescript-eslint/visitor-keys@8.43.0\\':\\n974.     resolution: {integrity: sha512-T+S1KqRD4sg/bHfLwrpF/K3gQLBM1n7Rp7OjjikjTEssI2YJzQpi5WXoynOaQ93ERIuq3O8RBTOUYDKszUCEHw==}\\n975.     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\\n976. \\n977.   \\'@vitest/coverage-v8@2.1.9\\':\\n978.     resolution: {integrity: sha512-Z2cOr0ksM00MpEfyVE8KXIYPEcBFxdbLSs56L8PO0QQMxt/6bDj45uQfxoc96v05KW3clk7vvgP0qfDit9DmfQ==}\\n979.     peerDependencies:\\n980.       \\'@vitest/browser\\': 2.1.9\\n981.       vitest: 2.1.9\\n982.     peerDependenciesMeta:\\n983.       \\'@vitest/browser\\':\\n984.         optional: true\\n985. \\n986.   \\'@vitest/expect@2.1.9\\':\\n987.     resolution: {integrity: sha512-UJCIkTBenHeKT1TTlKMJWy1laZewsRIzYighyYiJKZreqtdxSos/S1t+ktRMQWu2CKqaarrkeszJx1cgC5tGZw==}\\n988. \\n989.   \\'@vitest/mocker@2.1.9\\':\\n990.     resolution: {integrity: sha512-tVL6uJgoUdi6icpxmdrn5YNo3g3Dxv+IHJBr0GXHaEdTcw3F+cPKnsXFhli6nO+f/6SDKPHEK1UN+k+TQv0Ehg==}\\n991.     peerDependencies:\\n992.       msw: ^2.4.9\\n993.       vite: ^5.0.0\\n994.     peerDependenciesMeta:\\n995.       msw:\\n996.         optional: true\\n997.       vite:\\n998.         optional: true\\n999. \\n1000.   \\'@vitest/pretty-format@2.1.9\\':\\n\\n\\nFile: pnpm-workspace.yaml\\nLine number range: 1 - 3\\nContent:\\n1. packages:\\n2.   - \\'packages/*\\'\\n3.   - \\'playgrounds/*\\'\\n\\n\\nFile: README.md\\nLine number range: 1 - 38\\nContent:\\n1. <a href=\"https://svelte.dev\">\\n2. \\t<picture>\\n3. \\t\\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/banner_dark.png\">\\n4. \\t\\t<img src=\"assets/banner.png\" alt=\"Svelte - web development for the rest of us\" />\\n5. \\t</picture>\\n6. </a>\\n7. \\n8. [![License](https://img.shields.io/npm/l/svelte.svg)](LICENSE.md) [![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\\n9. \\n10. ## What is Svelte?\\n11. \\n12. Svelte is a new way to build web applications. It\\'s a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\\n13. \\n14. Learn more at the [Svelte website](https://svelte.dev), or stop by the [Discord chatroom](https://svelte.dev/chat).\\n15. \\n16. ## Supporting Svelte\\n17. \\n18. Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you\\'d like to support their efforts, please consider:\\n19. \\n20. - [Becoming a backer on Open Collective](https://opencollective.com/svelte).\\n21. \\n22. Funds donated via Open Collective will be used for compensating expenses related to Svelte\\'s development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte\\'s development more directly.\\n23. \\n24. ## Roadmap\\n25. \\n26. You may view [our roadmap](https://svelte.dev/roadmap) if you\\'d like to see what we\\'re currently working on.\\n27. \\n28. ## Contributing\\n29. \\n30. Please see the [Contributing Guide](CONTRIBUTING.md) and the [`svelte`](packages/svelte) package for information on contributing to Svelte.\\n31. \\n32. ## Is svelte.dev down?\\n33. \\n34. Probably not, but it\\'s possible. If you can\\'t seem to access any `.dev` sites, check out [this SuperUser question and answer](https://superuser.com/q/1413402).\\n35. \\n36. ## License\\n37. \\n38. [MIT](LICENSE.md)\\n\\n\\n\\nNow generate a complete executable bash script that can successfully set up and configure the environment for this project, especially designed to run inside Docker containers. The bash script should:\\n1. Install the appropriate runtime and dependencies for the project\\'s technology stack\\n2. Install all necessary system packages and tools\\n3. Set up the project directory structure and permissions\\n4. Configure the runtime environment properly\\n5. Set up necessary environment variables and configurations\\n6. Follow bash scripting best practices for error handling and security\\n\\nMake sure the bash script is self-contained and can set up the project environment from scratch in a Docker container environment.\\n' additional_kwargs={} response_metadata={} id='f4f2a622-d2fa-4bb0-9224-bb2934c0f55d'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='```bash\\n#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is run as root\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y --no-install-recommends \\\\\\n        curl \\\\\\n        git \\\\\\n        ca-certificates \\\\\\n        build-essential \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-venv \\\\\\n        nodejs \\\\\\n        npm\\n    log \"System dependencies installed\"\\n}\\n\\n# Install pnpm\\ninstall_pnpm() {\\n    log \"Installing pnpm...\"\\n    npm install -g pnpm\\n    log \"pnpm installed\"\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod -R 755 /app\\n    log \"Project directory structure set up\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    cd /app\\n    if [ -f \"pnpm-lock.yaml\" ]; then\\n        pnpm install\\n    else\\n        error \"pnpm-lock.yaml not found. Ensure the file exists in the project directory.\"\\n        exit 1\\n    fi\\n    log \"Project dependencies installed\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime() {\\n    log \"Configuring runtime environment...\"\\n    export NODE_ENV=production\\n    export PATH=\"/app/node_modules/.bin:$PATH\"\\n    log \"Runtime environment configured\"\\n}\\n\\n# Set up environment variables\\nsetup_env_vars() {\\n    log \"Setting up environment variables...\"\\n    export PNPM_HOME=\"/root/.pnpm\"\\n    export PATH=\"$PNPM_HOME:$PATH\"\\n    log \"Environment variables set up\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_pnpm\\n    setup_project_structure\\n    install_project_deps\\n    configure_runtime\\n    setup_env_vars\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the project, navigate to /app and use the appropriate pnpm or npm commands.\"\\n}\\n\\n# Run main function\\nmain \"$@\"\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 613, 'prompt_tokens': 23062, 'total_tokens': 23675, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--2d3f777e-272b-4432-9de5-40af5960b635-0' usage_metadata={'input_tokens': 23062, 'output_tokens': 613, 'total_tokens': 23675, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_file_messages": [
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_fGz4mQUBtaIFSNvb1wIQ1si8', 'function': {'arguments': '{\"relative_path\":\"prometheus_setup.sh\",\"content\":\"#!/bin/bash\\\\n\\\\n# Exit immediately if a command exits with a non-zero status\\\\nset -e\\\\n\\\\n# Colors for output\\\\nRED=\\'\\\\\\\\033[0;31m\\'\\\\nGREEN=\\'\\\\\\\\033[0;32m\\'\\\\nYELLOW=\\'\\\\\\\\033[1;33m\\'\\\\nNC=\\'\\\\\\\\033[0m\\' # No Color\\\\n\\\\n# Logging functions\\\\nlog() {\\\\n    echo -e \\\\\"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\\\\\"\\\\n}\\\\n\\\\nerror() {\\\\n    echo -e \\\\\"${RED}[ERROR] $1${NC}\\\\\" >&2\\\\n}\\\\n\\\\nwarning() {\\\\n    echo -e \\\\\"${YELLOW}[WARNING] $1${NC}\\\\\"\\\\n}\\\\n\\\\n# Ensure the script is run as root\\\\nif [ \\\\\"$(id -u)\\\\\" -ne 0 ]; then\\\\n    error \\\\\"This script must be run as root\\\\\"\\\\n    exit 1\\\\nfi\\\\n\\\\n# Install system dependencies\\\\ninstall_system_deps() {\\\\n    log \\\\\"Installing system dependencies...\\\\\"\\\\n    apt-get update\\\\n    apt-get install -y --no-install-recommends \\\\\\\\\\\\n        curl \\\\\\\\\\\\n        git \\\\\\\\\\\\n        ca-certificates \\\\\\\\\\\\n        build-essential \\\\\\\\\\\\n        python3 \\\\\\\\\\\\n        python3-pip \\\\\\\\\\\\n        python3-venv \\\\\\\\\\\\n        nodejs \\\\\\\\\\\\n        npm\\\\n    log \\\\\"System dependencies installed\\\\\"\\\\n}\\\\n\\\\n# Install pnpm\\\\ninstall_pnpm() {\\\\n    log \\\\\"Installing pnpm...\\\\\"\\\\n    npm install -g pnpm\\\\n    log \\\\\"pnpm installed\\\\\"\\\\n}\\\\n\\\\n# Set up project directory structure\\\\nsetup_project_structure() {\\\\n    log \\\\\"Setting up project directory structure...\\\\\"\\\\n    mkdir -p /app\\\\n    chmod -R 755 /app\\\\n    log \\\\\"Project directory structure set up\\\\\"\\\\n}\\\\n\\\\n# Install project dependencies\\\\ninstall_project_deps() {\\\\n    log \\\\\"Installing project dependencies...\\\\\"\\\\n    cd /app\\\\n    if [ -f \\\\\"pnpm-lock.yaml\\\\\" ]; then\\\\n        pnpm install\\\\n    else\\\\n        error \\\\\"pnpm-lock.yaml not found. Ensure the file exists in the project directory.\\\\\"\\\\n        exit 1\\\\n    fi\\\\n    log \\\\\"Project dependencies installed\\\\\"\\\\n}\\\\n\\\\n# Configure runtime environment\\\\nconfigure_runtime() {\\\\n    log \\\\\"Configuring runtime environment...\\\\\"\\\\n    export NODE_ENV=production\\\\n    export PATH=\\\\\"/app/node_modules/.bin:$PATH\\\\\"\\\\n    log \\\\\"Runtime environment configured\\\\\"\\\\n}\\\\n\\\\n# Set up environment variables\\\\nsetup_env_vars() {\\\\n    log \\\\\"Setting up environment variables...\\\\\"\\\\n    export PNPM_HOME=\\\\\"/root/.pnpm\\\\\"\\\\n    export PATH=\\\\\"$PNPM_HOME:$PATH\\\\\"\\\\n    log \\\\\"Environment variables set up\\\\\"\\\\n}\\\\n\\\\n# Main setup function\\\\nmain() {\\\\n    log \\\\\"Starting project environment setup...\\\\\"\\\\n\\\\n    install_system_deps\\\\n    install_pnpm\\\\n    setup_project_structure\\\\n    install_project_deps\\\\n    configure_runtime\\\\n    setup_env_vars\\\\n\\\\n    log \\\\\"Project environment setup completed successfully!\\\\\"\\\\n    log \\\\\"To start the project, navigate to /app and use the appropriate pnpm or npm commands.\\\\\"\\\\n}\\\\n\\\\n# Run main function\\\\nmain \\\\\"$@\\\\\"\"}', 'name': 'create_file'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 731, 'prompt_tokens': 5314, 'total_tokens': 6045, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--b9e1593c-d030-424c-80b3-5befe43dceb7-0' tool_calls=[{'name': 'create_file', 'args': {'relative_path': 'prometheus_setup.sh', 'content': '#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is run as root\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y --no-install-recommends \\\\\\n        curl \\\\\\n        git \\\\\\n        ca-certificates \\\\\\n        build-essential \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-venv \\\\\\n        nodejs \\\\\\n        npm\\n    log \"System dependencies installed\"\\n}\\n\\n# Install pnpm\\ninstall_pnpm() {\\n    log \"Installing pnpm...\"\\n    npm install -g pnpm\\n    log \"pnpm installed\"\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod -R 755 /app\\n    log \"Project directory structure set up\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    cd /app\\n    if [ -f \"pnpm-lock.yaml\" ]; then\\n        pnpm install\\n    else\\n        error \"pnpm-lock.yaml not found. Ensure the file exists in the project directory.\"\\n        exit 1\\n    fi\\n    log \"Project dependencies installed\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime() {\\n    log \"Configuring runtime environment...\"\\n    export NODE_ENV=production\\n    export PATH=\"/app/node_modules/.bin:$PATH\"\\n    log \"Runtime environment configured\"\\n}\\n\\n# Set up environment variables\\nsetup_env_vars() {\\n    log \"Setting up environment variables...\"\\n    export PNPM_HOME=\"/root/.pnpm\"\\n    export PATH=\"$PNPM_HOME:$PATH\"\\n    log \"Environment variables set up\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_pnpm\\n    setup_project_structure\\n    install_project_deps\\n    configure_runtime\\n    setup_env_vars\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the project, navigate to /app and use the appropriate pnpm or npm commands.\"\\n}\\n\\n# Run main function\\nmain \"$@\"'}, 'id': 'call_fGz4mQUBtaIFSNvb1wIQ1si8', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5314, 'output_tokens': 731, 'total_tokens': 6045, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='The file prometheus_setup.sh has been created.' name='create_file' id='f8bc632e-551b-4748-aa8d-d9a76f375f73' tool_call_id='call_fGz4mQUBtaIFSNvb1wIQ1si8'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='The bash script has been saved as `prometheus_setup.sh` in the project root.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 6062, 'total_tokens': 6082, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6016}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--859b454c-e5ae-44bf-91dc-c898a80faa6a-0' usage_metadata={'input_tokens': 6062, 'output_tokens': 20, 'total_tokens': 6082, 'input_token_details': {'audio': 0, 'cache_read': 6016}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_execute_messages": [],
            "env_implement_bash_content": "diff --git a/prometheus.Dockerfile b/prometheus.Dockerfile\nnew file mode 100644\nindex 000000000..1616a7282\n--- /dev/null\n+++ b/prometheus.Dockerfile\n@@ -0,0 +1,22 @@\n+FROM ubuntu:24.04\n+\n+# Avoid timezone prompts during package installation\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV TZ=UTC\n+\n+# Set working directory\n+WORKDIR /app\n+\n+# Install essential build and development tools\n+RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     wget     python3     python3-pip     python3-dev     python3-venv     nodejs     npm     default-jdk     gcc     g++     gdb     postgresql-client     mysql-client     sqlite3     iputils-ping     vim     nano     zip     unzip     ca-certificates     gnupg     lsb-release\n+\n+RUN mkdir -p /etc/apt/keyrings     && curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg     && echo     \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu     $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n+\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+RUN apt-get clean\n+RUN rm -rf /var/lib/apt/lists/*\n+RUN ln -s /usr/bin/python3 /usr/bin/python\n+\n+# Copy project files\n+COPY . /app/\ndiff --git a/prometheus_setup.sh b/prometheus_setup.sh\nnew file mode 100644\nindex 000000000..d366caddf\n--- /dev/null\n+++ b/prometheus_setup.sh\n@@ -0,0 +1,108 @@\n+#!/bin/bash\n+\n+# Exit immediately if a command exits with a non-zero status\n+set -e\n+\n+# Colors for output\n+RED='\\033[0;31m'\n+GREEN='\\033[0;32m'\n+YELLOW='\\033[1;33m'\n+NC='\\033[0m' # No Color\n+\n+# Logging functions\n+log() {\n+    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n+}\n+\n+error() {\n+    echo -e \"${RED}[ERROR] $1${NC}\" >&2\n+}\n+\n+warning() {\n+    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n+}\n+\n+# Ensure the script is run as root\n+if [ \"$(id -u)\" -ne 0 ]; then\n+    error \"This script must be run as root\"\n+    exit 1\n+fi\n+\n+# Install system dependencies\n+install_system_deps() {\n+    log \"Installing system dependencies...\"\n+    apt-get update\n+    apt-get install -y --no-install-recommends \\\n+        curl \\\n+        git \\\n+        ca-certificates \\\n+        build-essential \\\n+        python3 \\\n+        python3-pip \\\n+        python3-venv \\\n+        nodejs \\\n+        npm\n+    log \"System dependencies installed\"\n+}\n+\n+# Install pnpm\n+install_pnpm() {\n+    log \"Installing pnpm...\"\n+    npm install -g pnpm\n+    log \"pnpm installed\"\n+}\n+\n+# Set up project directory structure\n+setup_project_structure() {\n+    log \"Setting up project directory structure...\"\n+    mkdir -p /app\n+    chmod -R 755 /app\n+    log \"Project directory structure set up\"\n+}\n+\n+# Install project dependencies\n+install_project_deps() {\n+    log \"Installing project dependencies...\"\n+    cd /app\n+    if [ -f \"pnpm-lock.yaml\" ]; then\n+        pnpm install\n+    else\n+        error \"pnpm-lock.yaml not found. Ensure the file exists in the project directory.\"\n+        exit 1\n+    fi\n+    log \"Project dependencies installed\"\n+}\n+\n+# Configure runtime environment\n+configure_runtime() {\n+    log \"Configuring runtime environment...\"\n+    export NODE_ENV=production\n+    export PATH=\"/app/node_modules/.bin:$PATH\"\n+    log \"Runtime environment configured\"\n+}\n+\n+# Set up environment variables\n+setup_env_vars() {\n+    log \"Setting up environment variables...\"\n+    export PNPM_HOME=\"/root/.pnpm\"\n+    export PATH=\"$PNPM_HOME:$PATH\"\n+    log \"Environment variables set up\"\n+}\n+\n+# Main setup function\n+main() {\n+    log \"Starting project environment setup...\"\n+\n+    install_system_deps\n+    install_pnpm\n+    setup_project_structure\n+    install_project_deps\n+    configure_runtime\n+    setup_env_vars\n+\n+    log \"Project environment setup completed successfully!\"\n+    log \"To start the project, navigate to /app and use the appropriate pnpm or npm commands.\"\n+}\n+\n+# Run main function\n+main \"$@\"\n\\ No newline at end of file\ndiff --git a/prometheus_testsuite_commands.txt b/prometheus_testsuite_commands.txt\nnew file mode 100644\nindex 000000000..ce40e1e9a\n--- /dev/null\n+++ b/prometheus_testsuite_commands.txt\n@@ -0,0 +1 @@\n+npx sv --version\n",
            "env_implement_bash_path": "prometheus_setup.sh"
        },
        "timestamp": "2025-10-18T10:11:40.652780"
    },
    "prettier": {
        "project_name": "prettier",
        "project_repo_url": "https://github.com/prettier/prettier",
        "success": true,
        "playground_path": "/tmp/tmpusvu4sru/prettier",
        "container_info": null,
        "testsuite_states": {
            "testsuite_max_refined_query_loop": 4,
            "testsuite_context_provider_messages": [
                {
                    "type": "SystemMessage",
                    "content": "content=\"You are to discover ONE minimal, safe, and quick verification shell command from README/docs to confirm the environment/setup works (e.g., '<tool> --version', '<package> --help', 'make check', 'pytest -q'). Avoid destructive or long-running commands.\" additional_kwargs={} response_metadata={} id='5e2a5d49-1d31-4c97-b1c9-7fdd2605fff8'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Find one quick verification command from README/docs for this repository.' additional_kwargs={} response_metadata={} id='ea6c246e-3254-4e1f-b2f3-e4854d8bf649'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_CB91k6gZNy3VRnUYqxqxbDLt', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 72497, 'total_tokens': 72517, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--7733f48c-72d1-48cb-ac8b-0c8162e14aa9-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_CB91k6gZNy3VRnUYqxqxbDLt', 'type': 'tool_call'}] usage_metadata={'input_tokens': 72497, 'output_tokens': 20, 'total_tokens': 72517, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3569478}\\npreview: [![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'website/README.md\\', \\'node_id\\': 3569494}\\npreview: # Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site\\'s source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/release/README.md\\', \\'node_id\\': 3693195}\\npreview: # Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root\\'s `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React\\'s release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/build/README.md\\', \\'node_id\\': 3696619}\\npreview: # Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-oxc/README.md\\', \\'node_id\\': 3699293}\\npreview: # @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-hermes/README.md\\', \\'node_id\\': 3699394}\\npreview: # @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```' name='preview_file_content_with_basename' id='99d03908-efc5-43ec-8eb6-4b18fb915108' tool_call_id='call_CB91k6gZNy3VRnUYqxqxbDLt' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3569478}, 'preview': '[![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'website/README.md', 'node_id': 3569494}, 'preview': \"# Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site's source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/release/README.md', 'node_id': 3693195}, 'preview': \"# Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root's `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React's release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/build/README.md', 'node_id': 3696619}, 'preview': '# Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-oxc/README.md', 'node_id': 3699293}, 'preview': '# @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-hermes/README.md', 'node_id': 3699394}, 'preview': '# @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_A2EKRVoPe9TmLrbO6RNhGeNe', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 72497, 'total_tokens': 72517, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 72448}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f3e659d5-8a2b-4496-903b-c8aef3b73981-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_A2EKRVoPe9TmLrbO6RNhGeNe', 'type': 'tool_call'}] usage_metadata={'input_tokens': 72497, 'output_tokens': 20, 'total_tokens': 72517, 'input_token_details': {'audio': 0, 'cache_read': 72448}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3569478}\\npreview: [![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'website/README.md\\', \\'node_id\\': 3569494}\\npreview: # Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site\\'s source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/release/README.md\\', \\'node_id\\': 3693195}\\npreview: # Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root\\'s `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React\\'s release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/build/README.md\\', \\'node_id\\': 3696619}\\npreview: # Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-oxc/README.md\\', \\'node_id\\': 3699293}\\npreview: # @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-hermes/README.md\\', \\'node_id\\': 3699394}\\npreview: # @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```' name='preview_file_content_with_basename' id='3186985b-cbd9-41ca-bff4-fe0bcf2577fa' tool_call_id='call_A2EKRVoPe9TmLrbO6RNhGeNe' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3569478}, 'preview': '[![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'website/README.md', 'node_id': 3569494}, 'preview': \"# Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site's source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/release/README.md', 'node_id': 3693195}, 'preview': \"# Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root's `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React's release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/build/README.md', 'node_id': 3696619}, 'preview': '# Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-oxc/README.md', 'node_id': 3699293}, 'preview': '# @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-hermes/README.md', 'node_id': 3699394}, 'preview': '# @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_pZRJD3KGsiztorifbRbDfikv', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 72497, 'total_tokens': 72517, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 72448}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--70223d6a-fff2-4371-b127-0dbb67b15415-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_pZRJD3KGsiztorifbRbDfikv', 'type': 'tool_call'}] usage_metadata={'input_tokens': 72497, 'output_tokens': 20, 'total_tokens': 72517, 'input_token_details': {'audio': 0, 'cache_read': 72448}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3569478}\\npreview: [![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'website/README.md\\', \\'node_id\\': 3569494}\\npreview: # Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site\\'s source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/release/README.md\\', \\'node_id\\': 3693195}\\npreview: # Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root\\'s `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React\\'s release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'scripts/build/README.md\\', \\'node_id\\': 3696619}\\npreview: # Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-oxc/README.md\\', \\'node_id\\': 3699293}\\npreview: # @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'packages/plugin-hermes/README.md\\', \\'node_id\\': 3699394}\\npreview: # @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```' name='preview_file_content_with_basename' id='b3e38063-0354-47bb-ad7d-5aea40f775a0' tool_call_id='call_pZRJD3KGsiztorifbRbDfikv' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3569478}, 'preview': '[![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n\\n<h2 align=\"center\">Opinionated Code Formatter</h2>\\n\\n<p align=\"center\">\\n  <em>\\n    JavaScript\\n    · TypeScript\\n    · Flow\\n    · JSX\\n    · JSON\\n  </em>\\n  <br />\\n  <em>\\n    CSS\\n    · SCSS\\n    · Less\\n  </em>\\n  <br />\\n  <em>\\n    HTML\\n    · Vue\\n    · Angular\\n  </em>\\n  <br />\\n  <em>\\n    GraphQL\\n    · Markdown\\n    · YAML\\n  </em>\\n  <br />\\n  <em>\\n    <a href=\"https://prettier.io/docs/plugins\">\\n      Your favorite language?\\n    </a>\\n  </em>\\n</p>\\n\\n<p align=\"center\">\\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n  <br/>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://www.npmjs.com/package/prettier\">\\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n  <a href=\"https://github.com/prettier/prettier#badge\">\\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n</p>\\n\\n## Intro\\n\\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n\\n### Input\\n\\n<!-- prettier-ignore -->\\n```js\\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n```\\n\\n### Output\\n\\n```js\\nfoo(\\n  reallyLongArg(),\\n  omgSoManyParameters(),\\n  IShouldRefactorThis(),\\n  isThereSeriouslyAnotherOne(),\\n);\\n```\\n\\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n\\n---\\n\\n**[Documentation](https://prettier.io/docs/)**\\n\\n[Install](https://prettier.io/docs/install) ·\\n[Options](https://prettier.io/docs/options) ·\\n[CLI](https://prettier.io/docs/cli) ·\\n[API](https://prettier.io/docs/api)\\n\\n**[Playground](https://prettier.io/playground/)**\\n\\n---\\n\\n## Badge\\n\\nShow the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n\\n```md\\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n```\\n\\n## Contributing\\n\\nSee [CONTRIBUTING.md](CONTRIBUTING.md).'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'website/README.md', 'node_id': 3569494}, 'preview': \"# Prettier Website\\n\\nhttps://prettier.io/\\n\\n## Getting started\\n\\n1. Build the Prettier browser libs for the Playground by running the following in the project root directory:\\n\\n   ```sh\\n   cd your/path/to/prettier\\n   yarn build:website\\n   ```\\n\\n   To build for the current branch, use `yarn build:website:pr`. Otherwise, a release version of Prettier from `node_modules` is used.\\n\\n2. Switch to the `website` directory and start the development server:\\n\\n   ```sh\\n   cd website\\n   yarn start\\n   ```\\n\\n   This starts a server hosting the website locally at `http://localhost:3000/`. Any changes to the site's source files are reflected after refreshing the page, i.e. the server does not need to be restarted to show changes.\\n\\n   When working on the docs, you need to go to `http://localhost:3000/docs/next/index.html` (note “next”) to see your changes.\\n\\n## Docusaurus\\n\\nThe site is built on [Docusaurus](https://docusaurus.io/), a static site generator for documentation sites.\\n\\nIts main configuration file is `docusaurus.config.js` ([docs](https://docusaurus.io/docs/configuration)).\\n\\nPages can be added to the site by putting `.jsx` files with React components in `src/pages/`. It’s also possible to include `.md` files directly. ([docs](https://docusaurus.io/docs/creating-pages))\\n\\nImages and other static assets are placed inside the `static` directory: `static/img/your-image.png` is mapped to `http://prettier.io/img/your-image.png`. Any `.css` files in `static/` are concatenated to the standard styles provided by Docusaurus and used site-wide.\\n\\n## Playground\\n\\nThe Playground is not integrated with the Docusaurus infrastructure. Its UI (`website/playground/`) is built separately with webpack configured to put the resulting bundle in Docusaurus’s `static` directory. The `yarn start` command (in `website/`) concurrently starts both Docusaurus’s local server and webpack in the watch mode for the Playground.\\n\\nThe entry point of the playground is at `static/playground/index.html`.\\n\\nAnother part of the Playground is a web worker where formatting happens. It’s not managed by webpack and resides directly in `static/worker.mjs`. It expects to find the [UMD bundles of Prettier](https://prettier.io/docs/browser) in `static/lib/`. That’s why running `yarn build:website` or `PULL_REQUEST=true yarn build:website` in the project root is a required step.\\n\\nFinally, there is a service worker that caches Prettier’s relatively heavy bundles (`static/service-worker.mjs`).\\n\\n## Documentation\\n\\nIn the project repo, the `docs` directory is used to hold documentation written in Markdown.\\nThe front matter of documentation files should follow this example:\\n\\n```yaml\\nid: doc1 # used for docs to find each other and to map links\\ntitle: Document Title\\nlayout: docs1 # used to determine different sidebar groupings\\ncategory: Sidebar Category 1 # Category on the sidebar under which this doc goes\\npermalink: docs/doc1.html # link to the document that is used for site\\nprevious: doc0 # previous doc on sidebar for navigation\\nnext: doc2 # next doc on the sidebar for navigation\\n# don’t include next if this is the last doc; don’t include previous if first doc\\n---\\n```\\n\\nThe docs from `docs/` are published to `https://prettier.io/docs/next/` and are considered to be the docs of the next (not yet released) version of Prettier. When a release happens, the docs from `docs/` are copied to the `website/versioned_docs/version-stable` directory, whose content is published to `https://prettier.io/docs/`.\\n\\n## Blog\\n\\nThe `website/blog` directory contains blog posts written in Markdown. Their front matter should follow this example:\\n\\n```yaml\\ntitle: Blog Post Title\\nauthors: author declared in `blog/authors.yml`\\n---\\n```\\n\\nIn the blog post, you should include a line `<!-- truncate -->`. This determines under which point text will be ignored when generating the preview of your blog post. Blog posts should have the file name format: `yyyy-mm-dd-your-file-name.md`.\\n\\n## Static Build\\n\\nTo create a static build of the website, run `yarn build` (in `website/`). The result will be put in `website/build/`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/release/README.md', 'node_id': 3693195}, 'preview': \"# Release script\\n\\n## Usage\\n\\n```sh\\nnode ./scripts/release/release.js\\n```\\n\\nThe script has its own `package.json` so we can reinstall the root's `node_modules/` while making the release.\\n\\n## Flags\\n\\n| Flag                          | Description                                                                             |\\n| ----------------------------- | --------------------------------------------------------------------------------------- |\\n| `--version`                   | Version to release                                                                      |\\n| `--manual`                    | Manual run release process instead of publish from GitHub actions                       |\\n| `--dry`                       | Dry run                                                                                 |\\n| `--skip-dependencies-install` | Skip dependencies installation                                                          |\\n| `--next`                      | Pre-release such as alpha and beta. It must be run on the `next` branch or it will fail |\\n\\n## Credits\\n\\nThis script was inspired by [React's release script](https://github.com/facebook/react/tree/001f9ef/scripts/release).\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'scripts/build/README.md', 'node_id': 3696619}, 'preview': '# Prettier Build Script\\n\\n## Requirements\\n\\n- Node.js version `>= 16.16`.\\n\\n## Usage\\n\\n```sh\\nyarn build\\n```\\n\\n## Flags\\n\\n### `--package`\\n\\nWhat package to build, will build all packages if omitted.\\n\\n```\\nyarn build\\nyarn build --package prettier\\nyarn build --package prettier --package @prettier/plugin-oxc\\n```\\n\\n### `--clean`\\n\\nRemove `dist` directory before bundle files.\\n\\n```sh\\nyarn build --clean\\n```\\n\\n### `--playground`\\n\\nRun script with `--playground` flag will only build files needed for the website.\\n\\n```sh\\nyarn build --playground\\n```\\n\\n### `--print-size`\\n\\nTo print the bundled file sizes:\\n\\n```sh\\nyarn build --print-size\\n```\\n\\n### `--compare-size`\\n\\nPrint the file size changes compare to the last released version:\\n\\n```sh\\nyarn build --compare-size\\n```\\n\\n### `--file`\\n\\nTo build specific file(s):\\n\\n```sh\\nyarn build --file=esm/parser-babel.mjs\\n```\\n\\n```sh\\nyarn build --file=standalone.js --file=parser-meriyah.js\\n```\\n\\n### `--save-as`\\n\\nTo save bundled file to a different location, this flag can only use together with ONE `--file` flag\\n\\n```sh\\nyarn build --file=parser-babel.js --save-as=babel-for-test.js\\n```\\n\\n### `--report`\\n\\nVisualize and analyze your esbuild bundle to see which modules are taking up space.\\n\\nAvailable reporter formats:\\n\\n- `html` Generate a HTML report file, saved next to the bundled file with `.report.html` suffix.\\n- `text` Generate a plain text report file, saved next to the bundled file with `.report.txt` suffix.\\n- `stdout` Log report information in console.\\n\\n```sh\\nyarn build --report=all\\nyarn build --report=stdout --report=text --report=html\\n```\\n\\n### `--minify` and `--no-minify`\\n\\nBy default, the file minification is controlled by `config.mjs` and `bundler.mjs`, these flags are added to override that behavior.\\n\\nThese should only be used for debugging purposes, suggest to use them together with the `--file` flag.\\n\\nForce minify files:\\n\\n```sh\\nyarn build --file=index.js --minify\\n```\\n\\nDisable minify files:\\n\\n```sh\\nyarn build --file=parser-babel.js --no-minify\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-oxc/README.md', 'node_id': 3699293}, 'preview': '# @prettier/plugin-oxc\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-oxc.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-oxc)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-oxc.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Oxc](https://oxc.rs/) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-oxc\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-oxc\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js,mjs,cjs,jsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc\\n  - files:\\n      - \"**/*.{ts,mts,cts,tsx}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-oxc\"\\n      parser: oxc-ts\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'packages/plugin-hermes/README.md', 'node_id': 3699394}, 'preview': '# @prettier/plugin-hermes\\n\\n[![Npm Version](https://img.shields.io/npm/v/@prettier/plugin-hermes.svg?style=flat-square)](https://www.npmjs.com/package/@prettier/plugin-hermes)\\n[![MIT License](https://img.shields.io/npm/l/@prettier/plugin-hermes.svg?style=flat-square)](https://github.com/prettier/prettier/blob/main/license)\\n\\n> Prettier [Hermes](https://github.com/facebook/hermes/blob/main/README.md) plugin.\\n\\n## Install\\n\\n```bash\\nyarn add --dev prettier @prettier/plugin-hermes\\n```\\n\\n## Usage\\n\\nCreate or modify your [prettier configuration file](https://prettier.io/docs/en/configuration) to use the plugin:\\n\\n```yaml\\nplugins:\\n  - \"@prettier/plugin-hermes\"\\n```\\n\\n**Requires prettier >= 3.6**\\n\\nOr config explicitly\\n\\n```yaml\\noverrides:\\n  - files:\\n      - \"**/*.{js.flow,js,mjs,cjs}\"\\n    options:\\n      plugins:\\n        - \"@prettier/plugin-hermes\"\\n      parser: hermes\\n```'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search README.md and docs/install.md for a quick verification command, such as a version check or help command.' additional_kwargs={} response_metadata={} id='4836e9ba-f750-4278-a750-01886ada1337'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "testsuite_refined_query": "Search README.md and docs/install.md for a quick verification command, such as a version check or help command.",
            "testsuite_command": [
                "prettier --version",
                "prettier --help",
                "yarn build:website --help",
                "yarn start --help",
                "yarn build --help",
                "node ./scripts/release/release.js --version",
                "node ./scripts/release/release.js --help",
                "node --version",
                "yarn --version"
            ]
        },
        "env_states": {
            "max_refined_query_loop": 3,
            "env_implement_file_context_query": "OBJECTIVE: Find the most relevant environment configuration files that can help generate an accurate Dockerfile for this project,\nincluding Dockerfiles, dependency files, build configurations, and environment setup files.\n\n<reasoning>\n1. Analyze project characteristics:\n   - Programming language and framework\n   - Dependency management files\n   - Build system and tools\n   - Runtime requirements\n   - Environment configurations\n\n2. Search requirements:\n   - Existing Dockerfiles or containerization files\n   - Dependency files (requirements.txt, package.json, pom.xml, etc.)\n   - Build configuration files (Makefile, CMakeLists.txt, etc.)\n   - Environment configuration files (.env, config files)\n   - Setup and installation scripts\n\n3. Focus areas:\n   - Docker-related files (Dockerfile, docker-compose.yml, .dockerignore)\n   - Package management files (requirements.txt, package.json, go.mod, Cargo.toml, etc.)\n   - Build system files (Makefile, CMakeLists.txt, build.gradle, etc.)\n   - Environment configuration (.env, config.json, application.properties, etc.)\n   - Setup documentation (README.md, INSTALL.md, SETUP.md)\n   - CI/CD configuration files\n</reasoning>\n\nREQUIREMENTS:\n- Return the most relevant environment configuration files for Dockerfile generation\n- Must include complete file content with exact file paths and line numbers\n- Must include dependency files, build configurations, and environment setups\n- Must include any existing Docker-related files\n- Must include setup documentation and installation instructions\n\n<examples>\n<example id=\"python-web-app\">\n<project_context>\nPython Flask web application with requirements.txt\n</project_context>\n\n<ideal_files>\n# File: requirements.txt\nFlask==2.3.3\ngunicorn==21.2.0\npsycopg2-binary==2.9.7\nredis==4.6.0\n\n# File: app.py\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    return 'Hello World!'\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n\n# File: README.md\n## Installation\npip install -r requirements.txt\npython app.py\n</ideal_files>\n</example>\n\n<example id=\"nodejs-api\">\n<project_context>\nNode.js Express API with package.json\n</project_context>\n\n<ideal_files>\n# File: package.json\n{\n  \"name\": \"my-api\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^7.5.0\"\n  }\n}\n\n# File: server.js\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\napp.get('/', (req, res) => {\n  res.json({ message: 'API is running' });\n});\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});\n</ideal_files>\n</example>\n\nSearch priority:\n1. Existing Dockerfiles or containerization files\n2. Dependency management files (requirements.txt, package.json, etc.)\n3. Build configuration files (Makefile, CMakeLists.txt, etc.)\n4. Environment configuration files (.env, config files)\n5. Setup documentation and installation instructions\n\nFind the most relevant environment configuration files with complete context for Dockerfile generation.\n",
            "env_implement_file_context": [
                {
                    "type": "Context",
                    "content": "File: README.md\nLine number range: 1 - 104\nContent:\n1. [![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\n2. \n3. <h2 align=\"center\">Opinionated Code Formatter</h2>\n4. \n5. <p align=\"center\">\n6.   <em>\n7.     JavaScript\n8.     · TypeScript\n9.     · Flow\n10.     · JSX\n11.     · JSON\n12.   </em>\n13.   <br />\n14.   <em>\n15.     CSS\n16.     · SCSS\n17.     · Less\n18.   </em>\n19.   <br />\n20.   <em>\n21.     HTML\n22.     · Vue\n23.     · Angular\n24.   </em>\n25.   <br />\n26.   <em>\n27.     GraphQL\n28.     · Markdown\n29.     · YAML\n30.   </em>\n31.   <br />\n32.   <em>\n33.     <a href=\"https://prettier.io/docs/plugins\">\n34.       Your favorite language?\n35.     </a>\n36.   </em>\n37. </p>\n38. \n39. <p align=\"center\">\n40.   <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\n41.     <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\n42.   <a href=\"https://codecov.io/gh/prettier/prettier\">\n43.     <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\n44.   <a href=\"https://x.com/acdlite/status/974390255393505280\">\n45.     <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\n46.   <br/>\n47.   <a href=\"https://www.npmjs.com/package/prettier\">\n48.     <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\n49.   <a href=\"https://www.npmjs.com/package/prettier\">\n50.     <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\n51.   <a href=\"https://github.com/prettier/prettier#badge\">\n52.     <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\n53.   <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\n54.     <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\n55. </p>\n56. \n57. ## Intro\n58. \n59. Prettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\n60. \n61. ### Input\n62. \n63. <!-- prettier-ignore -->\n64. ```js\n65. foo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\n66. ```\n67. \n68. ### Output\n69. \n70. ```js\n71. foo(\n72.   reallyLongArg(),\n73.   omgSoManyParameters(),\n74.   IShouldRefactorThis(),\n75.   isThereSeriouslyAnotherOne(),\n76. );\n77. ```\n78. \n79. Prettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\n80. \n81. ---\n82. \n83. **[Documentation](https://prettier.io/docs/)**\n84. \n85. [Install](https://prettier.io/docs/install) ·\n86. [Options](https://prettier.io/docs/options) ·\n87. [CLI](https://prettier.io/docs/cli) ·\n88. [API](https://prettier.io/docs/api)\n89. \n90. **[Playground](https://prettier.io/playground/)**\n91. \n92. ---\n93. \n94. ## Badge\n95. \n96. Show the world you're using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n97. \n98. ```md\n99. [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n100. ```\n101. \n102. ## Contributing\n103. \n104. See [CONTRIBUTING.md](CONTRIBUTING.md).\n",
                    "relative_path": "README.md",
                    "start_line_number": 1,
                    "end_line_number": 104
                }
            ],
            "env_implement_write_messages": [
                {
                    "type": "HumanMessage",
                    "content": "content='Project Environment Context:\\nFile: README.md\\nLine number range: 1 - 104\\nContent:\\n1. [![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\\n2. \\n3. <h2 align=\"center\">Opinionated Code Formatter</h2>\\n4. \\n5. <p align=\"center\">\\n6.   <em>\\n7.     JavaScript\\n8.     · TypeScript\\n9.     · Flow\\n10.     · JSX\\n11.     · JSON\\n12.   </em>\\n13.   <br />\\n14.   <em>\\n15.     CSS\\n16.     · SCSS\\n17.     · Less\\n18.   </em>\\n19.   <br />\\n20.   <em>\\n21.     HTML\\n22.     · Vue\\n23.     · Angular\\n24.   </em>\\n25.   <br />\\n26.   <em>\\n27.     GraphQL\\n28.     · Markdown\\n29.     · YAML\\n30.   </em>\\n31.   <br />\\n32.   <em>\\n33.     <a href=\"https://prettier.io/docs/plugins\">\\n34.       Your favorite language?\\n35.     </a>\\n36.   </em>\\n37. </p>\\n38. \\n39. <p align=\"center\">\\n40.   <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\\n41.     <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\\n42.   <a href=\"https://codecov.io/gh/prettier/prettier\">\\n43.     <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\\n44.   <a href=\"https://x.com/acdlite/status/974390255393505280\">\\n45.     <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\\n46.   <br/>\\n47.   <a href=\"https://www.npmjs.com/package/prettier\">\\n48.     <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\\n49.   <a href=\"https://www.npmjs.com/package/prettier\">\\n50.     <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\\n51.   <a href=\"https://github.com/prettier/prettier#badge\">\\n52.     <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\\n53.   <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\\n54.     <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\\n55. </p>\\n56. \\n57. ## Intro\\n58. \\n59. Prettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\\n60. \\n61. ### Input\\n62. \\n63. <!-- prettier-ignore -->\\n64. ```js\\n65. foo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\\n66. ```\\n67. \\n68. ### Output\\n69. \\n70. ```js\\n71. foo(\\n72.   reallyLongArg(),\\n73.   omgSoManyParameters(),\\n74.   IShouldRefactorThis(),\\n75.   isThereSeriouslyAnotherOne(),\\n76. );\\n77. ```\\n78. \\n79. Prettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\\n80. \\n81. ---\\n82. \\n83. **[Documentation](https://prettier.io/docs/)**\\n84. \\n85. [Install](https://prettier.io/docs/install) ·\\n86. [Options](https://prettier.io/docs/options) ·\\n87. [CLI](https://prettier.io/docs/cli) ·\\n88. [API](https://prettier.io/docs/api)\\n89. \\n90. **[Playground](https://prettier.io/playground/)**\\n91. \\n92. ---\\n93. \\n94. ## Badge\\n95. \\n96. Show the world you\\'re using _Prettier_ → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n97. \\n98. ```md\\n99. [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\\n100. ```\\n101. \\n102. ## Contributing\\n103. \\n104. See [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n\\n\\nNow generate a complete executable bash script that can successfully set up and configure the environment for this project, especially designed to run inside Docker containers. The bash script should:\\n1. Install the appropriate runtime and dependencies for the project\\'s technology stack\\n2. Install all necessary system packages and tools\\n3. Set up the project directory structure and permissions\\n4. Configure the runtime environment properly\\n5. Set up necessary environment variables and configurations\\n6. Follow bash scripting best practices for error handling and security\\n\\nMake sure the bash script is self-contained and can set up the project environment from scratch in a Docker container environment.\\n' additional_kwargs={} response_metadata={} id='7ef6504a-458d-4ca7-974e-30fe1c197eb4'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='```bash\\n#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is run as root (Docker containers typically run as root by default)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y curl git nodejs npm\\n    log \"System dependencies installed successfully\"\\n}\\n\\n# Install Node.js and npm (if not already installed)\\ninstall_node() {\\n    log \"Checking for Node.js and npm...\"\\n    if ! command -v node &> /dev/null; then\\n        log \"Node.js not found. Installing Node.js...\"\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n        apt-get install -y nodejs\\n        log \"Node.js installed successfully\"\\n    else\\n        log \"Node.js is already installed\"\\n    fi\\n\\n    if ! command -v npm &> /dev/null; then\\n        error \"npm is not installed. Please check your Node.js installation.\"\\n        exit 1\\n    fi\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod -R 755 /app\\n    log \"Project directory structure set up successfully\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    if [ -f \"/app/package.json\" ]; then\\n        cd /app\\n        npm install\\n        log \"Project dependencies installed successfully\"\\n    else\\n        error \"package.json not found in /app. Please ensure the project files are mounted correctly.\"\\n        exit 1\\n    fi\\n}\\n\\n# Set up environment variables\\nsetup_env() {\\n    log \"Setting up environment variables...\"\\n    export NODE_ENV=production\\n    export APP_PORT=3000\\n    log \"Environment variables set successfully\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_node\\n    setup_project_structure\\n    install_project_deps\\n    setup_env\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the application, run: npm start\"\\n}\\n\\n# Run the main function\\nmain \"$@\"\\n``` \\n\\n### Explanation of the Script:\\n1. **Error Handling and Logging**:\\n   - The script uses `set -e` to exit immediately if any command fails.\\n   - Logging functions (`log`, `error`, `warning`) are used to provide clear feedback to the user.\\n\\n2. **System Dependencies**:\\n   - Installs `curl`, `git`, `nodejs`, and `npm` using `apt-get`.\\n\\n3. **Node.js Installation**:\\n   - Ensures Node.js and npm are installed. If not, it installs Node.js using the NodeSource setup script for Node.js 16.x (a commonly used version).\\n\\n4. **Project Directory Setup**:\\n   - Creates the `/app` directory (where the project files are expected to be mounted in the Docker container) and sets appropriate permissions.\\n\\n5. **Project Dependencies**:\\n   - Checks for the presence of `package.json` in `/app` and installs dependencies using `npm install`.\\n\\n6. **Environment Variables**:\\n   - Sets up environment variables like `NODE_ENV` and `APP_PORT` for the runtime environment.\\n\\n7. **Idempotency**:\\n   - The script is idempotent and can be safely re-run without causing issues.\\n\\n8. **Docker Compatibility**:\\n   - Assumes the script is running as root (default in Docker containers).\\n   - Does not use `sudo` since it is unnecessary in Docker containers.\\n\\n### Usage Instructions:\\n1. Place the project files (including `package.json`) in a directory.\\n2. Mount the project directory to `/app` in the Docker container.\\n3. Run the script inside the Docker container to set up the environment.\\n\\nExample Dockerfile:\\n```dockerfile\\nFROM node:16\\n\\n# Copy the setup script into the container\\nCOPY setup.sh /usr/local/bin/setup.sh\\nRUN chmod +x /usr/local/bin/setup.sh\\n\\n# Copy project files into the container\\nWORKDIR /app\\nCOPY . /app\\n\\n# Run the setup script\\nRUN /usr/local/bin/setup.sh\\n\\n# Expose the application port\\nEXPOSE 3000\\n\\n# Start the application\\nCMD [\"npm\", \"start\"]\\n```\\n\\nThis setup ensures the environment is properly configured for the project to run inside a Docker container.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1088, 'prompt_tokens': 2437, 'total_tokens': 3525, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--889adf71-a8bb-4b2e-b45e-ce871d9aeb31-0' usage_metadata={'input_tokens': 2437, 'output_tokens': 1088, 'total_tokens': 3525, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_file_messages": [
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_up1HTW5Y4DX45kAh5ljhgsYZ', 'function': {'arguments': '{\"relative_path\":\"prometheus_setup.sh\",\"content\":\"#!/bin/bash\\\\n\\\\n# Exit immediately if a command exits with a non-zero status\\\\nset -e\\\\n\\\\n# Colors for output\\\\nRED=\\'\\\\\\\\033[0;31m\\'\\\\nGREEN=\\'\\\\\\\\033[0;32m\\'\\\\nYELLOW=\\'\\\\\\\\033[1;33m\\'\\\\nNC=\\'\\\\\\\\033[0m\\' # No Color\\\\n\\\\n# Logging functions\\\\nlog() {\\\\n    echo -e \\\\\"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\\\\\"\\\\n}\\\\n\\\\nerror() {\\\\n    echo -e \\\\\"${RED}[ERROR] $1${NC}\\\\\" >&2\\\\n}\\\\n\\\\nwarning() {\\\\n    echo -e \\\\\"${YELLOW}[WARNING] $1${NC}\\\\\"\\\\n}\\\\n\\\\n# Ensure the script is run as root (Docker containers typically run as root by default)\\\\nif [ \\\\\"$(id -u)\\\\\" -ne 0 ]; then\\\\n    error \\\\\"This script must be run as root\\\\\"\\\\n    exit 1\\\\nfi\\\\n\\\\n# Install system dependencies\\\\ninstall_system_deps() {\\\\n    log \\\\\"Installing system dependencies...\\\\\"\\\\n    apt-get update\\\\n    apt-get install -y curl git nodejs npm\\\\n    log \\\\\"System dependencies installed successfully\\\\\"\\\\n}\\\\n\\\\n# Install Node.js and npm (if not already installed)\\\\ninstall_node() {\\\\n    log \\\\\"Checking for Node.js and npm...\\\\\"\\\\n    if ! command -v node &> /dev/null; then\\\\n        log \\\\\"Node.js not found. Installing Node.js...\\\\\"\\\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\\\n        apt-get install -y nodejs\\\\n        log \\\\\"Node.js installed successfully\\\\\"\\\\n    else\\\\n        log \\\\\"Node.js is already installed\\\\\"\\\\n    fi\\\\n\\\\n    if ! command -v npm &> /dev/null; then\\\\n        error \\\\\"npm is not installed. Please check your Node.js installation.\\\\\"\\\\n        exit 1\\\\n    fi\\\\n}\\\\n\\\\n# Set up project directory structure\\\\nsetup_project_structure() {\\\\n    log \\\\\"Setting up project directory structure...\\\\\"\\\\n    mkdir -p /app\\\\n    chmod -R 755 /app\\\\n    log \\\\\"Project directory structure set up successfully\\\\\"\\\\n}\\\\n\\\\n# Install project dependencies\\\\ninstall_project_deps() {\\\\n    log \\\\\"Installing project dependencies...\\\\\"\\\\n    if [ -f \\\\\"/app/package.json\\\\\" ]; then\\\\n        cd /app\\\\n        npm install\\\\n        log \\\\\"Project dependencies installed successfully\\\\\"\\\\n    else\\\\n        error \\\\\"package.json not found in /app. Please ensure the project files are mounted correctly.\\\\\"\\\\n        exit 1\\\\n    fi\\\\n}\\\\n\\\\n# Set up environment variables\\\\nsetup_env() {\\\\n    log \\\\\"Setting up environment variables...\\\\\"\\\\n    export NODE_ENV=production\\\\n    export APP_PORT=3000\\\\n    log \\\\\"Environment variables set successfully\\\\\"\\\\n}\\\\n\\\\n# Main setup function\\\\nmain() {\\\\n    log \\\\\"Starting project environment setup...\\\\\"\\\\n\\\\n    install_system_deps\\\\n    install_node\\\\n    setup_project_structure\\\\n    install_project_deps\\\\n    setup_env\\\\n\\\\n    log \\\\\"Project environment setup completed successfully!\\\\\"\\\\n    log \\\\\"To start the application, run: npm start\\\\\"\\\\n}\\\\n\\\\n# Run the main function\\\\nmain \\\\\"$@\\\\\"\"}', 'name': 'create_file'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 727, 'prompt_tokens': 72868, 'total_tokens': 73595, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--9a1aa174-df0b-4348-b277-c4e801bf3548-0' tool_calls=[{'name': 'create_file', 'args': {'relative_path': 'prometheus_setup.sh', 'content': '#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is run as root (Docker containers typically run as root by default)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update\\n    apt-get install -y curl git nodejs npm\\n    log \"System dependencies installed successfully\"\\n}\\n\\n# Install Node.js and npm (if not already installed)\\ninstall_node() {\\n    log \"Checking for Node.js and npm...\"\\n    if ! command -v node &> /dev/null; then\\n        log \"Node.js not found. Installing Node.js...\"\\n        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n        apt-get install -y nodejs\\n        log \"Node.js installed successfully\"\\n    else\\n        log \"Node.js is already installed\"\\n    fi\\n\\n    if ! command -v npm &> /dev/null; then\\n        error \"npm is not installed. Please check your Node.js installation.\"\\n        exit 1\\n    fi\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod -R 755 /app\\n    log \"Project directory structure set up successfully\"\\n}\\n\\n# Install project dependencies\\ninstall_project_deps() {\\n    log \"Installing project dependencies...\"\\n    if [ -f \"/app/package.json\" ]; then\\n        cd /app\\n        npm install\\n        log \"Project dependencies installed successfully\"\\n    else\\n        error \"package.json not found in /app. Please ensure the project files are mounted correctly.\"\\n        exit 1\\n    fi\\n}\\n\\n# Set up environment variables\\nsetup_env() {\\n    log \"Setting up environment variables...\"\\n    export NODE_ENV=production\\n    export APP_PORT=3000\\n    log \"Environment variables set successfully\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_deps\\n    install_node\\n    setup_project_structure\\n    install_project_deps\\n    setup_env\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To start the application, run: npm start\"\\n}\\n\\n# Run the main function\\nmain \"$@\"'}, 'id': 'call_up1HTW5Y4DX45kAh5ljhgsYZ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 72868, 'output_tokens': 727, 'total_tokens': 73595, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='The file prometheus_setup.sh has been created.' name='create_file' id='5556c770-03ae-4f26-80e8-4634236f390a' tool_call_id='call_up1HTW5Y4DX45kAh5ljhgsYZ'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='The bash script has been saved at the root of the project with the relative path:\\n\\n`prometheus_setup.sh`' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 73612, 'total_tokens': 73637, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 73472}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--ebbf5e0a-1db2-42f9-a6c1-341ffa061b10-0' usage_metadata={'input_tokens': 73612, 'output_tokens': 25, 'total_tokens': 73637, 'input_token_details': {'audio': 0, 'cache_read': 73472}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_execute_messages": [],
            "env_implement_bash_content": "diff --git a/prometheus.Dockerfile b/prometheus.Dockerfile\nnew file mode 100644\nindex 000000000..1616a7282\n--- /dev/null\n+++ b/prometheus.Dockerfile\n@@ -0,0 +1,22 @@\n+FROM ubuntu:24.04\n+\n+# Avoid timezone prompts during package installation\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV TZ=UTC\n+\n+# Set working directory\n+WORKDIR /app\n+\n+# Install essential build and development tools\n+RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     wget     python3     python3-pip     python3-dev     python3-venv     nodejs     npm     default-jdk     gcc     g++     gdb     postgresql-client     mysql-client     sqlite3     iputils-ping     vim     nano     zip     unzip     ca-certificates     gnupg     lsb-release\n+\n+RUN mkdir -p /etc/apt/keyrings     && curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg     && echo     \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu     $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n+\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+RUN apt-get clean\n+RUN rm -rf /var/lib/apt/lists/*\n+RUN ln -s /usr/bin/python3 /usr/bin/python\n+\n+# Copy project files\n+COPY . /app/\ndiff --git a/prometheus_setup.sh b/prometheus_setup.sh\nnew file mode 100644\nindex 000000000..947972bc4\n--- /dev/null\n+++ b/prometheus_setup.sh\n@@ -0,0 +1,101 @@\n+#!/bin/bash\n+\n+# Exit immediately if a command exits with a non-zero status\n+set -e\n+\n+# Colors for output\n+RED='\\033[0;31m'\n+GREEN='\\033[0;32m'\n+YELLOW='\\033[1;33m'\n+NC='\\033[0m' # No Color\n+\n+# Logging functions\n+log() {\n+    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n+}\n+\n+error() {\n+    echo -e \"${RED}[ERROR] $1${NC}\" >&2\n+}\n+\n+warning() {\n+    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n+}\n+\n+# Ensure the script is run as root (Docker containers typically run as root by default)\n+if [ \"$(id -u)\" -ne 0 ]; then\n+    error \"This script must be run as root\"\n+    exit 1\n+fi\n+\n+# Install system dependencies\n+install_system_deps() {\n+    log \"Installing system dependencies...\"\n+    apt-get update\n+    apt-get install -y curl git nodejs npm\n+    log \"System dependencies installed successfully\"\n+}\n+\n+# Install Node.js and npm (if not already installed)\n+install_node() {\n+    log \"Checking for Node.js and npm...\"\n+    if ! command -v node &> /dev/null; then\n+        log \"Node.js not found. Installing Node.js...\"\n+        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\n+        apt-get install -y nodejs\n+        log \"Node.js installed successfully\"\n+    else\n+        log \"Node.js is already installed\"\n+    fi\n+\n+    if ! command -v npm &> /dev/null; then\n+        error \"npm is not installed. Please check your Node.js installation.\"\n+        exit 1\n+    fi\n+}\n+\n+# Set up project directory structure\n+setup_project_structure() {\n+    log \"Setting up project directory structure...\"\n+    mkdir -p /app\n+    chmod -R 755 /app\n+    log \"Project directory structure set up successfully\"\n+}\n+\n+# Install project dependencies\n+install_project_deps() {\n+    log \"Installing project dependencies...\"\n+    if [ -f \"/app/package.json\" ]; then\n+        cd /app\n+        npm install\n+        log \"Project dependencies installed successfully\"\n+    else\n+        error \"package.json not found in /app. Please ensure the project files are mounted correctly.\"\n+        exit 1\n+    fi\n+}\n+\n+# Set up environment variables\n+setup_env() {\n+    log \"Setting up environment variables...\"\n+    export NODE_ENV=production\n+    export APP_PORT=3000\n+    log \"Environment variables set successfully\"\n+}\n+\n+# Main setup function\n+main() {\n+    log \"Starting project environment setup...\"\n+\n+    install_system_deps\n+    install_node\n+    setup_project_structure\n+    install_project_deps\n+    setup_env\n+\n+    log \"Project environment setup completed successfully!\"\n+    log \"To start the application, run: npm start\"\n+}\n+\n+# Run the main function\n+main \"$@\"\n\\ No newline at end of file\ndiff --git a/prometheus_testsuite_commands.txt b/prometheus_testsuite_commands.txt\nnew file mode 100644\nindex 000000000..f876fcd36\n--- /dev/null\n+++ b/prometheus_testsuite_commands.txt\n@@ -0,0 +1,9 @@\n+prettier --version\n+prettier --help\n+yarn build:website --help\n+yarn start --help\n+yarn build --help\n+node ./scripts/release/release.js --version\n+node ./scripts/release/release.js --help\n+node --version\n+yarn --version\n",
            "env_implement_bash_path": "prometheus_setup.sh"
        },
        "timestamp": "2025-10-18T10:16:25.211521"
    },
    "serverless": {
        "project_name": "serverless",
        "project_repo_url": "https://github.com/serverless/serverless",
        "success": true,
        "playground_path": "/tmp/tmpbnndb0ym/serverless",
        "container_info": null,
        "testsuite_states": {
            "testsuite_max_refined_query_loop": 0,
            "testsuite_context_provider_messages": [
                {
                    "type": "SystemMessage",
                    "content": "content=\"You are to discover ONE minimal, safe, and quick verification shell command from README/docs to confirm the environment/setup works (e.g., '<tool> --version', '<package> --help', 'make check', 'pytest -q'). Avoid destructive or long-running commands.\" additional_kwargs={} response_metadata={} id='0529df8a-1e1b-4101-b611-fe6eaed07480'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Find one quick verification command from README/docs for this repository.' additional_kwargs={} response_metadata={} id='128fa0a1-0df2-4680-a935-3b3a263ca163'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_DBdi4kjRKNguZd0EfW29ICMA', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 9670, 'total_tokens': 9690, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--93df75ec-0da5-4c6a-86f8-2747a64914ff-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_DBdi4kjRKNguZd0EfW29ICMA', 'type': 'tool_call'}] usage_metadata={'input_tokens': 9670, 'output_tokens': 20, 'total_tokens': 9690, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3700220}\\npreview: [![Serverless Framework AWS Lambda AWS DynamoDB AWS API Gateway](https://github.com/serverless/serverless/assets/2752551/66a8c6a9-bc4a-4116-b139-90c12963337e)](https://serverless.com)\\n\\n<br/>\\n\\n<div align=\"center\">\\n  <a aria-label=\"Serverless.com\" href=\"https://serverless.com\">Website</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Documentation\" href=\"https://serverless.com/framework/docs/\">Documentation</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Inc Twitter\" href=\"https://twitter.com/goserverless\">X / Twitter</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Community Slack\" href=\"https://serverless.com/slack\">Community Slack</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Community Forum\" href=\"https://forum.serverless.com\">Forum</a>\\n</div>\\n\\n<br/>\\n<br/>\\n\\n**The Serverless Framework** – Makes it easy to use AWS Lambda and other managed cloud services to build applications that auto-scale, cost nothing when idle, and result in radically low maintenance.\\n\\nThe Serverless Framework is a command-line tool with approachable YAML syntax to deploy both your code and cloud infrastructure needed to make tons of serverless application use-cases, like APIs, front-ends, data pipelines and scheduled tasks. It\\'s a multi-language framework that supports Node.js, Typescript, Python, Go, Java, and more. It\\'s also completely extensible via over 1,000 plugins which add more serverless use-cases and workflows to the Framework.\\n\\nActively maintained by [Serverless Inc](https://www.serverless.com).\\n\\n<br/>\\n\\n# Serverless Framework - V.4\\n\\n<div align=\"center\" style=\"max-width: 500px; margin: auto;\">\\n  <a href=\"https://www.youtube.com/watch?v=UQL_PPJUFOU\" target=\"_blank\">\\n    <img src=\"https://github.com/serverless/serverless/assets/2752551/2fc23656-df76-4d8a-b775-f4cc8ed2068d\" alt=\"Serverless Framework V.4 Overview Video\" style=\"width: 100%; max-width: 500px;\">\\n  </a>\\n</div>\\n\\n<br/>\\n\\n**August 2025** – V.4 continues to feature significant updates. Review them all below. In 2025, we have begun releasing bigger projects, like the [Serverless Container Framework](https://github.com/serverless/containers), and the [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp). As always, we are more excited about the serverless future than ever.\\n\\n## New Features In V.4\\n\\nHere\\'s a list of everything that\\'s new in V.4, so far:\\n\\n- **Improved Custom Domain Support:** You no longer need an external plugin to automatically configure custom domains and SSL certificates for your APIs and more. It\\'s now built into the [Serverless Framework CLI](https://www.serverless.com/framework/docs/providers/aws/guide/domains).\\n- **Integration with Doppler:** You can now easily fetch Secrets from Doppler via [Serverless Framework Variables](https://www.serverless.com/framework/docs/guides/variables/doppler).\\n- **Introducing [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp):** Built for Cursor, Windsurf, and other AI-powered IDEs, it auto-detects cloud resources from your code, fetching logs, state, and config from AWS, enabling you to debug serverless apps directly in your IDE — no AWS console visit needed! Supports Serverless Framework, Cloudformation, and more.\\n- **Introducing the [Serverless Container Framework](https://github.com/serverless/containers):** One solution to deploy serverless workloads everywhere - This is a new YAML file that works with the Serverless Framework CLI that gives you one experience to easily deploy containers to AWS Lambda and AWS ECS Fargate and migrate between them w/ zero-downtime — all without re-architecting. We launched this as a way to reduce large Lambda bills and give folks flexibility, but it is rapidly become the greatest developer experience for containers on AWS. Support for Google Cloud Run, Azure and more are coming soon.\\n- **Support for AWS SAM, AWS Cloudformation, & Traditional Serverless Framework Projects:** Now, you can use one tool to deploy all three of these IaC project files. [More info here](https://www.serverless.com/framework/docs/guides/sam)\\n- **Native Typescript Support:** You can now use `.ts` handlers in your AWS Lambda functions in `serverless.yml` and have them build automatically upon deploy. [ESBuild](https://esbuild.github.io/) is now included in the Framework which makes this possible. [More info here](https://www.serverless.com/framework/docs/providers/aws/guide/building).\\n- **The AWS AI Stack:** V.4 is optimized for [the AWS AI Stack](https://github.com/serverless/aws-ai-stack). Deploy a full-stack, serverless, boilerplate for AI applications on AWS, featuring Bedrock LLMs like Claude 3.5 Sonnet and Llama3.1 and much more.\\n- **New Dev Mode:** Run `serverless dev` to have events from your live architecture routed to your local code, enabling you to make fast changes without deployment. [More info here](https://www.serverless.com/framework/docs/providers/aws/cli-reference/dev).\\n- - **Node.js V22:** Support for Node.js version 22 on AWS Lambda.\\n- **New Stages Property:** Easily organize stage-specific config via `stages` and set `default` config to fallback to.\\n- **Improved Compose Experience:** Serverless Compose now has a beautiful new CLI experience that better demonstrates what is being deployed.\\n- **New Terraform & Vault Integrations:** Pull state outputs from several Terraform state storage solutions, and secrets from Vault. [Terraform Docs](https://www.serverless.com/framework/docs/guides/variables/terraform) [Vault Docs](https://www.serverless.com/framework/docs/guides/variables/vault)\\n- **Support Command:** Send support requests to our team [directly from the CLI](https://www.serverless.com/framework/docs/providers/aws/cli-reference/support), which auto-include contextual info which you can review before sending.\\n- **Debug Summary for AI:** When you run into a bug, you can run \"serverless support --ai\" to generate a concise report detailing your last bug with all necessary context, optimized for pasting into AI tools such as ChatGPT.\\n- **New AWS Lambda Runtimes:** \"python3.12\", \"dotnet8\", and \"java21\".\\n- **Advanced Logging Controls for AWS Lambda:** Capture Logs in JSON, increased log granularity, and setting a custom Log Group. Here is the [AWS article](https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/). Here is the [YAML implementation](https://github.com/serverless/serverless/blob/v4.0/docs/providers/aws/guide/serverless.yml.md#logs)\\n- **Axiom Integration:** Integrate with [Axiom\\'s observability solution](https://www.serverless.com/framework/docs/guides/observability/axiom) for a powerful logging, metrics and traces experience, at 3X less than AWS cloudwatch.\\n- **AWS SSO:** Environment variables, especially ones set by AWS SSO, are prioritized. The Framework and Dashboard no longer interfere with these.\\n- **Automatic Updates:** These happen by default now. Though, you will be able to control the level of updates you\\'re open to.\\n- **Improved Onboarding & Set-Up:** The `serverless` command has been re-written to be more helpful when setting up a new or existing project.\\n- **Updated Custom Resource Handlers:** All custom resource handlers now use `nodejs20.x`.\\n- **Deprecation Of Non-AWS Providers:** Deprecation of other cloud providers, in favor of handling this better in our upcoming Serverless Framework \"Extensions\".\\n\\n## Breaking Changes\\n\\nWe\\'re seeking to avoid breaking changes for the \"aws\" Provider. However, there are a few large things that are changing to be aware of:\\n\\n- The V.4 License is changing. See the section below for more information on this.\\n- Authentication is required within the CLI.\\n- Non-AWS Providers have been deprecated. We will be introducing new ways in V.4 to use other cloud infrastructure vendors.\\n\\nIf you stumble upon additional breaking changes, please create an issue. To learn more about what\\'s different and potential breaking changes, please see our [Upgrading to Serverless Framework V4 Documentation](https://www.serverless.com/framework/docs/guides/upgrading-v4).\\n\\n## License Changes in V.4\\n\\nPlease note, the structure and licensing of the V.4 repository differ from the V.4 npm module. The npm module contains some proprietary licensed software, as V.4 transitions to a common SaaS product, [as previously announced](https://www.serverless.com/blog/serverless-framework-v4-a-new-model). The original Serverless Framework source code and more will continue to remain MIT license software, the repository will soon be restructured to clearly distinguish between proprietary and open-source components.\\n\\n<br/>\\n\\n# Contents\\n\\n- [Features](#features)\\n- [Quick Start](#quick-start)\\n- [Examples](https://github.com/serverless/examples)\\n- [Plugins](https://github.com/serverless/plugins)\\n- [Community](#community)\\n\\n<br/>\\n\\n# <a name=\"features\"></a>Features\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/README.md\\', \\'node_id\\': 3700229}\\npreview: # How to run, organize and write tests?\\n\\nAs framework deals with significant technical debt baggage many of currently configured tests do not\\nresemble practise we want to follow in newly introduced tests.\\n\\nPlease follow this document as the only guideline, it also provides links to tests that serve as a good example to replicate\\n\\n## Unit tests\\n\\nTests are configured with [Mocha](https://mochajs.org/) test framework, and can be run with following command\\n\\n```\\nnpm test\\n```\\n\\nAll new tests should be configured with help of [runServerless](./utils/run-serverless.js) util - it\\'s the only way to test functionality against completely intialized `serverless` instance, and it\\'s the only scenario that reflects real world usage.\\n\\nCheck documentation of `runServerless` at [@serverless/test/docs/run-serverless](https://github.com/serverless/test/blob/main/docs/run-serverless.md#run-serverless). Note that `runServerless` as configured at `./utils/run-serverless.js` supports two additional options (`fixture` and `configExt`), which provides out of a box setup to run _Serverless_ instance against prepared fixture with eventually extended service configuration\\n\\nAs `runServerless` tests are expensive, it\\'s good to ensure a _minimal_ count of `runServerless` runs to test given scope of problems. Ideally with one service example we should cover most of the test cases we can (good example of such approach is [ALB health check tests](https://github.com/serverless/serverless/blob/80e70e7affd54418361c4d54bdef1561af6b8826/lib/plugins/aws/package/compile/events/alb/lib/healthCheck.test.js#L18-L127))\\n\\nWhen creating a new test, it is an established practice to name the top-level describe after the path to the file, as shown in [AWS Kafka tests](https://github.com/serverless/serverless/blob/b36cdf2db6ee25f7defe6f2c02dd40e1d5cb65c4/test/unit/lib/plugins/aws/package/compile/events/kafka.test.js#L10).\\n\\n### Existing test examples:\\n\\n- [Run against config passed inline](https://github.com/serverless/serverless/blob/73107822945a878abbdebe2309e8e9d87cc2858a/lib/plugins/aws/package/lib/generateCoreTemplate.test.js#L11-L14)\\n- [Run against preprepared fixture](https://github.com/serverless/serverless/blob/74634c3317a116077a008375e20d6a5b99b1256e/lib/plugins/aws/package/compile/functions/index.test.js#L2605-L2608)\\n  - Fixtures can be [extended](https://github.com/serverless/serverless/blob/74634c3317a116077a008375e20d6a5b99b1256e/lib/plugins/aws/package/compile/events/httpApi/index.test.js#L95-L99) on spot. Whenever possible it\\'s better to extend existing fixture (e.g. basic `function`) instead of creating new one (check [ALB health check tests](https://github.com/serverless/serverless/blob/80e70e7affd54418361c4d54bdef1561af6b8826/lib/plugins/aws/package/compile/events/alb/lib/healthCheck.test.js) for good example on such approach)\\n  - If needed introduce new test fixtures at [test/fixtures](./fixtures)\\n\\nExample of test files fully backed by `runServerless`:\\n\\n- [lib/plugins/aws/package/compile/events/httpApi.js](https://github.com/serverless/serverless/blob/main/lib/plugins/aws/package/compile/events/httpApi.js)\\n\\nIf we\\'re about to add new tests to an existing test file with tests written old way, then best is to create another `describe` block for new tests at the bottom (as it\\'s done [here](https://github.com/serverless/serverless/blob/main/test/unit/lib/plugins/aws/package/compile/functions.test.js#L1049))\\n\\n_Note: PR\\'s which rewrite existing tests into new method are very welcome! (but, ideally each PR should cover single test file rewrite)_\\n\\n### Coverage\\n\\nWe aim for a (near) 100% test coverage, so make sure your tests cover as much of your code as possible.\\n\\nDuring development, you can easily check coverage by running `npm run coverage`, then opening the `index.html` file inside the `coverage` directory.\\n\\n## AWS Integration tests\\n\\nRun all tests via:\\n\\n```\\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=xxx npm run integration-test-run-all\\n```\\n\\n_Note: Home folder is mocked for test run, therefore relying on `AWS_PROFILE` won\\'t work. _ and _secret key_, need to be configured directly into env variables\\\\_\\n\\n_Note: Some integration tests depend on shared infrastructure stack (see below)_\\n\\nIdeally any feature that integrates with AWS functionality should be backed by integration test.\\n\\nCheck existing set of AWS integration tests at [test/integration](./integration)\\n\\n### Running specific integration test\\n\\nPass test file to Mocha directly as follows\\n\\n```\\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=xxx npx mocha test/integration/{chosen}.test.js\\n```\\n\\n### Tests that depend on shared infrastructure stack\\n\\nDue to the fact that some of the tests require a bit more complex infrastructure setup which might be lengthy, two additional commands has been made available:\\n\\n- `integration-test-setup` - used for setting up all needed intrastructure dependencies\\n- `integration-test-teardown` - used for tearing down the infrastructure setup by the above command\\n\\nSuch tests take advantage of `isDependencyStackAvailable` util to check if all needed dependencies are ready. If not, it skips the given test suite.\\n\\nExamples of such tests:\\n\\n- [MSK](./integration/aws/infra-dependent/msk.test.js)\\n- [ActiveMQ](./integration/infra-dependent/active-mq.test.js)\\n- [RabbitMQ](./integration/infra-dependent/rabbit-mq.test.js)\\n- [FileSystemConfig](./integration/infra-dependent/file-system-config.test.js)\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md\\', \\'node_id\\': 3723675}\\npreview: # Hack\\n\\nThis directory contains code which performs raw SDK calls rather than going through CloudFormation template compilations.\\n\\nWe\\'re planning to port the logic of these code snippets to raw CloudFormation once AWS fixes the problems currently preventing us from solely relying on CloudFormation.\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'lib/plugins/aws/custom-resources/resources/README.md\\', \\'node_id\\': 3730097}\\npreview: # Serverless Custom CloudFormation Resources\\n\\nThis directory contains the Lambda functions for the Serverless Custom CloudFormation Resources.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/README.md\\', \\'node_id\\': 3734424}\\npreview: <!--\\ntitle: \\'Serverless Framework Documentation\\'\\nshort_title: \\'Introduction to the Serverless Framework\\'\\ndescription: \\'An introduction to the Serverless Framework, its philosophy, overview, and key highlights. Learn how to build serverless applications efficiently with minimal maintenance.\\'\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'AWS Lambda\\',\\n    \\'Serverless Documentation\\',\\n    \\'Serverless Architectures\\',\\n    \\'Cloud Infrastructure\\',\\n    \\'Serverless CLI\\',\\n    \\'Serverless Dashboard\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework - An Introduction\\n\\n## Philosophy\\n\\n**_Build applications that demand attention, not maintenance._**\\n\\nIn 2014, AWS Lambda was introduced offering a more efficient compute service in the cloud. With features like auto-scaling and no cost when idle, AWS Lambda offers a compute experience that demands so little maintenance it feels _\"serverless\"_.\\n\\nMonths later, the Serverless Framework was created to streamline the deployment of various use-cases on AWS Lambda. The Serverless Framework introduced the concept of _\"serverless architectures\"_, a transformative approach to building applications on the cloud, integrating AWS Lambda and cloud infrastructure with similar \"serverless\" qualities, to enable developers to create entire applications that scale massively with minimal maintenance.\\n\\nToday, the Serverless Framework continues to be the original, leading and most trusted tool for enterprises and start-ups building serverless architectures. Renowned Fortune 500 companies such as the _New York Times_, _Nike_, and _EA Games_ utilize it, while numerous startups have reached unicorn valuations and achieved notable exits using the Framework. These successes have been accomplished with relatively small engineering teams, leveraging the power of serverless architectures.\\n\\nThe mission of the Serverless Framework is to empower all developers to build more and manage less.\\n\\n## Overview\\n\\nThe Serverless Framework consists of a Command Line Interface and an optional Dashboard, and helps you deploy code and infrastructure together on Amazon Web Services, while increasingly supporting other cloud providers. The Framework is a YAML-based experience that uses simplified syntax to help you deploy complex infrastructure patterns easily, without needing to be a cloud expert. It is developed and maintained by Serverless Inc., a specialized software company based in San Francisco, California. Initially launched as an open-source project, the Framework has since transitioned to a SaaS product to better support its scalability and the extensive infrastructure capabilities it offers.\\n\\n## Highlights\\n\\n- **Empowerment:** Innovate faster by spending less time on infrastructure management.\\n- **Versatility:** Tackle diverse serverless use cases, from APIs and scheduled tasks to web sockets and data pipelines.\\n- **Infra & Code:** Streamline development with code and infrastructure deployment handled together.\\n- **Ease of Use:** Deploy complex applications without deep cloud infrastructure expertise, thanks to approachable YAML configuration.\\n- **Language Agnostic:** Develop in your preferred language – Node.js, Python, Java, Go, C#, Ruby, Swift, Kotlin, PHP, Scala, or F# – the Framework supports them all.\\n- **Full Lifecycle:** Build, deploy, monitor, update, and troubleshoot serverless applications with ease.\\n- **Scalable Organization:** Structure large projects and teams efficiently with built-in support for stages and project composition.\\n- **Plugin Ecosystem:** Extend and modify the Framework\\'s functionality with a rich plugin ecosystem.\\n- **Vibrant Community:** Get support and connect with a passionate community of Serverless developers.\\n\\n## Next Steps\\n\\nGet started with the Serverless Framework on AWS [via this guide](https://serverless.com/framework/docs/getting-started/).\\n\\nHave questions? Join thousands of other developers in our [Slack Channel](https://serverless.com/slack).\\n\\nAfter that, we recommend you...\\n\\n- [Learn Serverless Framework\\'s Core Concepts](https://www.serverless.com/framework/docs/providers/aws/guide/intro)\\n- [Get inspiration from these Serverless Framework Templates](https://github.com/serverless/examples)\\n- [Discover all of the events that can trigger AWS Lambda functions](https://www.serverless.com/framework/docs/providers/aws/guide/events)\\n- [Bookmark Serverless Framework\\'s `serverless.yml` guide](https://www.serverless.com/framework/docs/providers/aws/guide/serverless.yml)\\n- [Search the plugins registry to extend Serverless Framework](https://www.serverless.com/plugins)\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/providers/aws/README.md\\', \\'node_id\\': 3734434}\\npreview: <!--\\ntitle: Serverless Framework - AWS Documentation\\ndescription: Comprehensive guide to using AWS as the default cloud provider with the Serverless Framework.\\nshort_title: AWS Provider Documentation\\nkeywords:\\n  [\\'Serverless Framework\\', \\'AWS\\', \\'Cloud Provider\\', \\'Serverless Documentation\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# AWS Provider Documentation\\n\\nAWS is the default cloud provider used by Serverless Framework.\\n\\n**All the Serverless Framework documentation applies to AWS by default**. This is why there is no sub-documentation specific to AWS: everything related to AWS is already covered by the documentation.\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/providers/aws/guide/README.md\\', \\'node_id\\': 3734439}\\npreview: <!--\\ntitle: Serverless Framework - AWS Guide\\nshort_title: AWS Guide\\ndescription: An introduction to using AWS and AWS Lambda with the Serverless Framework.\\nkeywords: [\\'Serverless Framework\\', \\'AWS Lambda\\', \\'AWS Guide\\', \\'Serverless\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/guide/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless AWS Lambda Guide\\n\\nWelcome to the Serverless AWS Lambda Guide!\\n\\nGet started with the [Introduction to the framework](./intro.md)\\n\\nIf you have questions, join the [chat in Slack](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/providers/aws/examples/README.md\\', \\'node_id\\': 3734484}\\npreview: <!--\\ntitle: Serverless - AWS Lambda - Examples\\nshort_title: Serverless Examples\\ndescription: AWS Lambda examples using the Serverless Framework.\\nkeywords:\\n  [\\'Serverless Framework\\', \\'AWS Lambda\\', \\'examples\\', \\'serverless functions\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/examples/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# AWS Serverless Examples\\n\\nSearch for AWS Serverless Examples using our [Example Explorer](https://serverless.com/examples/).\\n\\nHave an example? Submit a PR or [open an issue](https://github.com/serverless/examples/issues). ⚡️\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/providers/aws/events/README.md\\', \\'node_id\\': 3734486}\\npreview: <!--\\ntitle: Serverless - AWS Lambda - Events\\ndescription: AWS Serverless Events Glossary covering various event sources for AWS Lambda.\\nshort_title: AWS Lambda Events\\nkeywords: [\\'Serverless\\', \\'Framework\\', \\'AWS\\', \\'Lambda\\', \\'Events\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/events/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless AWS Lambda Events\\n\\nWelcome to the AWS Serverless Events Glossary.\\n\\nPlease select a section on the left to get started, or see the [user\\nguide](../guide/events.md) for general information regarding Lambda Events in\\nServerless.\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/providers/aws/cli-reference/README.md\\', \\'node_id\\': 3734542}\\npreview: <!--\\ntitle: Serverless - AWS Lambda - CLI Reference\\nmenuText: CLI Reference\\nshort_title: CLI Reference\\nlayout: Doc\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/cli-reference/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless CLI Reference for AWS\\n\\nWelcome to the Serverless Framework CLI Reference for AWS. Please select a section on the left to get started.\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/README.md\\', \\'node_id\\': 3734581}\\npreview: <!--\\ntitle: Serverless Framework - User Guides\\ndescription: Discover comprehensive user guides for Serverless Framework, covering everything from getting started to advanced topics. Join the community chat on Slack or participate in the forums for more support.\\nshort_title: User Guides\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'user guides\\',\\n    \\'getting started\\',\\n    \\'advanced topics\\',\\n    \\'community\\',\\n    \\'Slack\\',\\n    \\'forums\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework User Guides\\n\\nWelcome to the Serverless Framework User Guides!\\n\\n[Get started with Serverless Framework](/framework/docs/getting-started)\\n\\nIf you have questions, join the [chat in Slack](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/variables/README.md\\', \\'node_id\\': 3734595}\\npreview: <!--\\ntitle: Serverless Framework - Variables\\ndescription: How to use Serverless Variables to insert dynamic configuration info into your serverless.yml\\nshort_title: Variables\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'Variables\\',\\n    \\'serverless.yml\\',\\n    \\'dynamic configuration\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/variables)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Variables\\n\\nVariables allow users to dynamically replace config values in `serverless.yml` config.\\n\\nThey are especially useful when providing secrets for your service to use and when you are working with multiple stages.\\n\\n## Syntax\\n\\nTo use variables, you will need to reference values enclosed in `${}` brackets.\\n\\n```yml\\n# serverless.yml file\\nyamlKeyXYZ: ${provider:resolver:key} # see list of current resolver providers below\\n# this is an example of providing a default value as the second parameter\\notherYamlKey: ${provider:resolver:key, defaultValue}\\n```\\n\\n**Note:** You can only use variables in `serverless.yml` property **values**, not property keys. So you can\\'t use variables to generate dynamic logical IDs in the custom resources section for example.\\n\\n## Variable Resolvers\\n\\nVariable Resolvers allow you to reference external data sources in your serverless.yml file.\\nEach Resolver has a Provider parent, which is responsible for fetching the credentials.\\nFor example, the `aws` Provider has a `ssm` Resolver and a `s3` Resolver,\\nwhich can fetch data from AWS SSM Parameter Store and S3, respectively.\\n\\nProviders can also have default variables that can be used in the serverless.yml file,\\nsuch as `accountId` for the `aws` Provider.\\n\\nYou can customize Providers and Resolvers by specifying custom configuration options in the `resolvers` block of the `stages` section.\\nThen, you can reference the customized Resolvers using `${customProviderName:customResolverName:key}` syntax.\\n\\n**You can always reference the default Resolvers provided by Providers, even if you don’t define them explicitly.**\\nFor example,\\nyou can reference the default `s3` Resolver provided by the `aws` Provider using `${aws:s3:myBucket/myKey}` syntax\\n(it will use the AWS provider which provides the credentials for the deployment),\\nor `${customProviderName:s3:myBucket/myKey}` if you define customized Provider configuration.\\n\\n### Examples\\n\\n#### Default Resolvers\\n\\n```yaml\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    environment:\\n      ACCOUNT_ID: ${aws:accountId} # built-in variable provided by the AWS provider\\n      SSM_VALUE: ${aws:ssm:/path/to/param} # uses the default resolver configuration and the same AWS provider which is used for the deployment\\n      S3_VALUE: ${aws:s3:myBucket/myKey} # uses the default resolver configuration and the same AWS provider which is used for the deployment\\n```\\n\\n#### Customized Resolvers\\n\\n```yaml\\nstages:\\n  default:\\n    resolvers:\\n      awsAccount1:\\n        type: aws\\n        profile: dev-account1-profile-name\\n      awsAccount2:\\n        type: aws\\n        profile: dev-account2-profile-name\\n        euS3: # custom resolver configuration defined for the awsAccount2 provider\\n          type: s3\\n          region: eu-west-1\\n  prod:\\n    resolvers:\\n      awsAccount1:\\n        type: aws\\n        profile: prod-account1-profile-name\\n      awsAccount2:\\n        type: aws\\n        profile: prod-account2-profile-name\\n        euS3: # custom resolver configuration defined for the awsAccount2 provider\\n          type: s3\\n          region: eu-west-1\\n\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    environment:\\n      ACCOUNT1_ID: ${awsAccount1:accountId} # built-in variable provided by the AWS provider\\n      SSM_VALUE: ${awsAccount1:ssm:/path/to/param} # uses the default resolver configuration even if it\\'s not explicitly defined in the resolvers block\\n      EU_S3_VALUE: ${awsAccount2:euS3:myBucket/myKey} # uses the customized resolver configuration\\n      S3_VALUE: ${awsAccount2:s3:myBucket/myKey} # uses the default resolver configuration even if a customized one (euS3) is defined for the same provider\\n```\\n\\n## Supported Variable Providers:\\n\\n- [Self-References Properties Defined in `serverless.yml`](./self)\\n- [Serverless Core Variables](./core)\\n- [Environment Variables](./env-vars)\\n- [CLI Options](./cli-options)\\n- [External YAML/JSON Files](./file)\\n- [Dynamic Values from Javascript](./javascript)\\n- [Git](./git)\\n- [AWS](./aws)\\n- [HashiCorp](./hashicorp)\\n\\n## Recursively reference properties\\n\\nYou can also **recursively reference properties** with the variable system. This means you can combine multiple values and variable sources for a lot of flexibility.\\n\\nFor example:\\n\\n```yml\\nprovider:\\n  name: aws\\n  environment:\\n    MY_SECRET: ${file(./config.${sls:stage}.json):CREDS}\\n```\\n\\nIf `sls deploy --stage qa` is run, the stage will be set to `qa`, which is used inside the `${file(./config.${sls:stage}.json):CREDS}` variable and it will resolve the `config.qa.json` file and use the `CREDS` key defined.\\n\\n**How that works:**\\n\\n1. `stage` is set to `qa` from the option supplied to the `sls deploy --stage qa` command. If no option is defined, then `${sls:stage}` will use the value in `provider.stage` or default to `dev` if not set.\\n2. `${sls:stage}` resolves to `qa` and is used in `${file(./config.${sls:stage}.json):CREDS}`\\n3. `${file(./config.qa.json):CREDS}` is found & the `CREDS` value is read\\n4. `MY_SECRET` value is set\\n\\nLikewise, if `sls deploy --stage prod` is run the `config.prod.json` file would be found and used.\\n\\n## Setting Variables using Parameters\\n\\nOccasionally you may want to set a variable directly in the `serverless.yml` that you can use throughout the file. In such a case you can use Parameters to set new variables or use them to set stage-specific variables.\\n\\nHere is an example of setting a domain variable based on the stage:\\n\\n```yaml\\nstages:\\n  default:\\n    params:\\n      domain: ${sls:stage}.example-dev.com\\n  prod:\\n    params:\\n      domain: example.com\\n\\nprovider:\\n  environment:\\n    APP_DOMAIN: ${param:domain}\\n```\\n\\nRead all about parameters in the [Parameters documentation](../../guides/parameters.md).\\n\\n## Multiple Configuration Files\\n\\nAdding many custom resources to your `serverless.yml` file could bloat the whole file, so you can use the Serverless Variable syntax to split this up.\\n\\n```yml\\nresources:\\n  Resources: ${file(cloudformation-resources.json)}\\n```\\n\\nThe corresponding resources which are defined inside the `cloudformation-resources.json` file will be resolved and loaded into the `Resources` section.\\n\\nIn order to use multiple resource files combined with resources inside the `serverless.yml` you can use an array.\\n\\n```yml\\nresources:\\n  - Resources:\\n      ApiGatewayRestApi:\\n        Type: AWS::ApiGateway::RestApi\\n\\n  - ${file(resources/first-cf-resources.yml)}\\n  - ${file(resources/second-cf-resources.yml)}\\n\\n  - Outputs:\\n      CognitoUserPoolId:\\n      Value:\\n        Ref: CognitoUserPool\\n```\\n\\nEach of your cloudformation files has to start with a `Resources` entity\\n\\n```yml\\nResources:\\n  Type: \\'AWS::S3::Bucket\\'\\n  Properties:\\n    BucketName: some-bucket-name\\n```\\n\\n## Default values\\n\\nThe Serverless framework gives you an intuitive way to reference multiple variables as a fallback strategy in case one of the variables is missing. This way you\\'ll be able to use a default value from a certain source, if the variable from another source is missing.\\n\\nFor example, you can use the `opt` variable to get the `memory` CLI option when running `serverless deploy --memory 2048`. If the `memory` option is not provided, the default value of `1024` will be used.\\n\\n```yml\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    memorySize: ${opt:memory, 1024}\\n```\\n\\nThe default value can also reference another variable.\\n\\n## Read String Variable Values as Boolean Values\\n\\nIn some cases, a parameter expect a `true` or `false` boolean value. If you are using a variable to define the value, it may return as a string (e.g. when using SSM variables) and thus return a `\"true\"` or `\"false\"` string value.\\n\\nTo ensure a boolean value is returned, read the string variable value as a boolean value. For example:\\n\\n```yml\\nprovider:\\n  tracing:\\n    apiGateway: ${strToBool(${ssm:API_GW_DEBUG_ENABLED})}\\n```\\n\\nThese are examples that explain how the conversion works after first lowercasing the passed string value:\\n\\n```plaintext\\n${strToBool(true)} => true\\n${strToBool(false)} => false\\n${strToBool(True)} => true\\n${strToBool(False)} => false\\n${strToBool(TRUE)} => true\\n${strToBool(FALSE)} => false\\n${strToBool(0)} => false\\n${strToBool(1)} => true\\n${strToBool(2)} => Error\\n${strToBool(null)} => Error\\n${strToBool(anything)} => Error\\n```\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/variables/hashicorp/README.md\\', \\'node_id\\': 3734607}\\npreview: <!--\\ntitle: Serverless Framework - Variables - HashiCorp-specific variables\\ndescription: >-\\n  How to reference HashiCorp-specific variables in the Serverless Framework for\\n  efficient configuration and deployment.\\nshort_title: Serverless Variables - HashiCorp Variables\\nkeywords:\\n  - Serverless Framework\\n  - HashiCorp-specific variables\\n  - configuration\\n  - deployment\\n-->\\n\\n# Resolvers\\n\\n- [HashiCorp Terraform State Outputs](terraform)\\n- [HashiCorp Vault Secrets](vault)\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/variables/aws/README.md\\', \\'node_id\\': 3734618}\\npreview: <!--\\ntitle: Serverless Framework - Variables - AWS-specific variables\\ndescription: >-\\n  How to reference AWS-specific variables in the Serverless Framework for\\n  efficient configuration and deployment.\\nshort_title: Serverless Variables - AWS Variables\\nkeywords:\\n  - Serverless Framework\\n  - AWS-specific variables\\n  - configuration\\n  - deployment\\n  - accountId\\n  - region\\n-->\\n\\n# Resolvers\\n\\n- [AWS S3](s3)\\n- [AWS SSM Parameter Store & Secrets Manager](ssm)\\n- [AWS CloudFormation Outputs](cf-stack)\\n\\n# Configuration options\\n\\n| Option            | Required |  Type   |  Default  | Description                                                          |\\n| ----------------- | :------: | :-----: | :-------: | :------------------------------------------------------------------- |\\n| `accessKeyId`     |    No    | String  |           | AWS Access Key ID                                                    |\\n| `secretAccessKey` |    No    | String  |           | AWS Secret Access Key                                                |\\n| `sessionToken`    |    No    | String  |           | AWS Session Token                                                    |\\n| `region`          |    No    | String  | us-east-1 | AWS region                                                           |\\n| `profile`         |    No    | String  |           | AWS profile name                                                     |\\n| `dashboard`       |    No    | Boolean |   true    | Whether Serverless Dashboard AWS Provider credentials should be used |\\n\\n## Example\\n\\n```yaml\\nstages:\\n  default:\\n    resolvers:\\n      aws-account-1:\\n        type: aws\\n        profile: account1-profile-name\\n        region: us-west-2\\n        accessKeyId: ${env:ACCOUNT1_AWS_ACCESS_KEY_ID}\\n        secretAccessKey: ${env:ACCOUNT1_AWS_SECRET_ACCESS_KEY}\\n        dashboard: false\\n```\\n\\n# Provider-specific variables\\n\\nYou can reference AWS-specific values as the source of your variables. Those values are exposed via the Serverless Variables system through:\\n\\n1. `{providerName:}` variable prefix which should be the name of the resolver provider specified in the `resolvers` block (`aws-account-1` in the example above).\\n2. `{aws:}` variable prefix which uses the deployment credentials.\\n\\nThe following variables are available:\\n\\n**accountId**\\n\\nAccount ID of you AWS Account, based on the AWS Credentials that you have configured.\\n\\n```yml\\nservice: new-service\\nprovider:\\n  name: aws\\n\\nfunctions:\\n  func1:\\n    name: function-1\\n    handler: handler.func1\\n    environment:\\n      ACCOUNT_ID: ${aws:accountId}\\n```\\n\\n**region**\\n\\nThe region used by the Serverless CLI. The `${aws:region}` variable is a shortcut for `${opt:region, self:provider.region, \"us-east-1\"}`.\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/plugins/README.md\\', \\'node_id\\': 3734630}\\npreview: <!--\\ntitle: Serverless Framework - Plugins\\ndescription: How to install plugins to customize the Serverless Framework\\nshort_title: Plugins\\nkeywords: [\\'Serverless Framework\\', \\'Plugins\\', \\'Installation\\', \\'Customization\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/plugins)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Plugins\\n\\nA plugin is custom JavaScript code that extends the Serverless Framework with new features.\\n\\nIf you or your organization have a specific workflow, install a pre-written plugin or write one to customize the Framework to your needs.\\n\\nSince the Serverless Framework is a group of \"core\" plugins, custom plugins are written exactly the same way as core plugins. Learn more about [creating a custom plugin](./creating-plugins.md).\\n\\nExplore existing plugins in the [Serverless Framework Plugins repository](https://www.serverless.com/plugins).\\n\\n## Installing plugins\\n\\nPlugins are installed per service. They are not applied globally.\\n\\nTo install a plugin, run the following command in a service directory:\\n\\n```\\nserverless plugin install -n custom-serverless-plugin\\n```\\n\\nThis command will install the plugin via NPM and register it in `serverless.yml`.\\n\\nYou can also install the plugin manually via NPM:\\n\\n```\\nnpm install --save-dev custom-serverless-plugin\\n```\\n\\nand then register it in `serverless.yml` in the `plugins` section:\\n\\n```yml\\n# serverless.yml file\\n\\nplugins:\\n  - custom-serverless-plugin\\n```\\n\\nSome plugins require extra configuration. The `custom` section in `serverless.yml` is where you can add extra configuration for plugins (the plugin\\'s documentation will tell you if you need to add anything there):\\n\\n```yml\\nplugins:\\n  - custom-serverless-plugin\\n\\ncustom:\\n  customkey: customvalue\\n```\\n\\nNote for plugin authors: read [Extending the configuration](./custom-configuration.md) to learn how to enhance `serverless.yml` with configuration validation.\\n\\n## Service local plugin\\n\\nIf you are working on a plugin, or have a plugin that is just designed for one project, it can be loaded from local files:\\n\\n```yml\\nplugins:\\n  - ./local-directory/custom-serverless-plugin\\n```\\n\\nThe path must start with `./` and is relative to the root of your service.\\n\\n## Load Order\\n\\nKeep in mind that the order you define your plugins matters. Serverless loads all the core plugins, and then the custom plugins in the order you\\'ve defined them.\\n\\n```yml\\n# serverless.yml\\n\\nplugins:\\n  - plugin1\\n  - plugin2\\n```\\n\\nIn this case `plugin1` is loaded before `plugin2`.\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/observability/README.md\\', \\'node_id\\': 3734645}\\npreview: <!--\\ntitle: Serverless Framework - Observability\\ndescription: How to configure observability for your Serverless Framework services\\nshort_title: Observability\\nkeywords: [\\'Serverless Framework\\', \\'Observability\\', \\'Monitoring\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/observability)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Observability\\n\\nObservability is a crucial aspect of managing and maintaining your serverless applications. It provides insights into the behavior, performance, and health of your services. The Serverless Framework allows you to automatically configure observability for your services.\\n\\n## Enabling Observability\\n\\nThe Serverless Framework supports multiple observability providers. You can configure it to work with your preferred provider using the `observability` property within the `stages` block in your `serverless.yml` file.\\nBelow is an example of how to enable the Serverless Dashboard observability feature for the `prod` stage:\\n\\n```yaml\\nstages:\\n  prod:\\n    observability: dashboard\\n```\\n\\n## Configuring Observability\\n\\nFor more granular control, you can specify the observability key as an object and include additional properties. In this configuration, the `provider` key is required, and you must specify the desired provider.\\n\\n```yaml\\nstages:\\n  prod:\\n    observability:\\n      provider: dashboard\\n      # additional configuration options for the chosen provider\\n      exampleSetting: customValue\\n```\\n\\n## Next Steps\\n\\nLearn more about configuring and using our supported observability providers:\\n\\n- [Serverless Dashboard](./dashboard)\\n- [Axiom](./axiom)\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'docs/guides/dashboard/README.md\\', \\'node_id\\': 3734653}\\npreview: <!--\\ntitle: Serverless Framework Dashboard - Setup & Overview\\ndescription: An overview and set-up guide for Serverless Framework Dashboard\\nshort_title: Serverless Dashboard - Setup & Overview\\nkeywords: [\\'Serverless Framework\\', \\'Dashboard\\', \\'Setup\\', \\'Overview\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/dashboard/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework Dashboard\\n\\nThe [Serverless Framework Dashboard](https://app.serverless.com/) is a SaaS solution that augments the Serverless Framework CLI to provide a powerful, unified experience to develop, deploy, test, secure and monitor your serverless applications, across all AWS accounts.\\n\\nThe aim of the Serverless Framework and its Dashboard is to offer a seamless, integrated development experience for you and your team throughout the entire lifecycle of your serverless applications. We hope it\\'s a breath of fresh air compared to the complexity of interacting with the AWS Console across several accounts, directly.\\n\\n## Features\\n\\n- **Deployments:** Easily see all Serverless Framework deployments made by you and your team, via CI/CD or local installations of the CLI, across all of your AWS accounts, in one place. Quickly check who made the deployment, what the status is, how it may have failed, see git... Output has been truncated becuase it is too long, please narrow down your query if you wish to see more' name='preview_file_content_with_basename' id='fa52e4e5-53a3-428f-b09a-dc8ac1730f10' tool_call_id='call_DBdi4kjRKNguZd0EfW29ICMA' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3700220}, 'preview': '[![Serverless Framework AWS Lambda AWS DynamoDB AWS API Gateway](https://github.com/serverless/serverless/assets/2752551/66a8c6a9-bc4a-4116-b139-90c12963337e)](https://serverless.com)\\n\\n<br/>\\n\\n<div align=\"center\">\\n  <a aria-label=\"Serverless.com\" href=\"https://serverless.com\">Website</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Documentation\" href=\"https://serverless.com/framework/docs/\">Documentation</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Inc Twitter\" href=\"https://twitter.com/goserverless\">X / Twitter</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Community Slack\" href=\"https://serverless.com/slack\">Community Slack</a>\\n  &nbsp;•&nbsp;\\n  <a aria-label=\"Serverless Framework Community Forum\" href=\"https://forum.serverless.com\">Forum</a>\\n</div>\\n\\n<br/>\\n<br/>\\n\\n**The Serverless Framework** – Makes it easy to use AWS Lambda and other managed cloud services to build applications that auto-scale, cost nothing when idle, and result in radically low maintenance.\\n\\nThe Serverless Framework is a command-line tool with approachable YAML syntax to deploy both your code and cloud infrastructure needed to make tons of serverless application use-cases, like APIs, front-ends, data pipelines and scheduled tasks. It\\'s a multi-language framework that supports Node.js, Typescript, Python, Go, Java, and more. It\\'s also completely extensible via over 1,000 plugins which add more serverless use-cases and workflows to the Framework.\\n\\nActively maintained by [Serverless Inc](https://www.serverless.com).\\n\\n<br/>\\n\\n# Serverless Framework - V.4\\n\\n<div align=\"center\" style=\"max-width: 500px; margin: auto;\">\\n  <a href=\"https://www.youtube.com/watch?v=UQL_PPJUFOU\" target=\"_blank\">\\n    <img src=\"https://github.com/serverless/serverless/assets/2752551/2fc23656-df76-4d8a-b775-f4cc8ed2068d\" alt=\"Serverless Framework V.4 Overview Video\" style=\"width: 100%; max-width: 500px;\">\\n  </a>\\n</div>\\n\\n<br/>\\n\\n**August 2025** – V.4 continues to feature significant updates. Review them all below. In 2025, we have begun releasing bigger projects, like the [Serverless Container Framework](https://github.com/serverless/containers), and the [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp). As always, we are more excited about the serverless future than ever.\\n\\n## New Features In V.4\\n\\nHere\\'s a list of everything that\\'s new in V.4, so far:\\n\\n- **Improved Custom Domain Support:** You no longer need an external plugin to automatically configure custom domains and SSL certificates for your APIs and more. It\\'s now built into the [Serverless Framework CLI](https://www.serverless.com/framework/docs/providers/aws/guide/domains).\\n- **Integration with Doppler:** You can now easily fetch Secrets from Doppler via [Serverless Framework Variables](https://www.serverless.com/framework/docs/guides/variables/doppler).\\n- **Introducing [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp):** Built for Cursor, Windsurf, and other AI-powered IDEs, it auto-detects cloud resources from your code, fetching logs, state, and config from AWS, enabling you to debug serverless apps directly in your IDE — no AWS console visit needed! Supports Serverless Framework, Cloudformation, and more.\\n- **Introducing the [Serverless Container Framework](https://github.com/serverless/containers):** One solution to deploy serverless workloads everywhere - This is a new YAML file that works with the Serverless Framework CLI that gives you one experience to easily deploy containers to AWS Lambda and AWS ECS Fargate and migrate between them w/ zero-downtime — all without re-architecting. We launched this as a way to reduce large Lambda bills and give folks flexibility, but it is rapidly become the greatest developer experience for containers on AWS. Support for Google Cloud Run, Azure and more are coming soon.\\n- **Support for AWS SAM, AWS Cloudformation, & Traditional Serverless Framework Projects:** Now, you can use one tool to deploy all three of these IaC project files. [More info here](https://www.serverless.com/framework/docs/guides/sam)\\n- **Native Typescript Support:** You can now use `.ts` handlers in your AWS Lambda functions in `serverless.yml` and have them build automatically upon deploy. [ESBuild](https://esbuild.github.io/) is now included in the Framework which makes this possible. [More info here](https://www.serverless.com/framework/docs/providers/aws/guide/building).\\n- **The AWS AI Stack:** V.4 is optimized for [the AWS AI Stack](https://github.com/serverless/aws-ai-stack). Deploy a full-stack, serverless, boilerplate for AI applications on AWS, featuring Bedrock LLMs like Claude 3.5 Sonnet and Llama3.1 and much more.\\n- **New Dev Mode:** Run `serverless dev` to have events from your live architecture routed to your local code, enabling you to make fast changes without deployment. [More info here](https://www.serverless.com/framework/docs/providers/aws/cli-reference/dev).\\n- - **Node.js V22:** Support for Node.js version 22 on AWS Lambda.\\n- **New Stages Property:** Easily organize stage-specific config via `stages` and set `default` config to fallback to.\\n- **Improved Compose Experience:** Serverless Compose now has a beautiful new CLI experience that better demonstrates what is being deployed.\\n- **New Terraform & Vault Integrations:** Pull state outputs from several Terraform state storage solutions, and secrets from Vault. [Terraform Docs](https://www.serverless.com/framework/docs/guides/variables/terraform) [Vault Docs](https://www.serverless.com/framework/docs/guides/variables/vault)\\n- **Support Command:** Send support requests to our team [directly from the CLI](https://www.serverless.com/framework/docs/providers/aws/cli-reference/support), which auto-include contextual info which you can review before sending.\\n- **Debug Summary for AI:** When you run into a bug, you can run \"serverless support --ai\" to generate a concise report detailing your last bug with all necessary context, optimized for pasting into AI tools such as ChatGPT.\\n- **New AWS Lambda Runtimes:** \"python3.12\", \"dotnet8\", and \"java21\".\\n- **Advanced Logging Controls for AWS Lambda:** Capture Logs in JSON, increased log granularity, and setting a custom Log Group. Here is the [AWS article](https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/). Here is the [YAML implementation](https://github.com/serverless/serverless/blob/v4.0/docs/providers/aws/guide/serverless.yml.md#logs)\\n- **Axiom Integration:** Integrate with [Axiom\\'s observability solution](https://www.serverless.com/framework/docs/guides/observability/axiom) for a powerful logging, metrics and traces experience, at 3X less than AWS cloudwatch.\\n- **AWS SSO:** Environment variables, especially ones set by AWS SSO, are prioritized. The Framework and Dashboard no longer interfere with these.\\n- **Automatic Updates:** These happen by default now. Though, you will be able to control the level of updates you\\'re open to.\\n- **Improved Onboarding & Set-Up:** The `serverless` command has been re-written to be more helpful when setting up a new or existing project.\\n- **Updated Custom Resource Handlers:** All custom resource handlers now use `nodejs20.x`.\\n- **Deprecation Of Non-AWS Providers:** Deprecation of other cloud providers, in favor of handling this better in our upcoming Serverless Framework \"Extensions\".\\n\\n## Breaking Changes\\n\\nWe\\'re seeking to avoid breaking changes for the \"aws\" Provider. However, there are a few large things that are changing to be aware of:\\n\\n- The V.4 License is changing. See the section below for more information on this.\\n- Authentication is required within the CLI.\\n- Non-AWS Providers have been deprecated. We will be introducing new ways in V.4 to use other cloud infrastructure vendors.\\n\\nIf you stumble upon additional breaking changes, please create an issue. To learn more about what\\'s different and potential breaking changes, please see our [Upgrading to Serverless Framework V4 Documentation](https://www.serverless.com/framework/docs/guides/upgrading-v4).\\n\\n## License Changes in V.4\\n\\nPlease note, the structure and licensing of the V.4 repository differ from the V.4 npm module. The npm module contains some proprietary licensed software, as V.4 transitions to a common SaaS product, [as previously announced](https://www.serverless.com/blog/serverless-framework-v4-a-new-model). The original Serverless Framework source code and more will continue to remain MIT license software, the repository will soon be restructured to clearly distinguish between proprietary and open-source components.\\n\\n<br/>\\n\\n# Contents\\n\\n- [Features](#features)\\n- [Quick Start](#quick-start)\\n- [Examples](https://github.com/serverless/examples)\\n- [Plugins](https://github.com/serverless/plugins)\\n- [Community](#community)\\n\\n<br/>\\n\\n# <a name=\"features\"></a>Features'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3700229}, 'preview': \"# How to run, organize and write tests?\\n\\nAs framework deals with significant technical debt baggage many of currently configured tests do not\\nresemble practise we want to follow in newly introduced tests.\\n\\nPlease follow this document as the only guideline, it also provides links to tests that serve as a good example to replicate\\n\\n## Unit tests\\n\\nTests are configured with [Mocha](https://mochajs.org/) test framework, and can be run with following command\\n\\n```\\nnpm test\\n```\\n\\nAll new tests should be configured with help of [runServerless](./utils/run-serverless.js) util - it's the only way to test functionality against completely intialized `serverless` instance, and it's the only scenario that reflects real world usage.\\n\\nCheck documentation of `runServerless` at [@serverless/test/docs/run-serverless](https://github.com/serverless/test/blob/main/docs/run-serverless.md#run-serverless). Note that `runServerless` as configured at `./utils/run-serverless.js` supports two additional options (`fixture` and `configExt`), which provides out of a box setup to run _Serverless_ instance against prepared fixture with eventually extended service configuration\\n\\nAs `runServerless` tests are expensive, it's good to ensure a _minimal_ count of `runServerless` runs to test given scope of problems. Ideally with one service example we should cover most of the test cases we can (good example of such approach is [ALB health check tests](https://github.com/serverless/serverless/blob/80e70e7affd54418361c4d54bdef1561af6b8826/lib/plugins/aws/package/compile/events/alb/lib/healthCheck.test.js#L18-L127))\\n\\nWhen creating a new test, it is an established practice to name the top-level describe after the path to the file, as shown in [AWS Kafka tests](https://github.com/serverless/serverless/blob/b36cdf2db6ee25f7defe6f2c02dd40e1d5cb65c4/test/unit/lib/plugins/aws/package/compile/events/kafka.test.js#L10).\\n\\n### Existing test examples:\\n\\n- [Run against config passed inline](https://github.com/serverless/serverless/blob/73107822945a878abbdebe2309e8e9d87cc2858a/lib/plugins/aws/package/lib/generateCoreTemplate.test.js#L11-L14)\\n- [Run against preprepared fixture](https://github.com/serverless/serverless/blob/74634c3317a116077a008375e20d6a5b99b1256e/lib/plugins/aws/package/compile/functions/index.test.js#L2605-L2608)\\n  - Fixtures can be [extended](https://github.com/serverless/serverless/blob/74634c3317a116077a008375e20d6a5b99b1256e/lib/plugins/aws/package/compile/events/httpApi/index.test.js#L95-L99) on spot. Whenever possible it's better to extend existing fixture (e.g. basic `function`) instead of creating new one (check [ALB health check tests](https://github.com/serverless/serverless/blob/80e70e7affd54418361c4d54bdef1561af6b8826/lib/plugins/aws/package/compile/events/alb/lib/healthCheck.test.js) for good example on such approach)\\n  - If needed introduce new test fixtures at [test/fixtures](./fixtures)\\n\\nExample of test files fully backed by `runServerless`:\\n\\n- [lib/plugins/aws/package/compile/events/httpApi.js](https://github.com/serverless/serverless/blob/main/lib/plugins/aws/package/compile/events/httpApi.js)\\n\\nIf we're about to add new tests to an existing test file with tests written old way, then best is to create another `describe` block for new tests at the bottom (as it's done [here](https://github.com/serverless/serverless/blob/main/test/unit/lib/plugins/aws/package/compile/functions.test.js#L1049))\\n\\n_Note: PR's which rewrite existing tests into new method are very welcome! (but, ideally each PR should cover single test file rewrite)_\\n\\n### Coverage\\n\\nWe aim for a (near) 100% test coverage, so make sure your tests cover as much of your code as possible.\\n\\nDuring development, you can easily check coverage by running `npm run coverage`, then opening the `index.html` file inside the `coverage` directory.\\n\\n## AWS Integration tests\\n\\nRun all tests via:\\n\\n```\\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=xxx npm run integration-test-run-all\\n```\\n\\n_Note: Home folder is mocked for test run, therefore relying on `AWS_PROFILE` won't work. _ and _secret key_, need to be configured directly into env variables\\\\_\\n\\n_Note: Some integration tests depend on shared infrastructure stack (see below)_\\n\\nIdeally any feature that integrates with AWS functionality should be backed by integration test.\\n\\nCheck existing set of AWS integration tests at [test/integration](./integration)\\n\\n### Running specific integration test\\n\\nPass test file to Mocha directly as follows\\n\\n```\\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=xxx npx mocha test/integration/{chosen}.test.js\\n```\\n\\n### Tests that depend on shared infrastructure stack\\n\\nDue to the fact that some of the tests require a bit more complex infrastructure setup which might be lengthy, two additional commands has been made available:\\n\\n- `integration-test-setup` - used for setting up all needed intrastructure dependencies\\n- `integration-test-teardown` - used for tearing down the infrastructure setup by the above command\\n\\nSuch tests take advantage of `isDependencyStackAvailable` util to check if all needed dependencies are ready. If not, it skips the given test suite.\\n\\nExamples of such tests:\\n\\n- [MSK](./integration/aws/infra-dependent/msk.test.js)\\n- [ActiveMQ](./integration/infra-dependent/active-mq.test.js)\\n- [RabbitMQ](./integration/infra-dependent/rabbit-mq.test.js)\\n- [FileSystemConfig](./integration/infra-dependent/file-system-config.test.js)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md', 'node_id': 3723675}, 'preview': \"# Hack\\n\\nThis directory contains code which performs raw SDK calls rather than going through CloudFormation template compilations.\\n\\nWe're planning to port the logic of these code snippets to raw CloudFormation once AWS fixes the problems currently preventing us from solely relying on CloudFormation.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/custom-resources/resources/README.md', 'node_id': 3730097}, 'preview': '# Serverless Custom CloudFormation Resources\\n\\nThis directory contains the Lambda functions for the Serverless Custom CloudFormation Resources.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/README.md', 'node_id': 3734424}, 'preview': '<!--\\ntitle: \\'Serverless Framework Documentation\\'\\nshort_title: \\'Introduction to the Serverless Framework\\'\\ndescription: \\'An introduction to the Serverless Framework, its philosophy, overview, and key highlights. Learn how to build serverless applications efficiently with minimal maintenance.\\'\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'AWS Lambda\\',\\n    \\'Serverless Documentation\\',\\n    \\'Serverless Architectures\\',\\n    \\'Cloud Infrastructure\\',\\n    \\'Serverless CLI\\',\\n    \\'Serverless Dashboard\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework - An Introduction\\n\\n## Philosophy\\n\\n**_Build applications that demand attention, not maintenance._**\\n\\nIn 2014, AWS Lambda was introduced offering a more efficient compute service in the cloud. With features like auto-scaling and no cost when idle, AWS Lambda offers a compute experience that demands so little maintenance it feels _\"serverless\"_.\\n\\nMonths later, the Serverless Framework was created to streamline the deployment of various use-cases on AWS Lambda. The Serverless Framework introduced the concept of _\"serverless architectures\"_, a transformative approach to building applications on the cloud, integrating AWS Lambda and cloud infrastructure with similar \"serverless\" qualities, to enable developers to create entire applications that scale massively with minimal maintenance.\\n\\nToday, the Serverless Framework continues to be the original, leading and most trusted tool for enterprises and start-ups building serverless architectures. Renowned Fortune 500 companies such as the _New York Times_, _Nike_, and _EA Games_ utilize it, while numerous startups have reached unicorn valuations and achieved notable exits using the Framework. These successes have been accomplished with relatively small engineering teams, leveraging the power of serverless architectures.\\n\\nThe mission of the Serverless Framework is to empower all developers to build more and manage less.\\n\\n## Overview\\n\\nThe Serverless Framework consists of a Command Line Interface and an optional Dashboard, and helps you deploy code and infrastructure together on Amazon Web Services, while increasingly supporting other cloud providers. The Framework is a YAML-based experience that uses simplified syntax to help you deploy complex infrastructure patterns easily, without needing to be a cloud expert. It is developed and maintained by Serverless Inc., a specialized software company based in San Francisco, California. Initially launched as an open-source project, the Framework has since transitioned to a SaaS product to better support its scalability and the extensive infrastructure capabilities it offers.\\n\\n## Highlights\\n\\n- **Empowerment:** Innovate faster by spending less time on infrastructure management.\\n- **Versatility:** Tackle diverse serverless use cases, from APIs and scheduled tasks to web sockets and data pipelines.\\n- **Infra & Code:** Streamline development with code and infrastructure deployment handled together.\\n- **Ease of Use:** Deploy complex applications without deep cloud infrastructure expertise, thanks to approachable YAML configuration.\\n- **Language Agnostic:** Develop in your preferred language – Node.js, Python, Java, Go, C#, Ruby, Swift, Kotlin, PHP, Scala, or F# – the Framework supports them all.\\n- **Full Lifecycle:** Build, deploy, monitor, update, and troubleshoot serverless applications with ease.\\n- **Scalable Organization:** Structure large projects and teams efficiently with built-in support for stages and project composition.\\n- **Plugin Ecosystem:** Extend and modify the Framework\\'s functionality with a rich plugin ecosystem.\\n- **Vibrant Community:** Get support and connect with a passionate community of Serverless developers.\\n\\n## Next Steps\\n\\nGet started with the Serverless Framework on AWS [via this guide](https://serverless.com/framework/docs/getting-started/).\\n\\nHave questions? Join thousands of other developers in our [Slack Channel](https://serverless.com/slack).\\n\\nAfter that, we recommend you...\\n\\n- [Learn Serverless Framework\\'s Core Concepts](https://www.serverless.com/framework/docs/providers/aws/guide/intro)\\n- [Get inspiration from these Serverless Framework Templates](https://github.com/serverless/examples)\\n- [Discover all of the events that can trigger AWS Lambda functions](https://www.serverless.com/framework/docs/providers/aws/guide/events)\\n- [Bookmark Serverless Framework\\'s `serverless.yml` guide](https://www.serverless.com/framework/docs/providers/aws/guide/serverless.yml)\\n- [Search the plugins registry to extend Serverless Framework](https://www.serverless.com/plugins)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/README.md', 'node_id': 3734434}, 'preview': \"<!--\\ntitle: Serverless Framework - AWS Documentation\\ndescription: Comprehensive guide to using AWS as the default cloud provider with the Serverless Framework.\\nshort_title: AWS Provider Documentation\\nkeywords:\\n  ['Serverless Framework', 'AWS', 'Cloud Provider', 'Serverless Documentation']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# AWS Provider Documentation\\n\\nAWS is the default cloud provider used by Serverless Framework.\\n\\n**All the Serverless Framework documentation applies to AWS by default**. This is why there is no sub-documentation specific to AWS: everything related to AWS is already covered by the documentation.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/guide/README.md', 'node_id': 3734439}, 'preview': \"<!--\\ntitle: Serverless Framework - AWS Guide\\nshort_title: AWS Guide\\ndescription: An introduction to using AWS and AWS Lambda with the Serverless Framework.\\nkeywords: ['Serverless Framework', 'AWS Lambda', 'AWS Guide', 'Serverless']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/guide/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless AWS Lambda Guide\\n\\nWelcome to the Serverless AWS Lambda Guide!\\n\\nGet started with the [Introduction to the framework](./intro.md)\\n\\nIf you have questions, join the [chat in Slack](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/examples/README.md', 'node_id': 3734484}, 'preview': \"<!--\\ntitle: Serverless - AWS Lambda - Examples\\nshort_title: Serverless Examples\\ndescription: AWS Lambda examples using the Serverless Framework.\\nkeywords:\\n  ['Serverless Framework', 'AWS Lambda', 'examples', 'serverless functions']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/examples/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# AWS Serverless Examples\\n\\nSearch for AWS Serverless Examples using our [Example Explorer](https://serverless.com/examples/).\\n\\nHave an example? Submit a PR or [open an issue](https://github.com/serverless/examples/issues). ⚡️\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/events/README.md', 'node_id': 3734486}, 'preview': \"<!--\\ntitle: Serverless - AWS Lambda - Events\\ndescription: AWS Serverless Events Glossary covering various event sources for AWS Lambda.\\nshort_title: AWS Lambda Events\\nkeywords: ['Serverless', 'Framework', 'AWS', 'Lambda', 'Events']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/events/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless AWS Lambda Events\\n\\nWelcome to the AWS Serverless Events Glossary.\\n\\nPlease select a section on the left to get started, or see the [user\\nguide](../guide/events.md) for general information regarding Lambda Events in\\nServerless.\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/cli-reference/README.md', 'node_id': 3734542}, 'preview': '<!--\\ntitle: Serverless - AWS Lambda - CLI Reference\\nmenuText: CLI Reference\\nshort_title: CLI Reference\\nlayout: Doc\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/providers/aws/cli-reference/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless CLI Reference for AWS\\n\\nWelcome to the Serverless Framework CLI Reference for AWS. Please select a section on the left to get started.\\n\\nIf you have questions, join the [Slack community](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/README.md', 'node_id': 3734581}, 'preview': \"<!--\\ntitle: Serverless Framework - User Guides\\ndescription: Discover comprehensive user guides for Serverless Framework, covering everything from getting started to advanced topics. Join the community chat on Slack or participate in the forums for more support.\\nshort_title: User Guides\\nkeywords:\\n  [\\n    'Serverless Framework',\\n    'user guides',\\n    'getting started',\\n    'advanced topics',\\n    'community',\\n    'Slack',\\n    'forums',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework User Guides\\n\\nWelcome to the Serverless Framework User Guides!\\n\\n[Get started with Serverless Framework](/framework/docs/getting-started)\\n\\nIf you have questions, join the [chat in Slack](https://serverless.com/slack) or [post over on the forums](https://forum.serverless.com/)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/README.md', 'node_id': 3734595}, 'preview': '<!--\\ntitle: Serverless Framework - Variables\\ndescription: How to use Serverless Variables to insert dynamic configuration info into your serverless.yml\\nshort_title: Variables\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'Variables\\',\\n    \\'serverless.yml\\',\\n    \\'dynamic configuration\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/variables)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Variables\\n\\nVariables allow users to dynamically replace config values in `serverless.yml` config.\\n\\nThey are especially useful when providing secrets for your service to use and when you are working with multiple stages.\\n\\n## Syntax\\n\\nTo use variables, you will need to reference values enclosed in `${}` brackets.\\n\\n```yml\\n# serverless.yml file\\nyamlKeyXYZ: ${provider:resolver:key} # see list of current resolver providers below\\n# this is an example of providing a default value as the second parameter\\notherYamlKey: ${provider:resolver:key, defaultValue}\\n```\\n\\n**Note:** You can only use variables in `serverless.yml` property **values**, not property keys. So you can\\'t use variables to generate dynamic logical IDs in the custom resources section for example.\\n\\n## Variable Resolvers\\n\\nVariable Resolvers allow you to reference external data sources in your serverless.yml file.\\nEach Resolver has a Provider parent, which is responsible for fetching the credentials.\\nFor example, the `aws` Provider has a `ssm` Resolver and a `s3` Resolver,\\nwhich can fetch data from AWS SSM Parameter Store and S3, respectively.\\n\\nProviders can also have default variables that can be used in the serverless.yml file,\\nsuch as `accountId` for the `aws` Provider.\\n\\nYou can customize Providers and Resolvers by specifying custom configuration options in the `resolvers` block of the `stages` section.\\nThen, you can reference the customized Resolvers using `${customProviderName:customResolverName:key}` syntax.\\n\\n**You can always reference the default Resolvers provided by Providers, even if you don’t define them explicitly.**\\nFor example,\\nyou can reference the default `s3` Resolver provided by the `aws` Provider using `${aws:s3:myBucket/myKey}` syntax\\n(it will use the AWS provider which provides the credentials for the deployment),\\nor `${customProviderName:s3:myBucket/myKey}` if you define customized Provider configuration.\\n\\n### Examples\\n\\n#### Default Resolvers\\n\\n```yaml\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    environment:\\n      ACCOUNT_ID: ${aws:accountId} # built-in variable provided by the AWS provider\\n      SSM_VALUE: ${aws:ssm:/path/to/param} # uses the default resolver configuration and the same AWS provider which is used for the deployment\\n      S3_VALUE: ${aws:s3:myBucket/myKey} # uses the default resolver configuration and the same AWS provider which is used for the deployment\\n```\\n\\n#### Customized Resolvers\\n\\n```yaml\\nstages:\\n  default:\\n    resolvers:\\n      awsAccount1:\\n        type: aws\\n        profile: dev-account1-profile-name\\n      awsAccount2:\\n        type: aws\\n        profile: dev-account2-profile-name\\n        euS3: # custom resolver configuration defined for the awsAccount2 provider\\n          type: s3\\n          region: eu-west-1\\n  prod:\\n    resolvers:\\n      awsAccount1:\\n        type: aws\\n        profile: prod-account1-profile-name\\n      awsAccount2:\\n        type: aws\\n        profile: prod-account2-profile-name\\n        euS3: # custom resolver configuration defined for the awsAccount2 provider\\n          type: s3\\n          region: eu-west-1\\n\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    environment:\\n      ACCOUNT1_ID: ${awsAccount1:accountId} # built-in variable provided by the AWS provider\\n      SSM_VALUE: ${awsAccount1:ssm:/path/to/param} # uses the default resolver configuration even if it\\'s not explicitly defined in the resolvers block\\n      EU_S3_VALUE: ${awsAccount2:euS3:myBucket/myKey} # uses the customized resolver configuration\\n      S3_VALUE: ${awsAccount2:s3:myBucket/myKey} # uses the default resolver configuration even if a customized one (euS3) is defined for the same provider\\n```\\n\\n## Supported Variable Providers:\\n\\n- [Self-References Properties Defined in `serverless.yml`](./self)\\n- [Serverless Core Variables](./core)\\n- [Environment Variables](./env-vars)\\n- [CLI Options](./cli-options)\\n- [External YAML/JSON Files](./file)\\n- [Dynamic Values from Javascript](./javascript)\\n- [Git](./git)\\n- [AWS](./aws)\\n- [HashiCorp](./hashicorp)\\n\\n## Recursively reference properties\\n\\nYou can also **recursively reference properties** with the variable system. This means you can combine multiple values and variable sources for a lot of flexibility.\\n\\nFor example:\\n\\n```yml\\nprovider:\\n  name: aws\\n  environment:\\n    MY_SECRET: ${file(./config.${sls:stage}.json):CREDS}\\n```\\n\\nIf `sls deploy --stage qa` is run, the stage will be set to `qa`, which is used inside the `${file(./config.${sls:stage}.json):CREDS}` variable and it will resolve the `config.qa.json` file and use the `CREDS` key defined.\\n\\n**How that works:**\\n\\n1. `stage` is set to `qa` from the option supplied to the `sls deploy --stage qa` command. If no option is defined, then `${sls:stage}` will use the value in `provider.stage` or default to `dev` if not set.\\n2. `${sls:stage}` resolves to `qa` and is used in `${file(./config.${sls:stage}.json):CREDS}`\\n3. `${file(./config.qa.json):CREDS}` is found & the `CREDS` value is read\\n4. `MY_SECRET` value is set\\n\\nLikewise, if `sls deploy --stage prod` is run the `config.prod.json` file would be found and used.\\n\\n## Setting Variables using Parameters\\n\\nOccasionally you may want to set a variable directly in the `serverless.yml` that you can use throughout the file. In such a case you can use Parameters to set new variables or use them to set stage-specific variables.\\n\\nHere is an example of setting a domain variable based on the stage:\\n\\n```yaml\\nstages:\\n  default:\\n    params:\\n      domain: ${sls:stage}.example-dev.com\\n  prod:\\n    params:\\n      domain: example.com\\n\\nprovider:\\n  environment:\\n    APP_DOMAIN: ${param:domain}\\n```\\n\\nRead all about parameters in the [Parameters documentation](../../guides/parameters.md).\\n\\n## Multiple Configuration Files\\n\\nAdding many custom resources to your `serverless.yml` file could bloat the whole file, so you can use the Serverless Variable syntax to split this up.\\n\\n```yml\\nresources:\\n  Resources: ${file(cloudformation-resources.json)}\\n```\\n\\nThe corresponding resources which are defined inside the `cloudformation-resources.json` file will be resolved and loaded into the `Resources` section.\\n\\nIn order to use multiple resource files combined with resources inside the `serverless.yml` you can use an array.\\n\\n```yml\\nresources:\\n  - Resources:\\n      ApiGatewayRestApi:\\n        Type: AWS::ApiGateway::RestApi\\n\\n  - ${file(resources/first-cf-resources.yml)}\\n  - ${file(resources/second-cf-resources.yml)}\\n\\n  - Outputs:\\n      CognitoUserPoolId:\\n      Value:\\n        Ref: CognitoUserPool\\n```\\n\\nEach of your cloudformation files has to start with a `Resources` entity\\n\\n```yml\\nResources:\\n  Type: \\'AWS::S3::Bucket\\'\\n  Properties:\\n    BucketName: some-bucket-name\\n```\\n\\n## Default values\\n\\nThe Serverless framework gives you an intuitive way to reference multiple variables as a fallback strategy in case one of the variables is missing. This way you\\'ll be able to use a default value from a certain source, if the variable from another source is missing.\\n\\nFor example, you can use the `opt` variable to get the `memory` CLI option when running `serverless deploy --memory 2048`. If the `memory` option is not provided, the default value of `1024` will be used.\\n\\n```yml\\nfunctions:\\n  hello:\\n    handler: handler.hello\\n    memorySize: ${opt:memory, 1024}\\n```\\n\\nThe default value can also reference another variable.\\n\\n## Read String Variable Values as Boolean Values\\n\\nIn some cases, a parameter expect a `true` or `false` boolean value. If you are using a variable to define the value, it may return as a string (e.g. when using SSM variables) and thus return a `\"true\"` or `\"false\"` string value.\\n\\nTo ensure a boolean value is returned, read the string variable value as a boolean value. For example:\\n\\n```yml\\nprovider:\\n  tracing:\\n    apiGateway: ${strToBool(${ssm:API_GW_DEBUG_ENABLED})}\\n```\\n\\nThese are examples that explain how the conversion works after first lowercasing the passed string value:\\n\\n```plaintext\\n${strToBool(true)} => true\\n${strToBool(false)} => false\\n${strToBool(True)} => true\\n${strToBool(False)} => false\\n${strToBool(TRUE)} => true\\n${strToBool(FALSE)} => false\\n${strToBool(0)} => false\\n${strToBool(1)} => true\\n${strToBool(2)} => Error\\n${strToBool(null)} => Error\\n${strToBool(anything)} => Error\\n```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/hashicorp/README.md', 'node_id': 3734607}, 'preview': '<!--\\ntitle: Serverless Framework - Variables - HashiCorp-specific variables\\ndescription: >-\\n  How to reference HashiCorp-specific variables in the Serverless Framework for\\n  efficient configuration and deployment.\\nshort_title: Serverless Variables - HashiCorp Variables\\nkeywords:\\n  - Serverless Framework\\n  - HashiCorp-specific variables\\n  - configuration\\n  - deployment\\n-->\\n\\n# Resolvers\\n\\n- [HashiCorp Terraform State Outputs](terraform)\\n- [HashiCorp Vault Secrets](vault)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/aws/README.md', 'node_id': 3734618}, 'preview': '<!--\\ntitle: Serverless Framework - Variables - AWS-specific variables\\ndescription: >-\\n  How to reference AWS-specific variables in the Serverless Framework for\\n  efficient configuration and deployment.\\nshort_title: Serverless Variables - AWS Variables\\nkeywords:\\n  - Serverless Framework\\n  - AWS-specific variables\\n  - configuration\\n  - deployment\\n  - accountId\\n  - region\\n-->\\n\\n# Resolvers\\n\\n- [AWS S3](s3)\\n- [AWS SSM Parameter Store & Secrets Manager](ssm)\\n- [AWS CloudFormation Outputs](cf-stack)\\n\\n# Configuration options\\n\\n| Option            | Required |  Type   |  Default  | Description                                                          |\\n| ----------------- | :------: | :-----: | :-------: | :------------------------------------------------------------------- |\\n| `accessKeyId`     |    No    | String  |           | AWS Access Key ID                                                    |\\n| `secretAccessKey` |    No    | String  |           | AWS Secret Access Key                                                |\\n| `sessionToken`    |    No    | String  |           | AWS Session Token                                                    |\\n| `region`          |    No    | String  | us-east-1 | AWS region                                                           |\\n| `profile`         |    No    | String  |           | AWS profile name                                                     |\\n| `dashboard`       |    No    | Boolean |   true    | Whether Serverless Dashboard AWS Provider credentials should be used |\\n\\n## Example\\n\\n```yaml\\nstages:\\n  default:\\n    resolvers:\\n      aws-account-1:\\n        type: aws\\n        profile: account1-profile-name\\n        region: us-west-2\\n        accessKeyId: ${env:ACCOUNT1_AWS_ACCESS_KEY_ID}\\n        secretAccessKey: ${env:ACCOUNT1_AWS_SECRET_ACCESS_KEY}\\n        dashboard: false\\n```\\n\\n# Provider-specific variables\\n\\nYou can reference AWS-specific values as the source of your variables. Those values are exposed via the Serverless Variables system through:\\n\\n1. `{providerName:}` variable prefix which should be the name of the resolver provider specified in the `resolvers` block (`aws-account-1` in the example above).\\n2. `{aws:}` variable prefix which uses the deployment credentials.\\n\\nThe following variables are available:\\n\\n**accountId**\\n\\nAccount ID of you AWS Account, based on the AWS Credentials that you have configured.\\n\\n```yml\\nservice: new-service\\nprovider:\\n  name: aws\\n\\nfunctions:\\n  func1:\\n    name: function-1\\n    handler: handler.func1\\n    environment:\\n      ACCOUNT_ID: ${aws:accountId}\\n```\\n\\n**region**\\n\\nThe region used by the Serverless CLI. The `${aws:region}` variable is a shortcut for `${opt:region, self:provider.region, \"us-east-1\"}`.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/plugins/README.md', 'node_id': 3734630}, 'preview': '<!--\\ntitle: Serverless Framework - Plugins\\ndescription: How to install plugins to customize the Serverless Framework\\nshort_title: Plugins\\nkeywords: [\\'Serverless Framework\\', \\'Plugins\\', \\'Installation\\', \\'Customization\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/plugins)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Plugins\\n\\nA plugin is custom JavaScript code that extends the Serverless Framework with new features.\\n\\nIf you or your organization have a specific workflow, install a pre-written plugin or write one to customize the Framework to your needs.\\n\\nSince the Serverless Framework is a group of \"core\" plugins, custom plugins are written exactly the same way as core plugins. Learn more about [creating a custom plugin](./creating-plugins.md).\\n\\nExplore existing plugins in the [Serverless Framework Plugins repository](https://www.serverless.com/plugins).\\n\\n## Installing plugins\\n\\nPlugins are installed per service. They are not applied globally.\\n\\nTo install a plugin, run the following command in a service directory:\\n\\n```\\nserverless plugin install -n custom-serverless-plugin\\n```\\n\\nThis command will install the plugin via NPM and register it in `serverless.yml`.\\n\\nYou can also install the plugin manually via NPM:\\n\\n```\\nnpm install --save-dev custom-serverless-plugin\\n```\\n\\nand then register it in `serverless.yml` in the `plugins` section:\\n\\n```yml\\n# serverless.yml file\\n\\nplugins:\\n  - custom-serverless-plugin\\n```\\n\\nSome plugins require extra configuration. The `custom` section in `serverless.yml` is where you can add extra configuration for plugins (the plugin\\'s documentation will tell you if you need to add anything there):\\n\\n```yml\\nplugins:\\n  - custom-serverless-plugin\\n\\ncustom:\\n  customkey: customvalue\\n```\\n\\nNote for plugin authors: read [Extending the configuration](./custom-configuration.md) to learn how to enhance `serverless.yml` with configuration validation.\\n\\n## Service local plugin\\n\\nIf you are working on a plugin, or have a plugin that is just designed for one project, it can be loaded from local files:\\n\\n```yml\\nplugins:\\n  - ./local-directory/custom-serverless-plugin\\n```\\n\\nThe path must start with `./` and is relative to the root of your service.\\n\\n## Load Order\\n\\nKeep in mind that the order you define your plugins matters. Serverless loads all the core plugins, and then the custom plugins in the order you\\'ve defined them.\\n\\n```yml\\n# serverless.yml\\n\\nplugins:\\n  - plugin1\\n  - plugin2\\n```\\n\\nIn this case `plugin1` is loaded before `plugin2`.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/observability/README.md', 'node_id': 3734645}, 'preview': \"<!--\\ntitle: Serverless Framework - Observability\\ndescription: How to configure observability for your Serverless Framework services\\nshort_title: Observability\\nkeywords: ['Serverless Framework', 'Observability', 'Monitoring']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/observability)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Observability\\n\\nObservability is a crucial aspect of managing and maintaining your serverless applications. It provides insights into the behavior, performance, and health of your services. The Serverless Framework allows you to automatically configure observability for your services.\\n\\n## Enabling Observability\\n\\nThe Serverless Framework supports multiple observability providers. You can configure it to work with your preferred provider using the `observability` property within the `stages` block in your `serverless.yml` file.\\nBelow is an example of how to enable the Serverless Dashboard observability feature for the `prod` stage:\\n\\n```yaml\\nstages:\\n  prod:\\n    observability: dashboard\\n```\\n\\n## Configuring Observability\\n\\nFor more granular control, you can specify the observability key as an object and include additional properties. In this configuration, the `provider` key is required, and you must specify the desired provider.\\n\\n```yaml\\nstages:\\n  prod:\\n    observability:\\n      provider: dashboard\\n      # additional configuration options for the chosen provider\\n      exampleSetting: customValue\\n```\\n\\n## Next Steps\\n\\nLearn more about configuring and using our supported observability providers:\\n\\n- [Serverless Dashboard](./dashboard)\\n- [Axiom](./axiom)\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/README.md', 'node_id': 3734653}, 'preview': '<!--\\ntitle: Serverless Framework Dashboard - Setup & Overview\\ndescription: An overview and set-up guide for Serverless Framework Dashboard\\nshort_title: Serverless Dashboard - Setup & Overview\\nkeywords: [\\'Serverless Framework\\', \\'Dashboard\\', \\'Setup\\', \\'Overview\\']\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/dashboard/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework Dashboard\\n\\nThe [Serverless Framework Dashboard](https://app.serverless.com/) is a SaaS solution that augments the Serverless Framework CLI to provide a powerful, unified experience to develop, deploy, test, secure and monitor your serverless applications, across all AWS accounts.\\n\\nThe aim of the Serverless Framework and its Dashboard is to offer a seamless, integrated development experience for you and your team throughout the entire lifecycle of your serverless applications. We hope it\\'s a breath of fresh air compared to the complexity of interacting with the AWS Console across several accounts, directly.\\n\\n## Features\\n\\n- **Deployments:** Easily see all Serverless Framework deployments made by you and your team, via CI/CD or local installations of the CLI, across all of your AWS accounts, in one place. Quickly check who made the deployment, what the status is, how it may have failed, see git metadata, serverless.yml, outputs, and much more.\\n\\n- **Secrets:** Set and share secrets in one place, for use within your Serverless Framework `serverless.yml` files. This works across all AWS accounts, so it\\'s ideal for making secrets easy to use without wrestling with AWS permissions to access them. Secrets are encrypted and secure by default.\\n\\n- **Observability:** The richest and slickest observability solution for AWS Lambda on the market. We\\'ve spent years crafting an observability solution that developers love, specializing in AWS Lambda. Set-up requires zero effort and you will instantly get rich Metrics, Traces, Logs and Alerts, just deploy with the Serverless Framework. The Observability features also support non-Serverless Framework deployed AWS Lambda functions. Simply connect your AWS accounts and you\\'ll be able to instrument all of the AWS Lambda functions in them.\\n\\n- **Providers:** Providers make it easy to manage deployment access to your AWS accounts. Each Provider connects to 1 AWS account, and you can assign it to specific Services, Stages, or set a Provider as a default across an entire AWS account. This enables your team to never have to deal with local AWS credentials. Providers use an AWS IAM Role to connect to your account and provide short-term credentials for every deployment, which is more secure by default.\\n\\n- **CI/CD:** CI/CD optimized for Serverless Framework that works out-of-the-box. Simply connect it to Github or BitBucket to enable automated deployments. Set up preview deployments for branches, and much more.\\n\\n## Minimum Version Requirements\\n\\nTo use Serverless Framework Dashboard, you must be using Serverless Framework CLI version 1.48.0 or later.\\n\\nFor Serverless Framework\\'s new Observability offering, you must use version 3.35.0 or later.\\n\\n## Set-Up\\n\\nIf you don\\'t already have a Serverless Framework account, create a new account at [https://app.serverless.com](https://app.serverless.com).\\n\\nIf you don\\'t have existing Serverless Framework Services, follow the [Getting Started with the Serverless Framework and AWS](../../getting-started.md) guide. This will help you get a Serverless Framework Service deployed to AWS, and enabled with the Dashboard.\\n\\nIf you have existing Serverless Framework Services, in the directory with your Service\\'s `serverless.yml` file, run the `serverless` command. This will walk you through the setup process, including setting up your AWS account credentials and creating an organization and application from the Dashboard. Once completed, you\\'ll notice that the `org` and `app` fields will be added to your `serverless.yml` to indicate the org/app to which this service belongs.\\n\\nYou can also add the configuration manually to your `serverless.yml` files within your Serverless Framework Services to connect to the Dashboard.\\n\\n```YAML\\n\\norg: # Your Serverless Framework Org name (e.g. acme-inc)\\napp: # A parent namespce for this Service and related Services App name (e.g. mobile-app), to improve Serverless Framework Dashboard organization\\n\\n```\\n\\nYou must deploy your Service with the above configuration in your YAML file to have it show in the Dashboard. Run serverless deploy to do this.\\n\\nIf you want to enable Observability (metrics, traces, logs) for your AWS Lambda functions within Serverless Framework Dashboard, you will have to add the following in the stages block of your serverless.yml:\\n\\n```yml\\nstages:\\n  prod:\\n    observability: true # turn on observability in the \"prod\" Stage.\\n  dev:\\n    observability: true # turn on observability in the \"dev\" Stage.\\n  default:\\n    observability: false # turn off observability for all other Stages.\\n```\\n\\nTo set up Observability, Serverless Framework will automatically create an AWS IAM Role within the AWS account you deployed to, giving Serverless Inc permission to AWS Cloudwatch and more. [You can transparently see the permissions this role requires in Github](https://github.com/serverless/console/blob/main/instrumentation/aws/iam-role-cfn-template.yaml)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/README.md', 'node_id': 3734662}, 'preview': '<!--\\ntitle: Serverless Framework - Monitoring & Observability - Overview & Setup\\ndescription: An overview and setup guide for Serverless Framework\\'s Monitoring & Observability features, including metrics, traces, logs, and more.\\nshort_title: Serverless Dashboard Observability - Overview & Setup\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'Monitoring\\',\\n    \\'Observability\\',\\n    \\'Setup\\',\\n    \\'Metrics\\',\\n    \\'Traces\\',\\n    \\'Logs\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/monitoring/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Monitoring & Observability\\n\\nEasily monitor and observe AWS Lambda functions with Serverless Framework. Access Metrics, Traces, Logs, Errors, and more, across all AWS accounts and Serverless Framework Services.\\n\\nWorks with or without deploying through Serverless Framework. Just connect your AWS account.\\n\\n## Features\\n\\n- A global view of Metrics, Traces, Logs, and Errors across all AWS accounts.\\n- Easily search through data via powerful filters.\\n- Instant error alerts.\\n- Auto-sample trace data to save costs.\\n- Detect code-defined API routes, like in Express.js.\\n- No set-up or complex instrumentation required.\\n\\n## Set-Up\\n\\nCurrently Serverless Framework Monitoring & Observability supports the Node.js 12+ and Python 3.8+ AWS Lambda runtimes only, and only AWS Commercial Regions (not GovCloud or China Regions).\\n\\nTo enable Serverless Framework Monitoring & Observability, first create a Serverless Framework account [here](https://app.serverless.com).\\n\\nNext, you must connect your AWS account(s) directly to Serverless Framework\\'s platform via an IAM Role. The permissions for this IAM Role are available in the [Dashboard Github Repo](https://github.com/serverless/dashboard), for your review.\\n\\nThere are two ways to connect your AWS account(s), _via Serverless Framework CLI_, and _via Serverless Framework Dashboard UI_.\\n\\nPlease note, enabling Serverless Framework\\'s Monitoring & Observability features will create a few resources on AWS accounts they\\'re connected to, adding minimal costs to your AWS accounts.\\n\\n### Set-Up Via Serverless Framework Dashboard UI\\n\\nThe most convenient way to set up Monitoring & Observability for multiple AWS accounts or accounts with many AWS Lambda functions is to do so via the Serverless Framework Dashboard UI.\\n\\nIn the navigation bar on the left, click on the \"Settings\" icon, and then click on the \"Integrations\" tab. Here is where you connect AWS accounts.\\n\\nIn a separate browser window, log into the AWS Account via the browser that you wish to connect to. You will need to have permission to create IAM Roles with the [required permissions](https://github.com/serverless/dashboard) for Monitoring & Observability.\\n\\nIn the \"Integrations\" view, click the \"Add Integrations\" button. This launches a quick process that opens a new browser window containing AWS Console\\'s AWS CloudFormation Stack Create view. This window is pre-loaded with an AWS CloudFormation Stack Template that contains an AWS IAM Role with all of the permissions Serverless Framework\\'s Monitoring & Observability features need. At the bottom of this page, click \"Create\".\\n\\nWhile the CloudFormation Stack is creating, go back to the Serverless Framework Dashboard. The Integration view should have detected your Stack is being created and this view will continue to update in real-time until the integration is completed. No other steps are required on your behalf.\\n\\nRepeat this step to connect as many AWS accounts that you\\'d like to enable Monitoring & Observability for.\\n\\nOnce an AWS account is connected, you will need to choose the AWS Lambda functions you wish to enable Monitoring & Observability on. You should see a newly created AWS Integration in the \"Integrations\" view. We recommend giving that AWS Account a name (e.g. \"production\", \"development\") so it\\'s easier to remember and find in Dashboard\\'s query filters. On the Integration, click the \"Edit\" button, and you will see all of the AWS Lambda functions within that AWS account.\\n\\nClick the \"Instrument\" toggle on individual AWS Lambda functions, or click the toggle in the table header to enable instrumentation on all of the functions within that page (you\\'ll have to repeat this on each page if you have multiple pages of AWS Lambda functions). Click \"Save\". This will instrument the AWS Lambda functions in the background. You can go through each page and continue to instrument AWS Lambda functions since instrumentation happens asynchronously.\\n\\nGo to the Metrics or Explorer view. Make sure your AWS Lambda functions are being invoked. After a few minutes, you should see data appear.\\n\\nPlease note, Metrics, Traces and more typically can take up to 10 minutes before they are visible in Serverless Framework Dashboard, after an AWS account has been integrated.\\n\\n### Set-Up Via Serverless Framework CLI\\n\\nYou can use the Serverless Framework CLI to enable Monitoring & Observability. This approach will automatically connect the Serverless Framework Platform to an AWS account and enable monitoring on all of the AWS Lambda functions for the selected stages within the Serverless Framework Service.\\n\\nHowever, if you want to connect multiple AWS accounts and/or enable monitoring on all AWS Lambda functions within an AWS account, setting it up via the Serverless Framework Dashboard UI is more convenient, as you can accomplish this in a few clicks.\\n\\nWithin the working directory of a Serverless Framework Service, ensure the Service is first connected to the Serverless Framework Dashboard. This can be confirmed by the presence of an org and app properties within the serverless.yml file. If the Service is not connected to the Dashboard, run the `serverless` command within the working directory of the Serverless Framework Service. Once your service is connected to the Serverless Dashboard, you can control your observability instrumentation settings under the stages property in your serverless.yml file:\\n\\n```yml\\n# Ensure these properties are present to connect to the Dashboard\\norg: my-org\\napp: my-app\\n\\n# Control observability instrumentation settings under stages\\nstages:\\n  dev:\\n    observability: true # Turn on observability in the dev stage\\n  prod:\\n    observability: true # Turn on observability in the prod stage\\n  default:\\n    observability: false # Turn off observability in all other stages\\n```\\n\\nNow, whenever you deploy, observability will be enabled or disabled according to the stage you are deploying to. In the above example, observability will be enabled in the dev and prod stages but disabled in all other stages.\\n\\nAfter deployment, confirm everything worked within the Serverless Framework Dashboard. Go to \"Settings\" > \"Integrations,\" and you should see the AWS account that was recently integrated. We highly recommend giving that account a name so it\\'s easier to remember and find in the Dashboard\\'s query filters.\\n\\nIf you click on the \"Edit\" button on that Integration, you should see all of the AWS Lambda functions in the account, indicating which ones are enabled and which are disabled.\\n\\nPlease note, Metrics, Traces and more typically can take up to 10 minutes before they are visible in Serverless Framework Dashboard, after an AWS account has been integrated.\\n\\n## Advanced Instrumentation Using The SDK\\n\\nIn addition to the out-of-the-box instrumentation provided by Serverless Framework Dashboard, you can customize instrumentation using the Serverless SDK for richer use cases, such as:\\n\\n- Capturing handled errors so that they are reported elegantly in Serverless Framework Dashboard.\\n- Capturing custom Trace Spans.\\n- Capturing Error and Warnings Events.\\n- Adding Custom Tags to Traces for better searchability.\\n- Integrating with structured logging libraries.\\n\\nSee the SDK documentation for Node and Python for details:\\n\\n- [Full NodeJS Documentation](./sdk/nodejs.md)\\n- [Full Python Documentation](./sdk/python.md)\\n\\n## Supported AWS Lambda Runtimes\\n\\nServerless Framework\\'s Monitoring & Observability features currently support the following AWS Lambda Runtimes:\\n\\n- nodejs14.x\\n- nodejs16.x\\n- nodejs18.x\\n- python3.8\\n- python3.9\\n- python3.10\\n- python3.11\\n\\n## Supported AWS Regions\\n\\nServerless Framework\\'s Monitoring & Observability features currently support all of the Commercial AWS Regions. They do not support GovCloud or reginos in China.\\n\\n## How Integration Works\\n\\nServerless Framework\\'s Monitoring & Observability features use a few approaches to thoroughly collect all Metrics, Traces, Errors and more from your AWS Lambda functions. This is all done via an AWS IAM Role that is created when you integrate your AWS account with Serverless Framework\\'s Platform. The permissions for this AWS IAM Role are kept in [Github here](https://github.com/serverless/dashboard), so that you can easily review what\\'s required. You can remove this IAM Role at any time. But we recommend hitting \"Remove\" on the Integration within the Dashboard because it will automatically un-instrument the AWS account and AWS Lambda functions, in addition to deleting the IAM Role.\\n\\nThe first thing an AWS account integration does is create a Kinesis Firehose within your AWS account connected to a Cloudwatch Logs Subscription to each of your AWS Lambda functions which publish logs into that Firehose. The Serverless Framework Platform ingests log data from that Kinesis Firehose. This helps us collect Logs and more from your AWS Lambda functions. During each invocation, the Serverless Framework logs a compressed payload containing Trace information within your AWS Cloudwatch Logs. This can be identified easily because it starts with `SERVERLESS_TELEMETRY`.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/sdk/README.md', 'node_id': 3734670}, 'preview': \"<!--\\ntitle: Serverless Framework - Monitoring & Observability - SDKs\\ndescription: Learn how to use the Serverless Framework SDK for monitoring and observability in your serverless applications.\\nshort_title: Serverless Observability - SDK\\nkeywords:\\n  [\\n    'Serverless Framework',\\n    'SDK',\\n    'Monitoring',\\n    'Observability',\\n    'Lambda',\\n    'Instrumentation',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://www.serverless.com/framework/docs/guides/sdk/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# Serverless Framework SDK\\n\\nWhen using the Serverless Framework Dashboard, the Framework automatically injects the `serverless_sdk` module into your lambda package and wraps your lambda to automatically instrument all the monitoring features in the Dashboard.\\n\\nIt also has certain features you can use directly in your lambda such as capturing an error in the Dashboard without causing your lambda to error and custom function spans.\\n\\n[NodeJS Documentation](./nodejs.md)\\n\\n[Python Documentation](./python.md)\\n\\n## Advanced Span Configuration\\n\\nFor most of the SDK configuration, like turning on/off span collection, follow the\\n[Monitoring Configuration](../README.md/#configuration) instructions to modify your\\nserverless.yml appropriately.\\n\\nIf needed, you can configure HTTP span collection with the following environment variables\\n\\n- `SERVERLESS_ENTERPRISE_SPANS_CAPTURE_HOSTS` - `*` by default. Set to a comma delimited list of host names to capture.\\n- `SERVERLESS_ENTERPRISE_SPANS_IGNORE_HOSTS` - not set by default. Set to comma delimited list of hostnames to not capture.\\n- `SERVERLESS_ENTERPRISE_SPANS_CAPTURE_AWS_SDK_HTTP` - not set by default. Set to any value to also capture HTTP spans for requests from `botocore` or `aws-sdk`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/cicd/README.md', 'node_id': 3734682}, 'preview': '<!--\\ntitle: Serverless Framework Dashboard - CI/CD\\ndescription: Learn how to set up and use Serverless Framework CI/CD to automatically test and deploy services from Github.\\nshort_title: Serverless Dashboard - CI/CD\\nkeywords:\\n  [\\n    \\'Serverless Framework\\',\\n    \\'CI/CD\\',\\n    \\'Github\\',\\n    \\'AWS\\',\\n    \\'Node.js\\',\\n    \\'Python\\',\\n    \\'Deployment\\',\\n    \\'Serverless Dashboard\\',\\n  ]\\n-->\\n\\n<!-- DOCS-SITE-LINK:START automatically generated  -->\\n\\n### [Read this on the main serverless docs site](https://serverless.com/framework/docs/guides/cicd/)\\n\\n<!-- DOCS-SITE-LINK:END -->\\n\\n# CI/CD\\n\\nServerless CI/CD enables you to automatically test and deploy services from Github.\\n\\n## Requirements\\n\\nBefore you setup your CI/CD workflow, make sure you meet the following requirements:\\n\\n1. **Must have your Serverless Framework project checked into Github**. Currently Github and BitBucket are supported as a VCS providers. Your project, including the serverless.yml file, must be checked into a repo.\\n2. **Must be deployed on AWS**. The dashboard currently only supports AWS as a cloud service provider. Other cloud service providers are a work in progress.\\n3. **Must use the Node or Python runtime**. Currently only Serverless Framework projects using the Node or Python runtimes are supported. Other runtimes may work but are not officially supported.\\n\\n## Getting Started in 3 steps\\n\\n### Step 1: Link your AWS Account\\n\\nAs is the case with deployments from the Serverless Framework CLI, Serverless CI/CD requires access to your AWS Account in order to deploy your services. To make this process as secure as possible, Serverless CI/CD will generate short-lived credentials to your AWS account on each deployment. This is done by creating an AWS Access Role in your AWS account and associating it with a Provider in the Serverless Framework Dashboard.\\n\\nIf you’ve already set up an AWS Access Role with a Provider, you can skip this step. Otherwise, please go through the instructions on our [Provider documentation page](../dashboard/providers.md) to help set one up.\\n\\n### Step 2: Connect to Github\\n\\n1. Login to [https://app.serverless.com/](https://app.serverless.com/).\\n2. Navigate to the app which contains the service you want to deploy and click the menu icon (...) on the right hand side and choose \"settings\"\\n3. In the “connect to git” section, click “connect to Github” or \"connect to BitBucket\" and follow the instructions to authenticate and install the Serverless Framework app.\\n4. In the “repository settings” section, select the repository and base directory if needed containing your service. The service name specified in the serverless.yml must match the service you are configuring.\\n5. In the \"branch deploys\" section, you can choose to map a specific branch in your repo to the correct stage. When code is merged to that branch it then deploys using that stage and its associated Provider (and parameters).\\n6. Changes will be automatically saved when you make them\\n\\nThat’s it! You do not have to create any configuration files in your repository or define your test commands or your\\ndeployment commands.\\n\\nYour service will now deploy from the master branch and you’ll see all the test results, logs, safeguard pass/fail\\nstatus, and deployment details.\\n\\n### Step 3: Deploy from a Github branch\\n\\nNow that you are setup to deploy all changes to the master branch to the dev stage for your service, go ahead and make a\\ncommit and navigate to “deployments” in the dashboard. You will be able to see the new test and deployment.'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_Mt0gUGgbRm4ck0gn6gd2F906', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'find_file_node_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 9670, 'total_tokens': 9690, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 9600}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ce1cc063-b1b4-4413-a8a3-2908d1fe83b3-0' tool_calls=[{'name': 'find_file_node_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_Mt0gUGgbRm4ck0gn6gd2F906', 'type': 'tool_call'}] usage_metadata={'input_tokens': 9670, 'output_tokens': 20, 'total_tokens': 9690, 'input_token_details': {'audio': 0, 'cache_read': 9600}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content=\"Result 1:\\nFileNode: {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3700220}\\n\\n\\nResult 2:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3700229}\\n\\n\\nResult 3:\\nFileNode: {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md', 'node_id': 3723675}\\n\\n\\nResult 4:\\nFileNode: {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/custom-resources/resources/README.md', 'node_id': 3730097}\\n\\n\\nResult 5:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/README.md', 'node_id': 3734424}\\n\\n\\nResult 6:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/README.md', 'node_id': 3734434}\\n\\n\\nResult 7:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/guide/README.md', 'node_id': 3734439}\\n\\n\\nResult 8:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/examples/README.md', 'node_id': 3734484}\\n\\n\\nResult 9:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/events/README.md', 'node_id': 3734486}\\n\\n\\nResult 10:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/cli-reference/README.md', 'node_id': 3734542}\\n\\n\\nResult 11:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/README.md', 'node_id': 3734581}\\n\\n\\nResult 12:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/README.md', 'node_id': 3734595}\\n\\n\\nResult 13:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/hashicorp/README.md', 'node_id': 3734607}\\n\\n\\nResult 14:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/aws/README.md', 'node_id': 3734618}\\n\\n\\nResult 15:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/plugins/README.md', 'node_id': 3734630}\\n\\n\\nResult 16:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/observability/README.md', 'node_id': 3734645}\\n\\n\\nResult 17:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/README.md', 'node_id': 3734653}\\n\\n\\nResult 18:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/README.md', 'node_id': 3734662}\\n\\n\\nResult 19:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/sdk/README.md', 'node_id': 3734670}\\n\\n\\nResult 20:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/cicd/README.md', 'node_id': 3734682}\" name='find_file_node_with_basename' id='6be9fa5c-2d92-4495-853e-d082b79c4e81' tool_call_id='call_Mt0gUGgbRm4ck0gn6gd2F906' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3700220}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3700229}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md', 'node_id': 3723675}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/custom-resources/resources/README.md', 'node_id': 3730097}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/README.md', 'node_id': 3734424}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/README.md', 'node_id': 3734434}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/guide/README.md', 'node_id': 3734439}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/examples/README.md', 'node_id': 3734484}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/events/README.md', 'node_id': 3734486}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/cli-reference/README.md', 'node_id': 3734542}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/README.md', 'node_id': 3734581}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/README.md', 'node_id': 3734595}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/hashicorp/README.md', 'node_id': 3734607}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/aws/README.md', 'node_id': 3734618}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/plugins/README.md', 'node_id': 3734630}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/observability/README.md', 'node_id': 3734645}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/README.md', 'node_id': 3734653}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/README.md', 'node_id': 3734662}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/sdk/README.md', 'node_id': 3734670}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/cicd/README.md', 'node_id': 3734682}}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_m7PUZ9ZU6Ctg7FDWvxpvFAFN', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'find_file_node_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 9670, 'total_tokens': 9690, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 9600}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--698c6b27-31b9-4122-b8f2-09ec87c1ea59-0' tool_calls=[{'name': 'find_file_node_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_m7PUZ9ZU6Ctg7FDWvxpvFAFN', 'type': 'tool_call'}] usage_metadata={'input_tokens': 9670, 'output_tokens': 20, 'total_tokens': 9690, 'input_token_details': {'audio': 0, 'cache_read': 9600}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content=\"Result 1:\\nFileNode: {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3700220}\\n\\n\\nResult 2:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3700229}\\n\\n\\nResult 3:\\nFileNode: {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md', 'node_id': 3723675}\\n\\n\\nResult 4:\\nFileNode: {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/custom-resources/resources/README.md', 'node_id': 3730097}\\n\\n\\nResult 5:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/README.md', 'node_id': 3734424}\\n\\n\\nResult 6:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/README.md', 'node_id': 3734434}\\n\\n\\nResult 7:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/guide/README.md', 'node_id': 3734439}\\n\\n\\nResult 8:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/examples/README.md', 'node_id': 3734484}\\n\\n\\nResult 9:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/events/README.md', 'node_id': 3734486}\\n\\n\\nResult 10:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/providers/aws/cli-reference/README.md', 'node_id': 3734542}\\n\\n\\nResult 11:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/README.md', 'node_id': 3734581}\\n\\n\\nResult 12:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/README.md', 'node_id': 3734595}\\n\\n\\nResult 13:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/hashicorp/README.md', 'node_id': 3734607}\\n\\n\\nResult 14:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/variables/aws/README.md', 'node_id': 3734618}\\n\\n\\nResult 15:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/plugins/README.md', 'node_id': 3734630}\\n\\n\\nResult 16:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/observability/README.md', 'node_id': 3734645}\\n\\n\\nResult 17:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/README.md', 'node_id': 3734653}\\n\\n\\nResult 18:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/README.md', 'node_id': 3734662}\\n\\n\\nResult 19:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/sdk/README.md', 'node_id': 3734670}\\n\\n\\nResult 20:\\nFileNode: {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/cicd/README.md', 'node_id': 3734682}\" name='find_file_node_with_basename' id='65adeab2-ff11-4fef-86a6-dfe6b0ffefd0' tool_call_id='call_m7PUZ9ZU6Ctg7FDWvxpvFAFN' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3700220}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3700229}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/package/compile/events/api-gateway/lib/hack/README.md', 'node_id': 3723675}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'lib/plugins/aws/custom-resources/resources/README.md', 'node_id': 3730097}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/README.md', 'node_id': 3734424}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/README.md', 'node_id': 3734434}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/guide/README.md', 'node_id': 3734439}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/examples/README.md', 'node_id': 3734484}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/events/README.md', 'node_id': 3734486}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/providers/aws/cli-reference/README.md', 'node_id': 3734542}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/README.md', 'node_id': 3734581}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/README.md', 'node_id': 3734595}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/hashicorp/README.md', 'node_id': 3734607}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/variables/aws/README.md', 'node_id': 3734618}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/plugins/README.md', 'node_id': 3734630}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/observability/README.md', 'node_id': 3734645}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/README.md', 'node_id': 3734653}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/README.md', 'node_id': 3734662}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/monitoring/sdk/README.md', 'node_id': 3734670}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'docs/guides/dashboard/cicd/README.md', 'node_id': 3734682}}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search the root README.md, docs/README.md, and docs/getting-started.md for a quick verification command.' additional_kwargs={} response_metadata={} id='05841e95-86b8-419d-9695-e6fb8488e5e6'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search the README.md and docs/getting-started.md for a quick verification command, such as a version check or a basic test command.' additional_kwargs={} response_metadata={} id='a1d4482e-83c0-4e9a-9214-65b0013f302e'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search README.md and docs/getting-started.md for a quick verification command.' additional_kwargs={} response_metadata={} id='f7838cbf-5cd4-4d4b-97de-cb2fa71c5cb9'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search README.md and docs/getting-started.md for a quick verification command, such as version check or help command.' additional_kwargs={} response_metadata={} id='08fb8183-7272-4abd-9292-b2d47f971c70'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search the README.md and docs/getting-started.md for a quick verification command, such as a version check or help command.' additional_kwargs={} response_metadata={} id='29656e31-9812-4a4c-8ec5-b682e37e024c'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "testsuite_refined_query": "",
            "testsuite_command": []
        },
        "env_states": {
            "max_refined_query_loop": 3,
            "env_implement_file_context_query": "OBJECTIVE: Find the most relevant environment configuration files that can help generate an accurate Dockerfile for this project,\nincluding Dockerfiles, dependency files, build configurations, and environment setup files.\n\n<reasoning>\n1. Analyze project characteristics:\n   - Programming language and framework\n   - Dependency management files\n   - Build system and tools\n   - Runtime requirements\n   - Environment configurations\n\n2. Search requirements:\n   - Existing Dockerfiles or containerization files\n   - Dependency files (requirements.txt, package.json, pom.xml, etc.)\n   - Build configuration files (Makefile, CMakeLists.txt, etc.)\n   - Environment configuration files (.env, config files)\n   - Setup and installation scripts\n\n3. Focus areas:\n   - Docker-related files (Dockerfile, docker-compose.yml, .dockerignore)\n   - Package management files (requirements.txt, package.json, go.mod, Cargo.toml, etc.)\n   - Build system files (Makefile, CMakeLists.txt, build.gradle, etc.)\n   - Environment configuration (.env, config.json, application.properties, etc.)\n   - Setup documentation (README.md, INSTALL.md, SETUP.md)\n   - CI/CD configuration files\n</reasoning>\n\nREQUIREMENTS:\n- Return the most relevant environment configuration files for Dockerfile generation\n- Must include complete file content with exact file paths and line numbers\n- Must include dependency files, build configurations, and environment setups\n- Must include any existing Docker-related files\n- Must include setup documentation and installation instructions\n\n<examples>\n<example id=\"python-web-app\">\n<project_context>\nPython Flask web application with requirements.txt\n</project_context>\n\n<ideal_files>\n# File: requirements.txt\nFlask==2.3.3\ngunicorn==21.2.0\npsycopg2-binary==2.9.7\nredis==4.6.0\n\n# File: app.py\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    return 'Hello World!'\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n\n# File: README.md\n## Installation\npip install -r requirements.txt\npython app.py\n</ideal_files>\n</example>\n\n<example id=\"nodejs-api\">\n<project_context>\nNode.js Express API with package.json\n</project_context>\n\n<ideal_files>\n# File: package.json\n{\n  \"name\": \"my-api\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^7.5.0\"\n  }\n}\n\n# File: server.js\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\napp.get('/', (req, res) => {\n  res.json({ message: 'API is running' });\n});\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});\n</ideal_files>\n</example>\n\nSearch priority:\n1. Existing Dockerfiles or containerization files\n2. Dependency management files (requirements.txt, package.json, etc.)\n3. Build configuration files (Makefile, CMakeLists.txt, etc.)\n4. Environment configuration files (.env, config files)\n5. Setup documentation and installation instructions\n\nFind the most relevant environment configuration files with complete context for Dockerfile generation.\n",
            "env_implement_file_context": [
                {
                    "type": "Context",
                    "content": "File: test/fixtures/programmatic/curated-plugins-python/requirements.txt\nLine number range: 1 - 1\nContent:\n1. requests\n",
                    "relative_path": "test/fixtures/programmatic/curated-plugins-python/requirements.txt",
                    "start_line_number": 1,
                    "end_line_number": 1
                },
                {
                    "type": "Context",
                    "content": "File: README.md\nLine number range: 1 - 93\nContent:\n1. [![Serverless Framework AWS Lambda AWS DynamoDB AWS API Gateway](https://github.com/serverless/serverless/assets/2752551/66a8c6a9-bc4a-4116-b139-90c12963337e)](https://serverless.com)\n2. \n3. <br/>\n4. \n5. <div align=\"center\">\n6.   <a aria-label=\"Serverless.com\" href=\"https://serverless.com\">Website</a>\n7.   &nbsp;•&nbsp;\n8.   <a aria-label=\"Serverless Framework Documentation\" href=\"https://serverless.com/framework/docs/\">Documentation</a>\n9.   &nbsp;•&nbsp;\n10.   <a aria-label=\"Serverless Inc Twitter\" href=\"https://twitter.com/goserverless\">X / Twitter</a>\n11.   &nbsp;•&nbsp;\n12.   <a aria-label=\"Serverless Framework Community Slack\" href=\"https://serverless.com/slack\">Community Slack</a>\n13.   &nbsp;•&nbsp;\n14.   <a aria-label=\"Serverless Framework Community Forum\" href=\"https://forum.serverless.com\">Forum</a>\n15. </div>\n16. \n17. <br/>\n18. <br/>\n19. \n20. **The Serverless Framework** – Makes it easy to use AWS Lambda and other managed cloud services to build applications that auto-scale, cost nothing when idle, and result in radically low maintenance.\n21. \n22. The Serverless Framework is a command-line tool with approachable YAML syntax to deploy both your code and cloud infrastructure needed to make tons of serverless application use-cases, like APIs, front-ends, data pipelines and scheduled tasks. It's a multi-language framework that supports Node.js, Typescript, Python, Go, Java, and more. It's also completely extensible via over 1,000 plugins which add more serverless use-cases and workflows to the Framework.\n23. \n24. Actively maintained by [Serverless Inc](https://www.serverless.com).\n25. \n26. <br/>\n27. \n28. # Serverless Framework - V.4\n29. \n30. <div align=\"center\" style=\"max-width: 500px; margin: auto;\">\n31.   <a href=\"https://www.youtube.com/watch?v=UQL_PPJUFOU\" target=\"_blank\">\n32.     <img src=\"https://github.com/serverless/serverless/assets/2752551/2fc23656-df76-4d8a-b775-f4cc8ed2068d\" alt=\"Serverless Framework V.4 Overview Video\" style=\"width: 100%; max-width: 500px;\">\n33.   </a>\n34. </div>\n35. \n36. <br/>\n37. \n38. **August 2025** – V.4 continues to feature significant updates. Review them all below. In 2025, we have begun releasing bigger projects, like the [Serverless Container Framework](https://github.com/serverless/containers), and the [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp). As always, we are more excited about the serverless future than ever.\n39. \n40. ## New Features In V.4\n41. \n42. Here's a list of everything that's new in V.4, so far:\n43. \n44. - **Improved Custom Domain Support:** You no longer need an external plugin to automatically configure custom domains and SSL certificates for your APIs and more. It's now built into the [Serverless Framework CLI](https://www.serverless.com/framework/docs/providers/aws/guide/domains).\n45. - **Integration with Doppler:** You can now easily fetch Secrets from Doppler via [Serverless Framework Variables](https://www.serverless.com/framework/docs/guides/variables/doppler).\n46. - **Introducing [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp):** Built for Cursor, Windsurf, and other AI-powered IDEs, it auto-detects cloud resources from your code, fetching logs, state, and config from AWS, enabling you to debug serverless apps directly in your IDE — no AWS console visit needed! Supports Serverless Framework, Cloudformation, and more.\n47. - **Introducing the [Serverless Container Framework](https://github.com/serverless/containers):** One solution to deploy serverless workloads everywhere - This is a new YAML file that works with the Serverless Framework CLI that gives you one experience to easily deploy containers to AWS Lambda and AWS ECS Fargate and migrate between them w/ zero-downtime — all without re-architecting. We launched this as a way to reduce large Lambda bills and give folks flexibility, but it is rapidly become the greatest developer experience for containers on AWS. Support for Google Cloud Run, Azure and more are coming soon.\n48. - **Support for AWS SAM, AWS Cloudformation, & Traditional Serverless Framework Projects:** Now, you can use one tool to deploy all three of these IaC project files. [More info here](https://www.serverless.com/framework/docs/guides/sam)\n49. - **Native Typescript Support:** You can now use `.ts` handlers in your AWS Lambda functions in `serverless.yml` and have them build automatically upon deploy. [ESBuild](https://esbuild.github.io/) is now included in the Framework which makes this possible. [More info here](https://www.serverless.com/framework/docs/providers/aws/guide/building).\n50. - **The AWS AI Stack:** V.4 is optimized for [the AWS AI Stack](https://github.com/serverless/aws-ai-stack). Deploy a full-stack, serverless, boilerplate for AI applications on AWS, featuring Bedrock LLMs like Claude 3.5 Sonnet and Llama3.1 and much more.\n51. - **New Dev Mode:** Run `serverless dev` to have events from your live architecture routed to your local code, enabling you to make fast changes without deployment. [More info here](https://www.serverless.com/framework/docs/providers/aws/cli-reference/dev).\n52. - - **Node.js V22:** Support for Node.js version 22 on AWS Lambda.\n53. - **New Stages Property:** Easily organize stage-specific config via `stages` and set `default` config to fallback to.\n54. - **Improved Compose Experience:** Serverless Compose now has a beautiful new CLI experience that better demonstrates what is being deployed.\n55. - **New Terraform & Vault Integrations:** Pull state outputs from several Terraform state storage solutions, and secrets from Vault. [Terraform Docs](https://www.serverless.com/framework/docs/guides/variables/terraform) [Vault Docs](https://www.serverless.com/framework/docs/guides/variables/vault)\n56. - **Support Command:** Send support requests to our team [directly from the CLI](https://www.serverless.com/framework/docs/providers/aws/cli-reference/support), which auto-include contextual info which you can review before sending.\n57. - **Debug Summary for AI:** When you run into a bug, you can run \"serverless support --ai\" to generate a concise report detailing your last bug with all necessary context, optimized for pasting into AI tools such as ChatGPT.\n58. - **New AWS Lambda Runtimes:** \"python3.12\", \"dotnet8\", and \"java21\".\n59. - **Advanced Logging Controls for AWS Lambda:** Capture Logs in JSON, increased log granularity, and setting a custom Log Group. Here is the [AWS article](https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/). Here is the [YAML implementation](https://github.com/serverless/serverless/blob/v4.0/docs/providers/aws/guide/serverless.yml.md#logs)\n60. - **Axiom Integration:** Integrate with [Axiom's observability solution](https://www.serverless.com/framework/docs/guides/observability/axiom) for a powerful logging, metrics and traces experience, at 3X less than AWS cloudwatch.\n61. - **AWS SSO:** Environment variables, especially ones set by AWS SSO, are prioritized. The Framework and Dashboard no longer interfere with these.\n62. - **Automatic Updates:** These happen by default now. Though, you will be able to control the level of updates you're open to.\n63. - **Improved Onboarding & Set-Up:** The `serverless` command has been re-written to be more helpful when setting up a new or existing project.\n64. - **Updated Custom Resource Handlers:** All custom resource handlers now use `nodejs20.x`.\n65. - **Deprecation Of Non-AWS Providers:** Deprecation of other cloud providers, in favor of handling this better in our upcoming Serverless Framework \"Extensions\".\n66. \n67. ## Breaking Changes\n68. \n69. We're seeking to avoid breaking changes for the \"aws\" Provider. However, there are a few large things that are changing to be aware of:\n70. \n71. - The V.4 License is changing. See the section below for more information on this.\n72. - Authentication is required within the CLI.\n73. - Non-AWS Providers have been deprecated. We will be introducing new ways in V.4 to use other cloud infrastructure vendors.\n74. \n75. If you stumble upon additional breaking changes, please create an issue. To learn more about what's different and potential breaking changes, please see our [Upgrading to Serverless Framework V4 Documentation](https://www.serverless.com/framework/docs/guides/upgrading-v4).\n76. \n77. ## License Changes in V.4\n78. \n79. Please note, the structure and licensing of the V.4 repository differ from the V.4 npm module. The npm module contains some proprietary licensed software, as V.4 transitions to a common SaaS product, [as previously announced](https://www.serverless.com/blog/serverless-framework-v4-a-new-model). The original Serverless Framework source code and more will continue to remain MIT license software, the repository will soon be restructured to clearly distinguish between proprietary and open-source components.\n80. \n81. <br/>\n82. \n83. # Contents\n84. \n85. - [Features](#features)\n86. - [Quick Start](#quick-start)\n87. - [Examples](https://github.com/serverless/examples)\n88. - [Plugins](https://github.com/serverless/plugins)\n89. - [Community](#community)\n90. \n91. <br/>\n92. \n93. # <a name=\"features\"></a>Features\n",
                    "relative_path": "README.md",
                    "start_line_number": 1,
                    "end_line_number": 93
                }
            ],
            "env_implement_write_messages": [
                {
                    "type": "HumanMessage",
                    "content": "content='Project Environment Context:\\nFile: test/fixtures/programmatic/curated-plugins-python/requirements.txt\\nLine number range: 1 - 1\\nContent:\\n1. requests\\n\\n\\nFile: README.md\\nLine number range: 1 - 93\\nContent:\\n1. [![Serverless Framework AWS Lambda AWS DynamoDB AWS API Gateway](https://github.com/serverless/serverless/assets/2752551/66a8c6a9-bc4a-4116-b139-90c12963337e)](https://serverless.com)\\n2. \\n3. <br/>\\n4. \\n5. <div align=\"center\">\\n6.   <a aria-label=\"Serverless.com\" href=\"https://serverless.com\">Website</a>\\n7.   &nbsp;•&nbsp;\\n8.   <a aria-label=\"Serverless Framework Documentation\" href=\"https://serverless.com/framework/docs/\">Documentation</a>\\n9.   &nbsp;•&nbsp;\\n10.   <a aria-label=\"Serverless Inc Twitter\" href=\"https://twitter.com/goserverless\">X / Twitter</a>\\n11.   &nbsp;•&nbsp;\\n12.   <a aria-label=\"Serverless Framework Community Slack\" href=\"https://serverless.com/slack\">Community Slack</a>\\n13.   &nbsp;•&nbsp;\\n14.   <a aria-label=\"Serverless Framework Community Forum\" href=\"https://forum.serverless.com\">Forum</a>\\n15. </div>\\n16. \\n17. <br/>\\n18. <br/>\\n19. \\n20. **The Serverless Framework** – Makes it easy to use AWS Lambda and other managed cloud services to build applications that auto-scale, cost nothing when idle, and result in radically low maintenance.\\n21. \\n22. The Serverless Framework is a command-line tool with approachable YAML syntax to deploy both your code and cloud infrastructure needed to make tons of serverless application use-cases, like APIs, front-ends, data pipelines and scheduled tasks. It\\'s a multi-language framework that supports Node.js, Typescript, Python, Go, Java, and more. It\\'s also completely extensible via over 1,000 plugins which add more serverless use-cases and workflows to the Framework.\\n23. \\n24. Actively maintained by [Serverless Inc](https://www.serverless.com).\\n25. \\n26. <br/>\\n27. \\n28. # Serverless Framework - V.4\\n29. \\n30. <div align=\"center\" style=\"max-width: 500px; margin: auto;\">\\n31.   <a href=\"https://www.youtube.com/watch?v=UQL_PPJUFOU\" target=\"_blank\">\\n32.     <img src=\"https://github.com/serverless/serverless/assets/2752551/2fc23656-df76-4d8a-b775-f4cc8ed2068d\" alt=\"Serverless Framework V.4 Overview Video\" style=\"width: 100%; max-width: 500px;\">\\n33.   </a>\\n34. </div>\\n35. \\n36. <br/>\\n37. \\n38. **August 2025** – V.4 continues to feature significant updates. Review them all below. In 2025, we have begun releasing bigger projects, like the [Serverless Container Framework](https://github.com/serverless/containers), and the [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp). As always, we are more excited about the serverless future than ever.\\n39. \\n40. ## New Features In V.4\\n41. \\n42. Here\\'s a list of everything that\\'s new in V.4, so far:\\n43. \\n44. - **Improved Custom Domain Support:** You no longer need an external plugin to automatically configure custom domains and SSL certificates for your APIs and more. It\\'s now built into the [Serverless Framework CLI](https://www.serverless.com/framework/docs/providers/aws/guide/domains).\\n45. - **Integration with Doppler:** You can now easily fetch Secrets from Doppler via [Serverless Framework Variables](https://www.serverless.com/framework/docs/guides/variables/doppler).\\n46. - **Introducing [Serverless MCP](https://www.serverless.com/framework/docs/guides/mcp):** Built for Cursor, Windsurf, and other AI-powered IDEs, it auto-detects cloud resources from your code, fetching logs, state, and config from AWS, enabling you to debug serverless apps directly in your IDE — no AWS console visit needed! Supports Serverless Framework, Cloudformation, and more.\\n47. - **Introducing the [Serverless Container Framework](https://github.com/serverless/containers):** One solution to deploy serverless workloads everywhere - This is a new YAML file that works with the Serverless Framework CLI that gives you one experience to easily deploy containers to AWS Lambda and AWS ECS Fargate and migrate between them w/ zero-downtime — all without re-architecting. We launched this as a way to reduce large Lambda bills and give folks flexibility, but it is rapidly become the greatest developer experience for containers on AWS. Support for Google Cloud Run, Azure and more are coming soon.\\n48. - **Support for AWS SAM, AWS Cloudformation, & Traditional Serverless Framework Projects:** Now, you can use one tool to deploy all three of these IaC project files. [More info here](https://www.serverless.com/framework/docs/guides/sam)\\n49. - **Native Typescript Support:** You can now use `.ts` handlers in your AWS Lambda functions in `serverless.yml` and have them build automatically upon deploy. [ESBuild](https://esbuild.github.io/) is now included in the Framework which makes this possible. [More info here](https://www.serverless.com/framework/docs/providers/aws/guide/building).\\n50. - **The AWS AI Stack:** V.4 is optimized for [the AWS AI Stack](https://github.com/serverless/aws-ai-stack). Deploy a full-stack, serverless, boilerplate for AI applications on AWS, featuring Bedrock LLMs like Claude 3.5 Sonnet and Llama3.1 and much more.\\n51. - **New Dev Mode:** Run `serverless dev` to have events from your live architecture routed to your local code, enabling you to make fast changes without deployment. [More info here](https://www.serverless.com/framework/docs/providers/aws/cli-reference/dev).\\n52. - - **Node.js V22:** Support for Node.js version 22 on AWS Lambda.\\n53. - **New Stages Property:** Easily organize stage-specific config via `stages` and set `default` config to fallback to.\\n54. - **Improved Compose Experience:** Serverless Compose now has a beautiful new CLI experience that better demonstrates what is being deployed.\\n55. - **New Terraform & Vault Integrations:** Pull state outputs from several Terraform state storage solutions, and secrets from Vault. [Terraform Docs](https://www.serverless.com/framework/docs/guides/variables/terraform) [Vault Docs](https://www.serverless.com/framework/docs/guides/variables/vault)\\n56. - **Support Command:** Send support requests to our team [directly from the CLI](https://www.serverless.com/framework/docs/providers/aws/cli-reference/support), which auto-include contextual info which you can review before sending.\\n57. - **Debug Summary for AI:** When you run into a bug, you can run \"serverless support --ai\" to generate a concise report detailing your last bug with all necessary context, optimized for pasting into AI tools such as ChatGPT.\\n58. - **New AWS Lambda Runtimes:** \"python3.12\", \"dotnet8\", and \"java21\".\\n59. - **Advanced Logging Controls for AWS Lambda:** Capture Logs in JSON, increased log granularity, and setting a custom Log Group. Here is the [AWS article](https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/). Here is the [YAML implementation](https://github.com/serverless/serverless/blob/v4.0/docs/providers/aws/guide/serverless.yml.md#logs)\\n60. - **Axiom Integration:** Integrate with [Axiom\\'s observability solution](https://www.serverless.com/framework/docs/guides/observability/axiom) for a powerful logging, metrics and traces experience, at 3X less than AWS cloudwatch.\\n61. - **AWS SSO:** Environment variables, especially ones set by AWS SSO, are prioritized. The Framework and Dashboard no longer interfere with these.\\n62. - **Automatic Updates:** These happen by default now. Though, you will be able to control the level of updates you\\'re open to.\\n63. - **Improved Onboarding & Set-Up:** The `serverless` command has been re-written to be more helpful when setting up a new or existing project.\\n64. - **Updated Custom Resource Handlers:** All custom resource handlers now use `nodejs20.x`.\\n65. - **Deprecation Of Non-AWS Providers:** Deprecation of other cloud providers, in favor of handling this better in our upcoming Serverless Framework \"Extensions\".\\n66. \\n67. ## Breaking Changes\\n68. \\n69. We\\'re seeking to avoid breaking changes for the \"aws\" Provider. However, there are a few large things that are changing to be aware of:\\n70. \\n71. - The V.4 License is changing. See the section below for more information on this.\\n72. - Authentication is required within the CLI.\\n73. - Non-AWS Providers have been deprecated. We will be introducing new ways in V.4 to use other cloud infrastructure vendors.\\n74. \\n75. If you stumble upon additional breaking changes, please create an issue. To learn more about what\\'s different and potential breaking changes, please see our [Upgrading to Serverless Framework V4 Documentation](https://www.serverless.com/framework/docs/guides/upgrading-v4).\\n76. \\n77. ## License Changes in V.4\\n78. \\n79. Please note, the structure and licensing of the V.4 repository differ from the V.4 npm module. The npm module contains some proprietary licensed software, as V.4 transitions to a common SaaS product, [as previously announced](https://www.serverless.com/blog/serverless-framework-v4-a-new-model). The original Serverless Framework source code and more will continue to remain MIT license software, the repository will soon be restructured to clearly distinguish between proprietary and open-source components.\\n80. \\n81. <br/>\\n82. \\n83. # Contents\\n84. \\n85. - [Features](#features)\\n86. - [Quick Start](#quick-start)\\n87. - [Examples](https://github.com/serverless/examples)\\n88. - [Plugins](https://github.com/serverless/plugins)\\n89. - [Community](#community)\\n90. \\n91. <br/>\\n92. \\n93. # <a name=\"features\"></a>Features\\n\\n\\n\\nNow generate a complete executable bash script that can successfully set up and configure the environment for this project, especially designed to run inside Docker containers. The bash script should:\\n1. Install the appropriate runtime and dependencies for the project\\'s technology stack\\n2. Install all necessary system packages and tools\\n3. Set up the project directory structure and permissions\\n4. Configure the runtime environment properly\\n5. Set up necessary environment variables and configurations\\n6. Follow bash scripting best practices for error handling and security\\n\\nMake sure the bash script is self-contained and can set up the project environment from scratch in a Docker container environment.\\n' additional_kwargs={} response_metadata={} id='f1cffd5a-2d8c-4c30-a8d9-cfea4c665c4d'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='```bash\\n#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is running as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root. Exiting.\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update -y\\n    apt-get install -y --no-install-recommends \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-venv \\\\\\n        build-essential \\\\\\n        libssl-dev \\\\\\n        libffi-dev \\\\\\n        curl \\\\\\n        wget \\\\\\n        ca-certificates\\n    apt-get clean\\n    rm -rf /var/lib/apt/lists/*\\n    log \"System dependencies installed successfully.\"\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod 755 /app\\n    log \"Project directory structure set up at /app.\"\\n}\\n\\n# Install Python dependencies\\ninstall_python_deps() {\\n    log \"Installing Python dependencies...\"\\n    cd /app\\n    if [ ! -f requirements.txt ]; then\\n        error \"requirements.txt not found in /app. Exiting.\"\\n        exit 1\\n    fi\\n    python3 -m venv venv\\n    source venv/bin/activate\\n    pip install --upgrade pip\\n    pip install -r requirements.txt\\n    deactivate\\n    log \"Python dependencies installed successfully.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime_env() {\\n    log \"Configuring runtime environment...\"\\n    export PYTHONUNBUFFERED=1\\n    export APP_HOME=/app\\n    export PATH=\"$APP_HOME/venv/bin:$PATH\"\\n    log \"Runtime environment configured.\"\\n}\\n\\n# Set up environment variables\\nsetup_env_vars() {\\n    log \"Setting up environment variables...\"\\n    echo \"export PYTHONUNBUFFERED=1\" >> /etc/environment\\n    echo \"export APP_HOME=/app\" >> /etc/environment\\n    echo \"export PATH=\\\\\"/app/venv/bin:\\\\$PATH\\\\\"\" >> /etc/environment\\n    log \"Environment variables set up successfully.\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    # Step 1: Install system dependencies\\n    install_system_deps\\n\\n    # Step 2: Set up project directory structure\\n    setup_project_structure\\n\\n    # Step 3: Copy project files (assumes Dockerfile or volume mounts will handle this)\\n    log \"Copying project files...\"\\n    cp -r /tmp/project/* /app/ || warning \"No project files found in /tmp/project. Ensure files are mounted or copied.\"\\n\\n    # Step 4: Install Python dependencies\\n    install_python_deps\\n\\n    # Step 5: Configure runtime environment\\n    configure_runtime_env\\n\\n    # Step 6: Set up environment variables\\n    setup_env_vars\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To activate the virtual environment, run: source /app/venv/bin/activate\"\\n}\\n\\n# Run main function\\nmain \"$@\"\\n``` \\n\\n### Explanation of the Script:\\n1. **Error Handling and Logging**:\\n   - The script uses `set -e` to exit on any error.\\n   - Logging functions (`log`, `error`, `warning`) provide clear feedback during execution.\\n\\n2. **System Dependencies**:\\n   - Installs Python 3, pip, and other necessary system packages for building Python dependencies.\\n\\n3. **Project Directory Setup**:\\n   - Creates a `/app` directory for the project and sets appropriate permissions.\\n\\n4. **Python Dependencies**:\\n   - Sets up a Python virtual environment in `/app/venv`.\\n   - Installs dependencies from `requirements.txt`.\\n\\n5. **Runtime Environment Configuration**:\\n   - Configures environment variables for Python and the application.\\n\\n6. **Environment Variables**:\\n   - Adds environment variables to `/etc/environment` for persistence.\\n\\n7. **Docker Compatibility**:\\n   - Assumes the script runs as root (default in Docker containers).\\n   - Avoids using `sudo` and cleans up unnecessary files to reduce image size.\\n\\n8. **Idempotency**:\\n   - The script can be safely re-run without causing issues (e.g., re-creating directories or re-installing dependencies).\\n\\n### Usage:\\n1. Place the script in your Docker image or mount it as a volume.\\n2. Ensure the project files (including `requirements.txt`) are available in `/tmp/project` or adjust the script to match your file structure.\\n3. Run the script during the Docker build process or as an entrypoint to set up the environment.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1103, 'prompt_tokens': 3457, 'total_tokens': 4560, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--235229b8-f2ee-4e34-affa-085547e7785b-0' usage_metadata={'input_tokens': 3457, 'output_tokens': 1103, 'total_tokens': 4560, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_file_messages": [
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_1T4pokTi5kjKfKW3lcwB4QVk', 'function': {'arguments': '{\"relative_path\":\"prometheus_setup.sh\",\"content\":\"#!/bin/bash\\\\n\\\\n# Exit immediately if a command exits with a non-zero status\\\\nset -e\\\\n\\\\n# Colors for output\\\\nRED=\\'\\\\\\\\033[0;31m\\'\\\\nGREEN=\\'\\\\\\\\033[0;32m\\'\\\\nYELLOW=\\'\\\\\\\\033[1;33m\\'\\\\nNC=\\'\\\\\\\\033[0m\\' # No Color\\\\n\\\\n# Logging functions\\\\nlog() {\\\\n    echo -e \\\\\"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\\\\\"\\\\n}\\\\n\\\\nerror() {\\\\n    echo -e \\\\\"${RED}[ERROR] $1${NC}\\\\\" >&2\\\\n}\\\\n\\\\nwarning() {\\\\n    echo -e \\\\\"${YELLOW}[WARNING] $1${NC}\\\\\"\\\\n}\\\\n\\\\n# Ensure the script is running as root (Docker containers typically run as root)\\\\nif [ \\\\\"$(id -u)\\\\\" -ne 0 ]; then\\\\n    error \\\\\"This script must be run as root. Exiting.\\\\\"\\\\n    exit 1\\\\nfi\\\\n\\\\n# Install system dependencies\\\\ninstall_system_deps() {\\\\n    log \\\\\"Installing system dependencies...\\\\\"\\\\n    apt-get update -y\\\\n    apt-get install -y --no-install-recommends \\\\\\\\\\\\n        python3 \\\\\\\\\\\\n        python3-pip \\\\\\\\\\\\n        python3-venv \\\\\\\\\\\\n        build-essential \\\\\\\\\\\\n        libssl-dev \\\\\\\\\\\\n        libffi-dev \\\\\\\\\\\\n        curl \\\\\\\\\\\\n        wget \\\\\\\\\\\\n        ca-certificates\\\\n    apt-get clean\\\\n    rm -rf /var/lib/apt/lists/*\\\\n    log \\\\\"System dependencies installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Set up project directory structure\\\\nsetup_project_structure() {\\\\n    log \\\\\"Setting up project directory structure...\\\\\"\\\\n    mkdir -p /app\\\\n    chmod 755 /app\\\\n    log \\\\\"Project directory structure set up at /app.\\\\\"\\\\n}\\\\n\\\\n# Install Python dependencies\\\\ninstall_python_deps() {\\\\n    log \\\\\"Installing Python dependencies...\\\\\"\\\\n    cd /app\\\\n    if [ ! -f requirements.txt ]; then\\\\n        error \\\\\"requirements.txt not found in /app. Exiting.\\\\\"\\\\n        exit 1\\\\n    fi\\\\n    python3 -m venv venv\\\\n    source venv/bin/activate\\\\n    pip install --upgrade pip\\\\n    pip install -r requirements.txt\\\\n    deactivate\\\\n    log \\\\\"Python dependencies installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Configure runtime environment\\\\nconfigure_runtime_env() {\\\\n    log \\\\\"Configuring runtime environment...\\\\\"\\\\n    export PYTHONUNBUFFERED=1\\\\n    export APP_HOME=/app\\\\n    export PATH=\\\\\"$APP_HOME/venv/bin:$PATH\\\\\"\\\\n    log \\\\\"Runtime environment configured.\\\\\"\\\\n}\\\\n\\\\n# Set up environment variables\\\\nsetup_env_vars() {\\\\n    log \\\\\"Setting up environment variables...\\\\\"\\\\n    echo \\\\\"export PYTHONUNBUFFERED=1\\\\\" >> /etc/environment\\\\n    echo \\\\\"export APP_HOME=/app\\\\\" >> /etc/environment\\\\n    echo \\\\\"export PATH=\\\\\\\\\\\\\"/app/venv/bin:\\\\\\\\$PATH\\\\\\\\\\\\\"\\\\\" >> /etc/environment\\\\n    log \\\\\"Environment variables set up successfully.\\\\\"\\\\n}\\\\n\\\\n# Main setup function\\\\nmain() {\\\\n    log \\\\\"Starting project environment setup...\\\\\"\\\\n\\\\n    # Step 1: Install system dependencies\\\\n    install_system_deps\\\\n\\\\n    # Step 2: Set up project directory structure\\\\n    setup_project_structure\\\\n\\\\n    # Step 3: Copy project files (assumes Dockerfile or volume mounts will handle this)\\\\n    log \\\\\"Copying project files...\\\\\"\\\\n    cp -r /tmp/project/* /app/ || warning \\\\\"No project files found in /tmp/project. Ensure files are mounted or copied.\\\\\"\\\\n\\\\n    # Step 4: Install Python dependencies\\\\n    install_python_deps\\\\n\\\\n    # Step 5: Configure runtime environment\\\\n    configure_runtime_env\\\\n\\\\n    # Step 6: Set up environment variables\\\\n    setup_env_vars\\\\n\\\\n    log \\\\\"Project environment setup completed successfully!\\\\\"\\\\n    log \\\\\"To activate the virtual environment, run: source /app/venv/bin/activate\\\\\"\\\\n}\\\\n\\\\n# Run main function\\\\nmain \\\\\"$@\\\\\"\"}', 'name': 'create_file'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 916, 'prompt_tokens': 10053, 'total_tokens': 10969, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--e5a60b5d-001f-4fee-bc8b-bdfa6f3ff4d5-0' tool_calls=[{'name': 'create_file', 'args': {'relative_path': 'prometheus_setup.sh', 'content': '#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is running as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root. Exiting.\"\\n    exit 1\\nfi\\n\\n# Install system dependencies\\ninstall_system_deps() {\\n    log \"Installing system dependencies...\"\\n    apt-get update -y\\n    apt-get install -y --no-install-recommends \\\\\\n        python3 \\\\\\n        python3-pip \\\\\\n        python3-venv \\\\\\n        build-essential \\\\\\n        libssl-dev \\\\\\n        libffi-dev \\\\\\n        curl \\\\\\n        wget \\\\\\n        ca-certificates\\n    apt-get clean\\n    rm -rf /var/lib/apt/lists/*\\n    log \"System dependencies installed successfully.\"\\n}\\n\\n# Set up project directory structure\\nsetup_project_structure() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /app\\n    chmod 755 /app\\n    log \"Project directory structure set up at /app.\"\\n}\\n\\n# Install Python dependencies\\ninstall_python_deps() {\\n    log \"Installing Python dependencies...\"\\n    cd /app\\n    if [ ! -f requirements.txt ]; then\\n        error \"requirements.txt not found in /app. Exiting.\"\\n        exit 1\\n    fi\\n    python3 -m venv venv\\n    source venv/bin/activate\\n    pip install --upgrade pip\\n    pip install -r requirements.txt\\n    deactivate\\n    log \"Python dependencies installed successfully.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime_env() {\\n    log \"Configuring runtime environment...\"\\n    export PYTHONUNBUFFERED=1\\n    export APP_HOME=/app\\n    export PATH=\"$APP_HOME/venv/bin:$PATH\"\\n    log \"Runtime environment configured.\"\\n}\\n\\n# Set up environment variables\\nsetup_env_vars() {\\n    log \"Setting up environment variables...\"\\n    echo \"export PYTHONUNBUFFERED=1\" >> /etc/environment\\n    echo \"export APP_HOME=/app\" >> /etc/environment\\n    echo \"export PATH=\\\\\"/app/venv/bin:\\\\$PATH\\\\\"\" >> /etc/environment\\n    log \"Environment variables set up successfully.\"\\n}\\n\\n# Main setup function\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    # Step 1: Install system dependencies\\n    install_system_deps\\n\\n    # Step 2: Set up project directory structure\\n    setup_project_structure\\n\\n    # Step 3: Copy project files (assumes Dockerfile or volume mounts will handle this)\\n    log \"Copying project files...\"\\n    cp -r /tmp/project/* /app/ || warning \"No project files found in /tmp/project. Ensure files are mounted or copied.\"\\n\\n    # Step 4: Install Python dependencies\\n    install_python_deps\\n\\n    # Step 5: Configure runtime environment\\n    configure_runtime_env\\n\\n    # Step 6: Set up environment variables\\n    setup_env_vars\\n\\n    log \"Project environment setup completed successfully!\"\\n    log \"To activate the virtual environment, run: source /app/venv/bin/activate\"\\n}\\n\\n# Run main function\\nmain \"$@\"'}, 'id': 'call_1T4pokTi5kjKfKW3lcwB4QVk', 'type': 'tool_call'}] usage_metadata={'input_tokens': 10053, 'output_tokens': 916, 'total_tokens': 10969, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='The file prometheus_setup.sh has been created.' name='create_file' id='c548d7bd-2641-465d-abde-7f5c556280de' tool_call_id='call_1T4pokTi5kjKfKW3lcwB4QVk'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='The bash script has been saved at the project root with the relative path:\\n\\n`prometheus_setup.sh`' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 10986, 'total_tokens': 11009, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 10880}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--217c9689-f988-4280-99de-217690bfa3cb-0' usage_metadata={'input_tokens': 10986, 'output_tokens': 23, 'total_tokens': 11009, 'input_token_details': {'audio': 0, 'cache_read': 10880}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_execute_messages": [],
            "env_implement_bash_content": "diff --git a/prometheus.Dockerfile b/prometheus.Dockerfile\nnew file mode 100644\nindex 0000000000..1616a72824\n--- /dev/null\n+++ b/prometheus.Dockerfile\n@@ -0,0 +1,22 @@\n+FROM ubuntu:24.04\n+\n+# Avoid timezone prompts during package installation\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV TZ=UTC\n+\n+# Set working directory\n+WORKDIR /app\n+\n+# Install essential build and development tools\n+RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     wget     python3     python3-pip     python3-dev     python3-venv     nodejs     npm     default-jdk     gcc     g++     gdb     postgresql-client     mysql-client     sqlite3     iputils-ping     vim     nano     zip     unzip     ca-certificates     gnupg     lsb-release\n+\n+RUN mkdir -p /etc/apt/keyrings     && curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg     && echo     \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu     $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n+\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+RUN apt-get clean\n+RUN rm -rf /var/lib/apt/lists/*\n+RUN ln -s /usr/bin/python3 /usr/bin/python\n+\n+# Copy project files\n+COPY . /app/\ndiff --git a/prometheus_setup.sh b/prometheus_setup.sh\nnew file mode 100644\nindex 0000000000..fe8c011ddc\n--- /dev/null\n+++ b/prometheus_setup.sh\n@@ -0,0 +1,120 @@\n+#!/bin/bash\n+\n+# Exit immediately if a command exits with a non-zero status\n+set -e\n+\n+# Colors for output\n+RED='\\033[0;31m'\n+GREEN='\\033[0;32m'\n+YELLOW='\\033[1;33m'\n+NC='\\033[0m' # No Color\n+\n+# Logging functions\n+log() {\n+    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n+}\n+\n+error() {\n+    echo -e \"${RED}[ERROR] $1${NC}\" >&2\n+}\n+\n+warning() {\n+    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n+}\n+\n+# Ensure the script is running as root (Docker containers typically run as root)\n+if [ \"$(id -u)\" -ne 0 ]; then\n+    error \"This script must be run as root. Exiting.\"\n+    exit 1\n+fi\n+\n+# Install system dependencies\n+install_system_deps() {\n+    log \"Installing system dependencies...\"\n+    apt-get update -y\n+    apt-get install -y --no-install-recommends \\\n+        python3 \\\n+        python3-pip \\\n+        python3-venv \\\n+        build-essential \\\n+        libssl-dev \\\n+        libffi-dev \\\n+        curl \\\n+        wget \\\n+        ca-certificates\n+    apt-get clean\n+    rm -rf /var/lib/apt/lists/*\n+    log \"System dependencies installed successfully.\"\n+}\n+\n+# Set up project directory structure\n+setup_project_structure() {\n+    log \"Setting up project directory structure...\"\n+    mkdir -p /app\n+    chmod 755 /app\n+    log \"Project directory structure set up at /app.\"\n+}\n+\n+# Install Python dependencies\n+install_python_deps() {\n+    log \"Installing Python dependencies...\"\n+    cd /app\n+    if [ ! -f requirements.txt ]; then\n+        error \"requirements.txt not found in /app. Exiting.\"\n+        exit 1\n+    fi\n+    python3 -m venv venv\n+    source venv/bin/activate\n+    pip install --upgrade pip\n+    pip install -r requirements.txt\n+    deactivate\n+    log \"Python dependencies installed successfully.\"\n+}\n+\n+# Configure runtime environment\n+configure_runtime_env() {\n+    log \"Configuring runtime environment...\"\n+    export PYTHONUNBUFFERED=1\n+    export APP_HOME=/app\n+    export PATH=\"$APP_HOME/venv/bin:$PATH\"\n+    log \"Runtime environment configured.\"\n+}\n+\n+# Set up environment variables\n+setup_env_vars() {\n+    log \"Setting up environment variables...\"\n+    echo \"export PYTHONUNBUFFERED=1\" >> /etc/environment\n+    echo \"export APP_HOME=/app\" >> /etc/environment\n+    echo \"export PATH=\\\"/app/venv/bin:\\$PATH\\\"\" >> /etc/environment\n+    log \"Environment variables set up successfully.\"\n+}\n+\n+# Main setup function\n+main() {\n+    log \"Starting project environment setup...\"\n+\n+    # Step 1: Install system dependencies\n+    install_system_deps\n+\n+    # Step 2: Set up project directory structure\n+    setup_project_structure\n+\n+    # Step 3: Copy project files (assumes Dockerfile or volume mounts will handle this)\n+    log \"Copying project files...\"\n+    cp -r /tmp/project/* /app/ || warning \"No project files found in /tmp/project. Ensure files are mounted or copied.\"\n+\n+    # Step 4: Install Python dependencies\n+    install_python_deps\n+\n+    # Step 5: Configure runtime environment\n+    configure_runtime_env\n+\n+    # Step 6: Set up environment variables\n+    setup_env_vars\n+\n+    log \"Project environment setup completed successfully!\"\n+    log \"To activate the virtual environment, run: source /app/venv/bin/activate\"\n+}\n+\n+# Run main function\n+main \"$@\"\n\\ No newline at end of file\ndiff --git a/prometheus_testsuite_commands.txt b/prometheus_testsuite_commands.txt\nnew file mode 100644\nindex 0000000000..e69de29bb2\n",
            "env_implement_bash_path": "prometheus_setup.sh"
        },
        "timestamp": "2025-10-18T10:20:52.523073"
    },
    "vscode": {
        "project_name": "vscode",
        "project_repo_url": "https://github.com/microsoft/vscode",
        "success": true,
        "playground_path": "/tmp/tmpdw0cccfg/vscode",
        "container_info": null,
        "testsuite_states": {
            "testsuite_max_refined_query_loop": 0,
            "testsuite_context_provider_messages": [
                {
                    "type": "SystemMessage",
                    "content": "content=\"You are to discover ONE minimal, safe, and quick verification shell command from README/docs to confirm the environment/setup works (e.g., '<tool> --version', '<package> --help', 'make check', 'pytest -q'). Avoid destructive or long-running commands.\" additional_kwargs={} response_metadata={} id='9756f73b-04fe-451d-bdf3-f59a7e57bc80'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Find one quick verification command from README/docs for this repository.' additional_kwargs={} response_metadata={} id='87f23d2a-ceb3-40f1-94eb-5a6537be406f'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_IwXIaRZc3R6VgOoyWDgEL2eH', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 37897, 'total_tokens': 37917, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--757cb015-e058-46b3-9284-3787db3ca16b-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_IwXIaRZc3R6VgOoyWDgEL2eH', 'type': 'tool_call'}] usage_metadata={'input_tokens': 37897, 'output_tokens': 20, 'total_tokens': 37917, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3734887}\\npreview: # Visual Studio Code - Open Source (\"Code - OSS\")\\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=✓&q=is%3Aissue+is%3Aopen+label%3Abug)\\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\\n\\n## The Repository\\n\\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\\n\\n## Visual Studio Code\\n\\n<p align=\"center\">\\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png\">\\n</p>\\n\\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\\n\\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\\n\\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code\\'s website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\\n\\n## Contributing\\n\\nThere are many ways in which you can participate in this project, for example:\\n\\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content\\n\\nIf you are interested in fixing issues and contributing directly to the code base,\\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\\n\\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\\n* [Contributing to translations](https://aka.ms/vscodeloc)\\n\\n## Feedback\\n\\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\\n* [Request a new feature](CONTRIBUTING.md)\\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n* [File an issue](https://github.com/microsoft/vscode/issues)\\n* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)\\n* Follow [@code](https://twitter.com/code) and let us know what you think!\\n\\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\\n\\n## Related Projects\\n\\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\\n\\n## Bundled Extensions\\n\\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.\\n\\n## Development Container\\n\\nThis repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.\\n\\n* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.\\n  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\\n\\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\\n\\n## Code of Conduct\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## License\\n\\nCopyright (c) Microsoft Corporation. All rights reserved.\\n\\nLicensed under the [MIT](LICENSE.txt) license.\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/README.md\\', \\'node_id\\': 3734900}\\npreview: # VSCode Tests\\n\\n## Contents\\n\\nThis folder contains the various test runners for VSCode. Please refer to the documentation within for how to run them:\\n\\n* `unit`: our suite of unit tests ([README](unit/README.md))\\n* `integration`: our suite of API tests ([README](integration/browser/README.md))\\n* `smoke`: our suite of automated UI tests ([README](smoke/README.md))\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/unit/README.md\\', \\'node_id\\': 3734908}\\npreview: # Unit Tests\\n\\n## Run (inside Electron)\\n\\n    ./scripts/test.[sh|bat]\\n\\nAll unit tests are run inside a Electron renderer environment which access to DOM and Nodejs api. This is the closest to the environment in which VS Code itself ships. Notes:\\n\\n- use the `--debug` to see an electron window with dev tools which allows for debugging\\n- to run only a subset of tests use the `--run` or `--glob` options\\n- use `npm run watch` to automatically compile changes\\n\\nFor instance, `./scripts/test.sh --debug --glob **/extHost*.test.js` runs all tests from `extHost`-files and enables you to debug them.\\n\\n## Run (inside browser)\\n\\n    npm run test-browser -- --browser webkit --browser chromium\\n\\nUnit tests from layers `common` and `browser` are run inside `chromium`, `webkit`, and (soon\\'ish) `firefox` (using playwright). This complements our electron-based unit test runner and adds more coverage of supported platforms. Notes:\\n\\n- these tests are part of the continuous build, that means you might have test failures that only happen with webkit on _windows_ or _chromium_ on linux\\n- you can run these tests locally via `npm run test-browser -- --browser chromium --browser webkit`\\n- to debug, open `<vscode>/test/unit/browser/renderer.html` inside a browser and use the `?m=<amd_module>`-query to specify what AMD module to load, e.g `file:///Users/jrieken/Code/vscode/test/unit/browser/renderer.html?m=vs/base/test/common/strings.test` runs all tests from `strings.test.ts`\\n- to run only a subset of tests use the `--run` or `--glob` options\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (https://playwright.dev/docs/debug#verbose-api-logs)\\n\\n## Run (with node)\\n\\n    npm run test-node -- --run src/vs/editor/test/browser/controller/cursor.test.ts\\n\\n## Coverage\\n\\nThe following command will create a `coverage` folder in the `.build` folder at the root of the workspace:\\n\\n### OS X and Linux\\n\\n    ./scripts/test.sh --coverage\\n\\n### Windows\\n\\n    scripts\\\\test --coverage\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/smoke/README.md\\', \\'node_id\\': 3736755}\\npreview: # VS Code Smoke Test\\n\\nMake sure you are on **Node v12.x**.\\n\\n## Quick Overview\\n\\n```bash\\n# Build extensions in the VS Code repo (if needed)\\nnpm i && npm run compile\\n\\n# Dev (Electron)\\nnpm run smoketest\\n\\n# Dev (Web - Must be run on distro)\\nnpm run smoketest -- --web --browser [chromium|webkit]\\n\\n# Build (Electron)\\nnpm run smoketest -- --build <path to latest version>\\nexample: npm run smoketest -- --build /Applications/Visual\\\\ Studio\\\\ Code\\\\ -\\\\ Insiders.app\\n\\n# Build (Web - read instructions below)\\nnpm run smoketest -- --build <path to server web build (ends in -web)> --web --browser [chromium|webkit]\\n\\n# Remote (Electron)\\nnpm run smoketest -- --build <path to latest version> --remote\\n```\\n\\n\\\\* This step is necessary only when running without `--build` and OSS doesn\\'t already exist in the `.build/electron` directory.\\n\\n### Running for a release (Endgame)\\n\\nYou must always run the smoketest version that matches the release you are testing. So, if you want to run the smoketest for a release build (e.g. `release/1.22`), you need to check out that version of the smoke tests too:\\n\\n```bash\\ngit fetch\\ngit checkout release/1.22\\nnpm i && npm run compile\\ncd test/smoke\\nnpm i\\n```\\n\\n#### Web\\n\\nThere is no support for testing an old version to a new one yet.\\nInstead, simply configure the `--build` command line argument to point to the absolute path of the extracted server web build folder (e.g. `<rest of path here>/vscode-server-darwin-x64-web` for macOS). The server web build is available from the builds page (see previous subsection).\\n\\n**macOS**: if you have downloaded the server with web bits, make sure to run the following command before unzipping it to avoid security issues on startup:\\n\\n```bash\\nxattr -d com.apple.quarantine <path to server with web folder zip>\\n```\\n\\n**Note**: make sure to point to the server that includes the client bits!\\n\\n### Debug\\n\\n- `--verbose` logs all the low level driver calls made to Code;\\n- `-f PATTERN` (alias `-g PATTERN`) filters the tests to be run. You can also use pretty much any mocha argument;\\n- `--headless` will run playwright in headless mode when `--web` is used.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>), for example to `pw:browser`.\\n\\n### Develop\\n\\n```bash\\ncd test/smoke\\nnpm run watch\\n```\\n\\n## Troubleshooting\\n\\n### Error: Could not get a unique tmp filename, max tries reached\\n\\nOn Windows, check for the folder `C:\\\\Users\\\\<username>\\\\AppData\\\\Local\\\\Temp\\\\t`. If this folder exists, the `tmp` module can\\'t run properly, resulting in the error above. In this case, delete the `t` folder.\\n\\n## Pitfalls\\n\\n- Beware of workbench **state**. The tests within a single suite will share the same state.\\n\\n- Beware of **singletons**. This evil can, and will, manifest itself under the form of FS paths, TCP ports, IPC handles. Whenever writing a test, or setting up more smoke test architecture, make sure it can run simultaneously with any other tests and even itself. All test suites should be able to run many times in parallel.\\n\\n- Beware of **focus**. **Never** depend on DOM elements having focus using `.focused` classes or `:focus` pseudo-classes, since they will lose that state as soon as another window appears on top of the running VS Code window. A safe approach which avoids this problem is to use the `waitForActiveElement` API. Many tests use this whenever they need to wait for a specific element to _have focus_.\\n\\n- Beware of **timing**. You need to read from or write to the DOM... but is it the right time to do that? Can you 100% guarantee that `input` box will be visible at that point in time? Or are you just hoping that it will be so? Hope is your worst enemy in UI tests. Example: just because you triggered Quick Access with `F1`, it doesn\\'t mean that it\\'s open and you can just start typing; you must first wait for the input element to be in the DOM as well as be the current active element.\\n\\n- Beware of **waiting**. **Never** wait longer than a couple of seconds for anything, unless it\\'s justified. Think of it as a human using Code. Would a human take 10 minutes to run through the Search viewlet smoke test? Then, the computer should even be faster. **Don\\'t** use `setTimeout` just because. Think about what you should wait for in the DOM to be ready and wait for that instead.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/monaco/README.md\\', \\'node_id\\': 3738548}\\npreview: # Monaco Editor Test\\n\\nThis directory contains scripts that are used to smoke test the Monaco Editor distribution.\\n\\n## Setup & Bundle\\n\\n $test/monaco> npm i\\n $test/monaco> npm run bundle\\n\\n## Compile and run tests\\n\\n $test/monaco> npm run compile\\n $test/monaco> npm run test\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/mcp/README.md\\', \\'node_id\\': 3738926}\\npreview: # Code - OSS Development MCP Server\\n\\nThis directory contains a Model Context Protocol (MCP) server that provides Playwright browser automation capabilities for Code - OSS development and testing. The MCP server exposes Code - OSS\\'s Playwright testing infrastructure through a standardized interface, allowing AI assistants and other tools to interact with browsers programmatically.\\n\\n## What is MCP?\\n\\nThe [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that enables AI assistants to securely connect to external data sources and tools. This MCP server specifically provides browser automation capabilities using Playwright, making it possible for AI assistants to:\\n\\n- Navigate web pages\\n- Interact with UI elements (click, type, hover, etc.)\\n- Take screenshots and capture page content\\n- Evaluate JavaScript in browser contexts\\n- Handle file uploads and downloads\\n- Manage browser tabs and windows\\n\\n## Quick Start - Stdio\\n\\nFirstly, make sure you install all dependencies (`npm i`) at the root of the repo.\\n\\nThen, open the Command Palette and run:\\n```\\nMCP: List Servers → vscode-playwright-mcp → Start Server\\n```\\nor open [mcp.json](../../.vscode/mcp.json) and start it from there.\\n\\nThat\\'s it! It should automatically compile everything needed.\\n\\nThen you can use `/playwright` to ask specific questions.\\n\\n## Arguments\\n\\nOpen the [mcp.json](../../.vscode/mcp.json) and modify the `args`:\\n\\n* `[\"run\", \"start-stdio\"]`: opens Electron window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\"]`: opens a Chromium window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\", \"--headless\"]`: opens a headless window\\n\\n> *NOTE: `--web` requires running `npm run install-playwright` from root*\\n\\n## Debugging the server\\n\\nYou can modify the mcp.json to debug the server:\\n```JSON\\n\"vscode-playwright-mcp\": {\\n\\t\"type\": \"stdio\",\\n\\t\"command\": \"node\",\\n\\t\"args\": [\"./out/stdio.js\"],\\n\\t\"cwd\": \"${workspaceFolder}/test/mcp\",\\n\\t\"dev\": {\\n\\t\\t\"watch\": \"test/mcp/**/*.ts\",\\n\\t\\t\"debug\": {\\n\\t\\t\\t\"type\": \"node\"\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\n## What the Server Provides\\n\\nThe MCP server exposes a comprehensive set of browser automation tools through the MCP protocol:\\n\\n### Element Interaction\\n- Click on elements (single, double, right-click)\\n- Type text into input fields\\n- Hover over elements\\n- Drag and drop between elements\\n- Select options in dropdowns\\n\\n### Content Capture & Analysis\\n- Take screenshots (full page or specific elements)\\n- Capture accessibility snapshots for better element targeting\\n- Get page console messages\\n- Monitor network requests\\n\\n### Advanced Features\\n- Evaluate JavaScript code in browser contexts\\n- Handle file uploads\\n- Wait for specific content or time delays\\n- Handle browser dialogs and alerts\\n\\n## Development\\n\\n### Manual Setup (Advanced)\\n\\nIf you prefer to run the server manually:\\n\\n```bash\\n# Navigate to the MCP directory\\ncd test/mcp\\n\\n# Install dependencies\\nnpm install\\n\\n# Compile TypeScript\\nnpm run compile # or watch\\n\\n# Start the server\\nnpm start\\n```\\n\\n### Project Structure\\n\\n```\\ntest/mcp/\\n├── src/\\n│   ├── main.ts              # Express server and MCP endpoint handlers\\n│   ├── playwright.ts        # Code - OSS Playwright integration\\n│   ├── inMemoryEventStore.ts # Session management for resumability\\n│   └── utils.ts             # Utility functions\\n├── package.json             # Dependencies and scripts\\n├── tsconfig.json           # TypeScript configuration\\n└── README.md              # This file\\n```\\n\\n### Key Features\\n\\n- **Session Management**: Supports multiple concurrent MCP sessions with proper cleanup\\n- **Resumability**: Built-in event store for connection resumption\\n- **Code - OSS Integration**: Uses Code - OSS\\'s existing Playwright test infrastructure\\n- **CORS Support**: Configured for cross-origin requests\\n- **Error Handling**: Comprehensive error handling and logging\\n\\n## Troubleshooting\\n\\n### Server Won\\'t Start\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Verify all dependencies are installed with `npm install`\\n\\n### Browser Automation Issues\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Check the server logs for Playwright-related errors\\n- Verify the test repository is properly cloned\\n\\n## Contributing\\n\\nThis MCP server is part of the Code - OSS development infrastructure. When making changes:\\n\\n1. Follow the existing TypeScript and coding conventions\\n2. Test with multiple MCP clients if possible\\n3. Update this README if adding new capabilities\\n4. Ensure proper error handling and logging\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the top-level project\\'s license file for details.\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/integration/browser/README.md\\', \\'node_id\\': 3740947}\\npreview: # Integration test\\n\\n## Compile\\n\\nMake sure to run the following commands to compile and install dependencies:\\n\\n    cd test/integration/browser\\n    npm i\\n    npm run compile\\n\\n## Run (inside Electron)\\n\\n    scripts/test-integration.[sh|bat]\\n\\nAll integration tests run in an Electron instance. You can specify to run the tests against a real build by setting the environment variables `INTEGRATION_TEST_ELECTRON_PATH` and `VSCODE_REMOTE_SERVER_PATH` (if you want to include remote tests).\\n\\n## Run (inside browser)\\n\\n    scripts/test-web-integration.[sh|bat] --browser [chromium|webkit] [--debug]\\n\\nAll integration tests run in a browser instance as specified by the command line arguments.\\n\\nAdd the `--debug` flag to see a browser window with the tests running.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>)\\n\\n## Debug\\n\\nAll integration tests can be run and debugged from within VSCode (both Electron and Web) simply by selecting the related launch configuration and running them.\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/automation/README.md\\', \\'node_id\\': 3741239}\\npreview: # VS Code Automation Package\\n\\nThis package contains functionality for automating various components of the VS Code UI, via an automation \"driver\" that connects from a separate process. It is used by the `smoke` tests.\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vscode-dts/README.md\\', \\'node_id\\': 3744265}\\npreview: # vscode-dts\\n\\nThis is the place for the stable API and for API proposals.\\n\\n## Consume a proposal\\n\\n1. find a proposal you are interested in\\n1. add its name to your extensions `package.json#enabledApiProposals` property\\n1. run `npx vscode-dts dev` to download the `d.ts` files into your project\\n1. don\\'t forget that extension using proposed API cannot be published\\n1. learn more here: <https://code.visualstudio.com/api/advanced-topics/using-proposed-api>\\n\\n## Add a new proposal\\n\\n1. create a _new_ file in this directory, its name must follow this pattern `vscode.proposed.[a-zA-Z]+.d.ts`\\n1. creating the proposal-file will automatically update `src/vs/platform/extensions/common/extensionsApiProposals.ts` (make sure to run `npm run watch`)\\n1. declare and implement your proposal\\n1. make sure to use the `checkProposedApiEnabled` and/or `isProposedApiEnabled`-utils to enforce the API being proposed. Make sure to invoke them with your proposal\\'s name which got generated into `extensionsApiProposals.ts`\\n1. Most likely will need to add your proposed api to vscode-api-tests as well\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vs/workbench/contrib/terminalContrib/README.md\\', \\'node_id\\': 3897567}\\npreview: _Terminal contribs_ are a way of splitting out standalone terminal features into their own components that build upon the main terminal code. The `terminalContrib/` folder can only import from `terminal/`, not the other way around. There are eslint rules to prevent this circular dependencies.\\n\\nHaving the entire feature and its tests in the same place makes not only the contrib easier to maintain and understand, but also the core terminal code as it\\'s less interspersed with feature code. Sometimes it\\'s not possible without bigger changes to make the feature totally standalone, in this case the goal is to get as close as possible.\\n\\nThis should not be confused with the similar `ITerminalContribution` which is a parallel to `IEditorContribution` and is used for decorating each individual terminal with additional functionality. An entry in `terminalContrib/` may use `ITerminalContribution`s to add its features.\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vs/editor/test/node/diffing/README.md\\', \\'node_id\\': 4481497}\\npreview: # Diffing Fixture Tests\\n\\nEvery folder in `fixtures` represents a test.\\nThe file that starts with `1.` is diffed against the file that starts with `2.`. Use `tst` instead of `ts` to avoid compiler/linter errors for typescript diff files.\\n\\n* Missing `*.expected.diff.json` are created automatically (as well as an `*.invalid.diff.json` file).\\n* If the actual diff does not equal the expected diff, the expected file is updated automatically. The previous value of the expected file is written to `*.invalid.diff.json`.\\n* The test will fail if there are any `*.invalid.diff.json` files. This makes sure that the test keeps failing even if it is run a second time.\\n\\nWhen changing the diffing algorithm, run the fixture tests, review the diff of the `*.expected.diff.json` files and delete all `*.invalid.diff.json` files.\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/typescript-language-features/README.md\\', \\'node_id\\': 4707968}\\npreview: # Language Features for TypeScript and JavaScript files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [TypeScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/typescript) and [JavaScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/javascript) to learn about the features of this extension.\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/typescript-language-features/web/README.md\\', \\'node_id\\': 4707977}\\npreview: # vscode-wasm-typescript\\n\\nLanguage server host for typescript using vscode\\'s sync-api in the browser.\\n\\n## Getting up and running\\n\\nTo test this out, you\\'ll need three shells:\\n\\n1. `npm i` for vscode itself\\n2. `npm run watch-web` for the web side\\n3. `node <root>/scripts/code-web.js --coi`\\n\\nThe last command will open a browser window. You\\'ll want to add `?vscode-coi=`\\nto the end. This is for enabling shared array buffers. So, for example:\\n`http://localhost:8080/?vscode-coi=`.\\n\\n### Working on type acquisition\\n\\nIn order to work with web\\'s new type acquisition, you\\'ll need to enable\\n`TypeScript > Experimental > Tsserver > Web: Enable Project Wide Intellisense`\\nin your VS Code options (`Ctrl-,`), you may need to reload the page.\\n\\nThis happens when working in a regular `.js` file on a dependency without\\ndeclared types. You should be able to open `file.js` and write something like\\n`import lodash from \\'lodash\\';` at the top of the file and, after a moment, get\\ntypes and other intellisense features (like Go To Def/Source Def) working as\\nexpected. This scenario works off Tsserver\\'s own Automatic Type Acquisition\\ncapabilities, and simulates a \"global\" types cache stored at\\n`/vscode-global-typings/ts-nul-authority/project`, which is backed by an\\nin-memory `MemFs` `FileSystemProvider`.\\n\\n### Simulated `node_modules`\\n\\nFor regular `.ts` files, instead of going through Tsserver\\'s type acquisition,\\na separate `AutoInstallerFs` is used to create a \"virtual\" `node_modules` that\\nextracts desired packages on demand, to an underlying `MemFs`. This will\\nhappen any time a filesystem operation is done inside a `node_modules` folder\\nacross any project in the workspace, and will use the \"real\" `package.json`\\n(and, if present, `package-lock.json`) to resolve the dependency tree.\\n\\nA fallback is then set up such that when a URI like\\n`memfs:/path/to/node_modules/lodash/lodash.d.ts` is accessed, that gets\\nredirected to\\n`vscode-node-modules:/ts-nul-authority/memfs/ts-nul-authority/path/to/node_modules/lodash/lodash.d.ts`,\\nwhich will be sent to the `AutoInstallerFs`.\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/theme-seti/README.md\\', \\'node_id\\': 4725047}\\npreview: # theme-seti\\n\\nThis is an icon theme that uses the icons from [`seti-ui`](https://github.com/jesseweed/seti-ui).\\n\\n## Updating icons\\n\\nThere is script that can be used to update icons, [./build/update-icon-theme.js](build/update-icon-theme.js).\\n\\nTo run this script, run `npm run update` from the `theme-seti` directory.\\n\\nThis can be run in one of two ways: looking at a local copy of `seti-ui` for icons, or getting them straight from GitHub.\\n\\nIf you want to run it from a local copy of `seti-ui`, first clone [`seti-ui`](https://github.com/jesseweed/seti-ui) to the folder next to your `vscode` repo (from the `theme-seti` directory, `../../`).\\nThen, inside the `set-ui` directory, run `npm install` followed by `npm run prepublishOnly`. This will generate updated icons.\\n\\nIf you want to download the icons straight from GitHub, change the `FROM_DISK` variable to `false` inside of `update-icon-theme.js`.\\n\\n### Languages not shipped with `vscode`\\n\\nLanguages that are not shipped with `vscode` must be added to the `nonBuiltInLanguages` object inside of `update-icon-theme.js`.\\n\\nThese should match [the file mapping in `seti-ui`](https://github.com/jesseweed/seti-ui/blob/master/styles/components/icons/mapping.less).\\n\\nPlease try and keep this list in alphabetical order! Thank you.\\n\\n## Previewing icons\\n\\nThere is a [`./icons/preview.html`](./icons/preview.html) file that can be opened to see all of the icons included in the theme.\\nNote that to view this, it needs to be hosted by a web server.\\n\\nWhen updating icons, it is always a good idea to make sure that they work properly by looking at this page.\\nWhen submitting a PR that updates these icons, a screenshot of the preview page should accompany it.\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/terminal-suggest/README.md\\', \\'node_id\\': 4725296}\\npreview: # Terminal Suggestions\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled. To enable the completions from this extension, set `terminal.integrated.suggest.enabled` to `true`.\\n\\n## Features\\n\\nProvides terminal suggestions for zsh, bash, fish, and pwsh.\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/terminal-suggest/src/fig/README.md\\', \\'node_id\\': 4728058}\\npreview: This folder contains the `autocomplete-parser` project from https://github.com/aws/amazon-q-developer-cli/blob/main/packages/autocomplete-parser and its dependencies which were located in siblings folders and https://github.com/withfig/autocomplete-tools, both licenses under MIT. The fork was necessary for a few reasons:\\n\\n- They ship as ESM modules which we\\'re not ready to consume just yet.\\n- We want the more complete `autocomplete-parser` that contains the important `parseArguments` function that does the bulk of the smarts in parsing the fig commands.\\n- We needed to strip out all the implementation-specific parts from their `api-bindings` project that deals with settings, IPC, fuzzy sorting, etc.\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/simple-browser/README.md\\', \\'node_id\\': 4735296}\\npreview: # Simple Browser\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nProvides a very basic browser preview using an iframe embedded in a [webviewW](). This extension is primarily meant to be used by other extensions for showing simple web content.\\n\\n\\nResult 18:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/search-result/README.md\\', \\'node_id\\': 4735682}\\npreview: # Language Features for Search Result files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nThis extension provides Syntax Highlighting, Symbol Information, Result Highlighting, and Go to Definition capabilities for the Search Results Editor.\\n\\n\\nResult 19:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/references-view/README.md\\', \\'node_id\\': 4735988}\\npreview: # References View\\n\\nThis extension shows reference search results as separate view, just like search results. It complements the peek view presentation that is also built into VS Code. The following features are available:\\n\\n- List All References via the Command Palette, the Context Menu, or via <kbd>Alt+Shift+F12</kbd>\\n- View references in a dedicated tree view that sits in the sidebar\\n- Navigate through search results via <kbd>F4</kbd> and <kbd>Shift+F4</kbd>\\n- Remove references from the list via inline commands\\n\\n![](https://raw.githubusercontent.com/microsoft/vscode-references-view/master/media/demo.png)\\n\\n**Note** that this extension is bundled with Visual Studio Code version 1.29 and later - it doesn\\'t need to be installed anymore.\\n\\n## Requirements\\n\\nThis extension is just an alternative UI for reference search and extensions implementing reference search must still be installed.\\n\\n## Issues\\n\\nThis extension ships with Visual Studio Code and uses its issue tracker. Please file issue here: https://github.com/Microsoft/vscode/issues\\n\\n# Contributing\\n\\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\\n\\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n\\nResult 20:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/php-language-features/README.md\\', \\'node_id\\': 4737042}\\npreview: # Language Features for PHP files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [PHP in Visual Studio Code](https://code.visualstudio.com/docs/languages/php) to learn about the features of this extension.\\n\\n\\nResult 21:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/npm/README.md\\', \\'node_id\\': 4737797}\\npreview: # Node npm\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\n### Task Running\\n\\nThis extension supports running npm scripts defined in the `package.json` as [tasks](https://code.visualstudio.com/docs/editor/tasks). Scripts with the name \\'build\\', \\'compile\\', or \\'watch\\'\\nare treated as build tasks.\\n\\nTo run scripts as tasks, use the **Tasks** menu.\\n\\nFor more information about auto detection of Tasks, see the [documentation](https://code.visualstudio.com/Docs/editor/tasks#_task-autodetection).\\n\\n### Script Explorer\\n\\nThe Npm Script Explorer shows the npm scripts found in your workspace. The explorer view is enabled by the setting `npm.enableScriptExplorer`. A script can be opened, run, or debug from the explorer.\\n\\n### Run Scripts from the Editor\\n\\nThe extension supports to run the selected script as a task when editing the `package.json`file. You can either run a script from\\nthe hover shown on a script or using the command `Run Selected Npm Script`.\\n\\n### Run Scripts from a Folder in the Explorer\\n\\nThe extension supports running a script as a task from a folder in the Explorer. The command  `Run NPM Script in Folder...` shown in the Explorer context menu finds all scripts in `package.json` files that are contained in this folder. You can then select the script to be executed as a task from the resulting list. You enable this support with the `npm.runScriptFromFolder` which is `false` by default.\\n\\n### Others\\n\\nThe extension fetches data from <https://registry.npmjs.org> and <https://registry.bower.io> to provide auto-completion and information on hover features on npm dependencies.\\n\\n## Settings\\n\\n- `npm.autoDetect` - Enable detecting scripts as tasks, the default is `on`.\\n- `npm.runSilent` - Run npm script with the `--silent` option, the default is `false`.\\n- `npm.packageManager` - The package manager used to install dependencies: `auto`, `npm`, `yarn`, `pnpm` or `bun`. The default is `auto`, which detects your package manager based on files in your workspace.\\n- `npm.scriptRunner` - The script runner used to run the scripts: `auto`, `npm`, `yarn`, `pnpm`, `bun` or `node`. The default is `auto`, which detects your script runner based on files in your workspace.\\n- `npm.exclude` - Glob patterns for folders that should be excluded from automatic script detection. The pattern is matched against the **absolute path** of the package.json. For example, to exclude all test folders use \\'&ast;&ast;/test/&ast;&ast;\\'.\\n- `npm.enableScriptExplorer` - Enable an explorer view for npm scripts.\\n- `npm.scriptExplorerAction` - The default click action: `open` or `run`, the default is `open`.\\n- `npm.enableRunFromFolder` - Enable running npm scripts from the context menu of folders in Explorer, the default is `false`.\\n- `npm.scriptCodeLens.enable` - Enable/disable the code lenses to run a script, the default is `false`.\\n\\n\\nResult 22:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/notebook-renderers/README.md\\', \\'node_id\\': 4739483}\\npreview: # Builtin Notebook Output Renderers for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following notebook renderers for VS Code:\\n\\n- Image renderer for png, jpeg and gif\\n\\n\\nResult 23:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/microsoft-authentication/README.md\\', \\'node_id\\': 4740838}\\npreview: # Microsoft Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to Microsoft. It registers the `microsoft` Authentication Provider that can be leveraged by other extensions. This also provides the Microsoft authentication used by Settings Sync.\\n\\nAdditionally, it provides the `microsoft-sovereign-cloud` Authentication Provider that can be used to sign in to other Azure clouds like Azure for US Government or Azure China. Use the setting `microsoft-sovereign-cloud.endpoint` to select the authentication endpoint the provider should use. Please note that different scopes may also be required in different environments.\\n\\n\\nResult 24:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/mermaid-chat-features/README.md\\', \\'node_id\\': 4743452}\\npreview: # Mermaid Chat Features\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds basic [Mermaid.js](https://mermaid.js.org) diagram rendering to build-in chat.\\n\\n\\nResult 25:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/merge-conflict/README.md\\', \\'node_id\\': 4743675}\\npreview: # Merge Conflict\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Merge Conflicts in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_merge-conflicts) to learn about features of this extension.\\n\\n\\nResult 26:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/media-preview/README.md\\', \\'node_id\\': 4744324}\\npreview: # Media Preview\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides basic preview for images, audio and video files.\\n\\n### Supported image file extensions\\n\\n- `.jpg`, `.jpe`, `.jpeg`\\n- `.png`\\n- `.bmp`\\n- `.gif`\\n- `.ico`\\n- `.webp`\\n- `.avif`\\n\\n### Supported audio formats\\n\\n- `.mp3`\\n- `.wav`\\n- `.ogg`, `.oga`\\n\\n### Supported video formats\\n\\n- `.mp4` (does not support `aac` audio tracks)\\n- `.webm` (vp8 only)\\n\\n\\nResult 27:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/markdown-math/README.md\\', \\'node_id\\': 4745044}\\npreview: # Markdown Math\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds math rendering using [KaTeX](https://katex.org) to VS Code\\'s built-in markdown preview and markdown cells in notebooks.\\n\\n\\nResult 28:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/markdown-language-features/README.md\\', \\'node_id\\': 4745172}\\npreview: # Language Features for Markdown files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Markdown in Visual Studio Code](https://code.visualstudio.com/docs/languages/markdown) to learn about the features of this extension.\\n\\n\\nResult 29:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/json-language-features/README.md\\', \\'node_id\\': 4751670}\\npreview: # Language Features for JSON files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [JSON in Visual Studio Code](https://code.visualstudio.com/docs/languages/json) to learn about the features of this extension.\\n\\n\\nResult 30:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/json-language-features/server/README.md\\', \\'node_id\\': 4751677}\\npreview: # VSCode JSON Language Server\\n\\n[![NPM Version](https://img.shields.io/npm/v/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Version](https://img.shields.io/npm/l/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n\\nThe JSON Language server provides language-specific smarts for editing, validating and understanding JSON documents. It runs as a separate executable and implements the [language server protocol](https://microsoft.github.io/language-server-protocol/overview) to be connected by any code editor or IDE.\\n\\n## Capabilities\\n\\n### Server capabilities\\n\\nThe JSON language server supports requests on documents of language id `json` and `jsonc`.\\n\\n- `json` documents are parsed and validated following the [JSON specification](https://tools.ietf.org/html/rfc7159).\\n- `jsonc` documents additionally accept single line (`//`) and multi-line comments (`/* ... */`). JSONC is a VSCode specific file format, intended for VSCode configuration files, without any aspirations to define a new common file format.\\n\\nThe server implements the following capabilities of the language server protocol:\\n\\n- [Code completion](https://microsoft.github.io/language-server-protocol/specification#textDocument_completion) for JSON properties and values based on the document\\'s [JSON schema](http://json-schema.org/) or based on existing properties and values used at other places in the document. JSON schemas are configured through the server configuration options.\\n- [Hover](https://microsoft.github.io/language-server-protocol/specification#textDocument_hover) for values based on descriptions in the document\\'s [JSON schema](http://json-schema.org/).\\n- [Document Symbols](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentSymbol) for quick navigation to properties in the document.\\n- [Document Colors](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentColor) for showing color decorators on values representing colors and [Color Presentation](https://microsoft.github.io/language-server-protocol/specification#textDocument_colorPresentation) for color presentation information to support color... Output has been truncated becuase it is too long, please narrow down your query if you wish to see more' name='preview_file_content_with_basename' id='257d6f3c-324c-417f-8782-329e9de076b5' tool_call_id='call_IwXIaRZc3R6VgOoyWDgEL2eH' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3734887}, 'preview': '# Visual Studio Code - Open Source (\"Code - OSS\")\\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=✓&q=is%3Aissue+is%3Aopen+label%3Abug)\\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\\n\\n## The Repository\\n\\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\\n\\n## Visual Studio Code\\n\\n<p align=\"center\">\\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png\">\\n</p>\\n\\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\\n\\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\\n\\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code\\'s website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\\n\\n## Contributing\\n\\nThere are many ways in which you can participate in this project, for example:\\n\\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content\\n\\nIf you are interested in fixing issues and contributing directly to the code base,\\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\\n\\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\\n* [Contributing to translations](https://aka.ms/vscodeloc)\\n\\n## Feedback\\n\\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\\n* [Request a new feature](CONTRIBUTING.md)\\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n* [File an issue](https://github.com/microsoft/vscode/issues)\\n* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)\\n* Follow [@code](https://twitter.com/code) and let us know what you think!\\n\\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\\n\\n## Related Projects\\n\\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\\n\\n## Bundled Extensions\\n\\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.\\n\\n## Development Container\\n\\nThis repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.\\n\\n* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.\\n  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\\n\\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\\n\\n## Code of Conduct\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## License\\n\\nCopyright (c) Microsoft Corporation. All rights reserved.\\n\\nLicensed under the [MIT](LICENSE.txt) license.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3734900}, 'preview': '# VSCode Tests\\n\\n## Contents\\n\\nThis folder contains the various test runners for VSCode. Please refer to the documentation within for how to run them:\\n\\n* `unit`: our suite of unit tests ([README](unit/README.md))\\n* `integration`: our suite of API tests ([README](integration/browser/README.md))\\n* `smoke`: our suite of automated UI tests ([README](smoke/README.md))'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3734908}, 'preview': \"# Unit Tests\\n\\n## Run (inside Electron)\\n\\n    ./scripts/test.[sh|bat]\\n\\nAll unit tests are run inside a Electron renderer environment which access to DOM and Nodejs api. This is the closest to the environment in which VS Code itself ships. Notes:\\n\\n- use the `--debug` to see an electron window with dev tools which allows for debugging\\n- to run only a subset of tests use the `--run` or `--glob` options\\n- use `npm run watch` to automatically compile changes\\n\\nFor instance, `./scripts/test.sh --debug --glob **/extHost*.test.js` runs all tests from `extHost`-files and enables you to debug them.\\n\\n## Run (inside browser)\\n\\n    npm run test-browser -- --browser webkit --browser chromium\\n\\nUnit tests from layers `common` and `browser` are run inside `chromium`, `webkit`, and (soon'ish) `firefox` (using playwright). This complements our electron-based unit test runner and adds more coverage of supported platforms. Notes:\\n\\n- these tests are part of the continuous build, that means you might have test failures that only happen with webkit on _windows_ or _chromium_ on linux\\n- you can run these tests locally via `npm run test-browser -- --browser chromium --browser webkit`\\n- to debug, open `<vscode>/test/unit/browser/renderer.html` inside a browser and use the `?m=<amd_module>`-query to specify what AMD module to load, e.g `file:///Users/jrieken/Code/vscode/test/unit/browser/renderer.html?m=vs/base/test/common/strings.test` runs all tests from `strings.test.ts`\\n- to run only a subset of tests use the `--run` or `--glob` options\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (https://playwright.dev/docs/debug#verbose-api-logs)\\n\\n## Run (with node)\\n\\n    npm run test-node -- --run src/vs/editor/test/browser/controller/cursor.test.ts\\n\\n## Coverage\\n\\nThe following command will create a `coverage` folder in the `.build` folder at the root of the workspace:\\n\\n### OS X and Linux\\n\\n    ./scripts/test.sh --coverage\\n\\n### Windows\\n\\n    scripts\\\\test --coverage\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/smoke/README.md', 'node_id': 3736755}, 'preview': \"# VS Code Smoke Test\\n\\nMake sure you are on **Node v12.x**.\\n\\n## Quick Overview\\n\\n```bash\\n# Build extensions in the VS Code repo (if needed)\\nnpm i && npm run compile\\n\\n# Dev (Electron)\\nnpm run smoketest\\n\\n# Dev (Web - Must be run on distro)\\nnpm run smoketest -- --web --browser [chromium|webkit]\\n\\n# Build (Electron)\\nnpm run smoketest -- --build <path to latest version>\\nexample: npm run smoketest -- --build /Applications/Visual\\\\ Studio\\\\ Code\\\\ -\\\\ Insiders.app\\n\\n# Build (Web - read instructions below)\\nnpm run smoketest -- --build <path to server web build (ends in -web)> --web --browser [chromium|webkit]\\n\\n# Remote (Electron)\\nnpm run smoketest -- --build <path to latest version> --remote\\n```\\n\\n\\\\* This step is necessary only when running without `--build` and OSS doesn't already exist in the `.build/electron` directory.\\n\\n### Running for a release (Endgame)\\n\\nYou must always run the smoketest version that matches the release you are testing. So, if you want to run the smoketest for a release build (e.g. `release/1.22`), you need to check out that version of the smoke tests too:\\n\\n```bash\\ngit fetch\\ngit checkout release/1.22\\nnpm i && npm run compile\\ncd test/smoke\\nnpm i\\n```\\n\\n#### Web\\n\\nThere is no support for testing an old version to a new one yet.\\nInstead, simply configure the `--build` command line argument to point to the absolute path of the extracted server web build folder (e.g. `<rest of path here>/vscode-server-darwin-x64-web` for macOS). The server web build is available from the builds page (see previous subsection).\\n\\n**macOS**: if you have downloaded the server with web bits, make sure to run the following command before unzipping it to avoid security issues on startup:\\n\\n```bash\\nxattr -d com.apple.quarantine <path to server with web folder zip>\\n```\\n\\n**Note**: make sure to point to the server that includes the client bits!\\n\\n### Debug\\n\\n- `--verbose` logs all the low level driver calls made to Code;\\n- `-f PATTERN` (alias `-g PATTERN`) filters the tests to be run. You can also use pretty much any mocha argument;\\n- `--headless` will run playwright in headless mode when `--web` is used.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>), for example to `pw:browser`.\\n\\n### Develop\\n\\n```bash\\ncd test/smoke\\nnpm run watch\\n```\\n\\n## Troubleshooting\\n\\n### Error: Could not get a unique tmp filename, max tries reached\\n\\nOn Windows, check for the folder `C:\\\\Users\\\\<username>\\\\AppData\\\\Local\\\\Temp\\\\t`. If this folder exists, the `tmp` module can't run properly, resulting in the error above. In this case, delete the `t` folder.\\n\\n## Pitfalls\\n\\n- Beware of workbench **state**. The tests within a single suite will share the same state.\\n\\n- Beware of **singletons**. This evil can, and will, manifest itself under the form of FS paths, TCP ports, IPC handles. Whenever writing a test, or setting up more smoke test architecture, make sure it can run simultaneously with any other tests and even itself. All test suites should be able to run many times in parallel.\\n\\n- Beware of **focus**. **Never** depend on DOM elements having focus using `.focused` classes or `:focus` pseudo-classes, since they will lose that state as soon as another window appears on top of the running VS Code window. A safe approach which avoids this problem is to use the `waitForActiveElement` API. Many tests use this whenever they need to wait for a specific element to _have focus_.\\n\\n- Beware of **timing**. You need to read from or write to the DOM... but is it the right time to do that? Can you 100% guarantee that `input` box will be visible at that point in time? Or are you just hoping that it will be so? Hope is your worst enemy in UI tests. Example: just because you triggered Quick Access with `F1`, it doesn't mean that it's open and you can just start typing; you must first wait for the input element to be in the DOM as well as be the current active element.\\n\\n- Beware of **waiting**. **Never** wait longer than a couple of seconds for anything, unless it's justified. Think of it as a human using Code. Would a human take 10 minutes to run through the Search viewlet smoke test? Then, the computer should even be faster. **Don't** use `setTimeout` just because. Think about what you should wait for in the DOM to be ready and wait for that instead.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/monaco/README.md', 'node_id': 3738548}, 'preview': '# Monaco Editor Test\\n\\nThis directory contains scripts that are used to smoke test the Monaco Editor distribution.\\n\\n## Setup & Bundle\\n\\n $test/monaco> npm i\\n $test/monaco> npm run bundle\\n\\n## Compile and run tests\\n\\n $test/monaco> npm run compile\\n $test/monaco> npm run test'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/mcp/README.md', 'node_id': 3738926}, 'preview': '# Code - OSS Development MCP Server\\n\\nThis directory contains a Model Context Protocol (MCP) server that provides Playwright browser automation capabilities for Code - OSS development and testing. The MCP server exposes Code - OSS\\'s Playwright testing infrastructure through a standardized interface, allowing AI assistants and other tools to interact with browsers programmatically.\\n\\n## What is MCP?\\n\\nThe [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that enables AI assistants to securely connect to external data sources and tools. This MCP server specifically provides browser automation capabilities using Playwright, making it possible for AI assistants to:\\n\\n- Navigate web pages\\n- Interact with UI elements (click, type, hover, etc.)\\n- Take screenshots and capture page content\\n- Evaluate JavaScript in browser contexts\\n- Handle file uploads and downloads\\n- Manage browser tabs and windows\\n\\n## Quick Start - Stdio\\n\\nFirstly, make sure you install all dependencies (`npm i`) at the root of the repo.\\n\\nThen, open the Command Palette and run:\\n```\\nMCP: List Servers → vscode-playwright-mcp → Start Server\\n```\\nor open [mcp.json](../../.vscode/mcp.json) and start it from there.\\n\\nThat\\'s it! It should automatically compile everything needed.\\n\\nThen you can use `/playwright` to ask specific questions.\\n\\n## Arguments\\n\\nOpen the [mcp.json](../../.vscode/mcp.json) and modify the `args`:\\n\\n* `[\"run\", \"start-stdio\"]`: opens Electron window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\"]`: opens a Chromium window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\", \"--headless\"]`: opens a headless window\\n\\n> *NOTE: `--web` requires running `npm run install-playwright` from root*\\n\\n## Debugging the server\\n\\nYou can modify the mcp.json to debug the server:\\n```JSON\\n\"vscode-playwright-mcp\": {\\n\\t\"type\": \"stdio\",\\n\\t\"command\": \"node\",\\n\\t\"args\": [\"./out/stdio.js\"],\\n\\t\"cwd\": \"${workspaceFolder}/test/mcp\",\\n\\t\"dev\": {\\n\\t\\t\"watch\": \"test/mcp/**/*.ts\",\\n\\t\\t\"debug\": {\\n\\t\\t\\t\"type\": \"node\"\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\n## What the Server Provides\\n\\nThe MCP server exposes a comprehensive set of browser automation tools through the MCP protocol:\\n\\n### Element Interaction\\n- Click on elements (single, double, right-click)\\n- Type text into input fields\\n- Hover over elements\\n- Drag and drop between elements\\n- Select options in dropdowns\\n\\n### Content Capture & Analysis\\n- Take screenshots (full page or specific elements)\\n- Capture accessibility snapshots for better element targeting\\n- Get page console messages\\n- Monitor network requests\\n\\n### Advanced Features\\n- Evaluate JavaScript code in browser contexts\\n- Handle file uploads\\n- Wait for specific content or time delays\\n- Handle browser dialogs and alerts\\n\\n## Development\\n\\n### Manual Setup (Advanced)\\n\\nIf you prefer to run the server manually:\\n\\n```bash\\n# Navigate to the MCP directory\\ncd test/mcp\\n\\n# Install dependencies\\nnpm install\\n\\n# Compile TypeScript\\nnpm run compile # or watch\\n\\n# Start the server\\nnpm start\\n```\\n\\n### Project Structure\\n\\n```\\ntest/mcp/\\n├── src/\\n│   ├── main.ts              # Express server and MCP endpoint handlers\\n│   ├── playwright.ts        # Code - OSS Playwright integration\\n│   ├── inMemoryEventStore.ts # Session management for resumability\\n│   └── utils.ts             # Utility functions\\n├── package.json             # Dependencies and scripts\\n├── tsconfig.json           # TypeScript configuration\\n└── README.md              # This file\\n```\\n\\n### Key Features\\n\\n- **Session Management**: Supports multiple concurrent MCP sessions with proper cleanup\\n- **Resumability**: Built-in event store for connection resumption\\n- **Code - OSS Integration**: Uses Code - OSS\\'s existing Playwright test infrastructure\\n- **CORS Support**: Configured for cross-origin requests\\n- **Error Handling**: Comprehensive error handling and logging\\n\\n## Troubleshooting\\n\\n### Server Won\\'t Start\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Verify all dependencies are installed with `npm install`\\n\\n### Browser Automation Issues\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Check the server logs for Playwright-related errors\\n- Verify the test repository is properly cloned\\n\\n## Contributing\\n\\nThis MCP server is part of the Code - OSS development infrastructure. When making changes:\\n\\n1. Follow the existing TypeScript and coding conventions\\n2. Test with multiple MCP clients if possible\\n3. Update this README if adding new capabilities\\n4. Ensure proper error handling and logging\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the top-level project\\'s license file for details.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/integration/browser/README.md', 'node_id': 3740947}, 'preview': '# Integration test\\n\\n## Compile\\n\\nMake sure to run the following commands to compile and install dependencies:\\n\\n    cd test/integration/browser\\n    npm i\\n    npm run compile\\n\\n## Run (inside Electron)\\n\\n    scripts/test-integration.[sh|bat]\\n\\nAll integration tests run in an Electron instance. You can specify to run the tests against a real build by setting the environment variables `INTEGRATION_TEST_ELECTRON_PATH` and `VSCODE_REMOTE_SERVER_PATH` (if you want to include remote tests).\\n\\n## Run (inside browser)\\n\\n    scripts/test-web-integration.[sh|bat] --browser [chromium|webkit] [--debug]\\n\\nAll integration tests run in a browser instance as specified by the command line arguments.\\n\\nAdd the `--debug` flag to see a browser window with the tests running.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>)\\n\\n## Debug\\n\\nAll integration tests can be run and debugged from within VSCode (both Electron and Web) simply by selecting the related launch configuration and running them.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/automation/README.md', 'node_id': 3741239}, 'preview': '# VS Code Automation Package\\n\\nThis package contains functionality for automating various components of the VS Code UI, via an automation \"driver\" that connects from a separate process. It is used by the `smoke` tests.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vscode-dts/README.md', 'node_id': 3744265}, 'preview': \"# vscode-dts\\n\\nThis is the place for the stable API and for API proposals.\\n\\n## Consume a proposal\\n\\n1. find a proposal you are interested in\\n1. add its name to your extensions `package.json#enabledApiProposals` property\\n1. run `npx vscode-dts dev` to download the `d.ts` files into your project\\n1. don't forget that extension using proposed API cannot be published\\n1. learn more here: <https://code.visualstudio.com/api/advanced-topics/using-proposed-api>\\n\\n## Add a new proposal\\n\\n1. create a _new_ file in this directory, its name must follow this pattern `vscode.proposed.[a-zA-Z]+.d.ts`\\n1. creating the proposal-file will automatically update `src/vs/platform/extensions/common/extensionsApiProposals.ts` (make sure to run `npm run watch`)\\n1. declare and implement your proposal\\n1. make sure to use the `checkProposedApiEnabled` and/or `isProposedApiEnabled`-utils to enforce the API being proposed. Make sure to invoke them with your proposal's name which got generated into `extensionsApiProposals.ts`\\n1. Most likely will need to add your proposed api to vscode-api-tests as well\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/workbench/contrib/terminalContrib/README.md', 'node_id': 3897567}, 'preview': \"_Terminal contribs_ are a way of splitting out standalone terminal features into their own components that build upon the main terminal code. The `terminalContrib/` folder can only import from `terminal/`, not the other way around. There are eslint rules to prevent this circular dependencies.\\n\\nHaving the entire feature and its tests in the same place makes not only the contrib easier to maintain and understand, but also the core terminal code as it's less interspersed with feature code. Sometimes it's not possible without bigger changes to make the feature totally standalone, in this case the goal is to get as close as possible.\\n\\nThis should not be confused with the similar `ITerminalContribution` which is a parallel to `IEditorContribution` and is used for decorating each individual terminal with additional functionality. An entry in `terminalContrib/` may use `ITerminalContribution`s to add its features.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/editor/test/node/diffing/README.md', 'node_id': 4481497}, 'preview': '# Diffing Fixture Tests\\n\\nEvery folder in `fixtures` represents a test.\\nThe file that starts with `1.` is diffed against the file that starts with `2.`. Use `tst` instead of `ts` to avoid compiler/linter errors for typescript diff files.\\n\\n* Missing `*.expected.diff.json` are created automatically (as well as an `*.invalid.diff.json` file).\\n* If the actual diff does not equal the expected diff, the expected file is updated automatically. The previous value of the expected file is written to `*.invalid.diff.json`.\\n* The test will fail if there are any `*.invalid.diff.json` files. This makes sure that the test keeps failing even if it is run a second time.\\n\\nWhen changing the diffing algorithm, run the fixture tests, review the diff of the `*.expected.diff.json` files and delete all `*.invalid.diff.json` files.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/README.md', 'node_id': 4707968}, 'preview': '# Language Features for TypeScript and JavaScript files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [TypeScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/typescript) and [JavaScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/javascript) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/web/README.md', 'node_id': 4707977}, 'preview': '# vscode-wasm-typescript\\n\\nLanguage server host for typescript using vscode\\'s sync-api in the browser.\\n\\n## Getting up and running\\n\\nTo test this out, you\\'ll need three shells:\\n\\n1. `npm i` for vscode itself\\n2. `npm run watch-web` for the web side\\n3. `node <root>/scripts/code-web.js --coi`\\n\\nThe last command will open a browser window. You\\'ll want to add `?vscode-coi=`\\nto the end. This is for enabling shared array buffers. So, for example:\\n`http://localhost:8080/?vscode-coi=`.\\n\\n### Working on type acquisition\\n\\nIn order to work with web\\'s new type acquisition, you\\'ll need to enable\\n`TypeScript > Experimental > Tsserver > Web: Enable Project Wide Intellisense`\\nin your VS Code options (`Ctrl-,`), you may need to reload the page.\\n\\nThis happens when working in a regular `.js` file on a dependency without\\ndeclared types. You should be able to open `file.js` and write something like\\n`import lodash from \\'lodash\\';` at the top of the file and, after a moment, get\\ntypes and other intellisense features (like Go To Def/Source Def) working as\\nexpected. This scenario works off Tsserver\\'s own Automatic Type Acquisition\\ncapabilities, and simulates a \"global\" types cache stored at\\n`/vscode-global-typings/ts-nul-authority/project`, which is backed by an\\nin-memory `MemFs` `FileSystemProvider`.\\n\\n### Simulated `node_modules`\\n\\nFor regular `.ts` files, instead of going through Tsserver\\'s type acquisition,\\na separate `AutoInstallerFs` is used to create a \"virtual\" `node_modules` that\\nextracts desired packages on demand, to an underlying `MemFs`. This will\\nhappen any time a filesystem operation is done inside a `node_modules` folder\\nacross any project in the workspace, and will use the \"real\" `package.json`\\n(and, if present, `package-lock.json`) to resolve the dependency tree.\\n\\nA fallback is then set up such that when a URI like\\n`memfs:/path/to/node_modules/lodash/lodash.d.ts` is accessed, that gets\\nredirected to\\n`vscode-node-modules:/ts-nul-authority/memfs/ts-nul-authority/path/to/node_modules/lodash/lodash.d.ts`,\\nwhich will be sent to the `AutoInstallerFs`.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/theme-seti/README.md', 'node_id': 4725047}, 'preview': '# theme-seti\\n\\nThis is an icon theme that uses the icons from [`seti-ui`](https://github.com/jesseweed/seti-ui).\\n\\n## Updating icons\\n\\nThere is script that can be used to update icons, [./build/update-icon-theme.js](build/update-icon-theme.js).\\n\\nTo run this script, run `npm run update` from the `theme-seti` directory.\\n\\nThis can be run in one of two ways: looking at a local copy of `seti-ui` for icons, or getting them straight from GitHub.\\n\\nIf you want to run it from a local copy of `seti-ui`, first clone [`seti-ui`](https://github.com/jesseweed/seti-ui) to the folder next to your `vscode` repo (from the `theme-seti` directory, `../../`).\\nThen, inside the `set-ui` directory, run `npm install` followed by `npm run prepublishOnly`. This will generate updated icons.\\n\\nIf you want to download the icons straight from GitHub, change the `FROM_DISK` variable to `false` inside of `update-icon-theme.js`.\\n\\n### Languages not shipped with `vscode`\\n\\nLanguages that are not shipped with `vscode` must be added to the `nonBuiltInLanguages` object inside of `update-icon-theme.js`.\\n\\nThese should match [the file mapping in `seti-ui`](https://github.com/jesseweed/seti-ui/blob/master/styles/components/icons/mapping.less).\\n\\nPlease try and keep this list in alphabetical order! Thank you.\\n\\n## Previewing icons\\n\\nThere is a [`./icons/preview.html`](./icons/preview.html) file that can be opened to see all of the icons included in the theme.\\nNote that to view this, it needs to be hosted by a web server.\\n\\nWhen updating icons, it is always a good idea to make sure that they work properly by looking at this page.\\nWhen submitting a PR that updates these icons, a screenshot of the preview page should accompany it.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/README.md', 'node_id': 4725296}, 'preview': '# Terminal Suggestions\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled. To enable the completions from this extension, set `terminal.integrated.suggest.enabled` to `true`.\\n\\n## Features\\n\\nProvides terminal suggestions for zsh, bash, fish, and pwsh.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/src/fig/README.md', 'node_id': 4728058}, 'preview': \"This folder contains the `autocomplete-parser` project from https://github.com/aws/amazon-q-developer-cli/blob/main/packages/autocomplete-parser and its dependencies which were located in siblings folders and https://github.com/withfig/autocomplete-tools, both licenses under MIT. The fork was necessary for a few reasons:\\n\\n- They ship as ESM modules which we're not ready to consume just yet.\\n- We want the more complete `autocomplete-parser` that contains the important `parseArguments` function that does the bulk of the smarts in parsing the fig commands.\\n- We needed to strip out all the implementation-specific parts from their `api-bindings` project that deals with settings, IPC, fuzzy sorting, etc.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/simple-browser/README.md', 'node_id': 4735296}, 'preview': '# Simple Browser\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nProvides a very basic browser preview using an iframe embedded in a [webviewW](). This extension is primarily meant to be used by other extensions for showing simple web content.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/search-result/README.md', 'node_id': 4735682}, 'preview': '# Language Features for Search Result files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nThis extension provides Syntax Highlighting, Symbol Information, Result Highlighting, and Go to Definition capabilities for the Search Results Editor.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/references-view/README.md', 'node_id': 4735988}, 'preview': \"# References View\\n\\nThis extension shows reference search results as separate view, just like search results. It complements the peek view presentation that is also built into VS Code. The following features are available:\\n\\n- List All References via the Command Palette, the Context Menu, or via <kbd>Alt+Shift+F12</kbd>\\n- View references in a dedicated tree view that sits in the sidebar\\n- Navigate through search results via <kbd>F4</kbd> and <kbd>Shift+F4</kbd>\\n- Remove references from the list via inline commands\\n\\n![](https://raw.githubusercontent.com/microsoft/vscode-references-view/master/media/demo.png)\\n\\n**Note** that this extension is bundled with Visual Studio Code version 1.29 and later - it doesn't need to be installed anymore.\\n\\n## Requirements\\n\\nThis extension is just an alternative UI for reference search and extensions implementing reference search must still be installed.\\n\\n## Issues\\n\\nThis extension ships with Visual Studio Code and uses its issue tracker. Please file issue here: https://github.com/Microsoft/vscode/issues\\n\\n# Contributing\\n\\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\\n\\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/php-language-features/README.md', 'node_id': 4737042}, 'preview': '# Language Features for PHP files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [PHP in Visual Studio Code](https://code.visualstudio.com/docs/languages/php) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/npm/README.md', 'node_id': 4737797}, 'preview': \"# Node npm\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\n### Task Running\\n\\nThis extension supports running npm scripts defined in the `package.json` as [tasks](https://code.visualstudio.com/docs/editor/tasks). Scripts with the name 'build', 'compile', or 'watch'\\nare treated as build tasks.\\n\\nTo run scripts as tasks, use the **Tasks** menu.\\n\\nFor more information about auto detection of Tasks, see the [documentation](https://code.visualstudio.com/Docs/editor/tasks#_task-autodetection).\\n\\n### Script Explorer\\n\\nThe Npm Script Explorer shows the npm scripts found in your workspace. The explorer view is enabled by the setting `npm.enableScriptExplorer`. A script can be opened, run, or debug from the explorer.\\n\\n### Run Scripts from the Editor\\n\\nThe extension supports to run the selected script as a task when editing the `package.json`file. You can either run a script from\\nthe hover shown on a script or using the command `Run Selected Npm Script`.\\n\\n### Run Scripts from a Folder in the Explorer\\n\\nThe extension supports running a script as a task from a folder in the Explorer. The command  `Run NPM Script in Folder...` shown in the Explorer context menu finds all scripts in `package.json` files that are contained in this folder. You can then select the script to be executed as a task from the resulting list. You enable this support with the `npm.runScriptFromFolder` which is `false` by default.\\n\\n### Others\\n\\nThe extension fetches data from <https://registry.npmjs.org> and <https://registry.bower.io> to provide auto-completion and information on hover features on npm dependencies.\\n\\n## Settings\\n\\n- `npm.autoDetect` - Enable detecting scripts as tasks, the default is `on`.\\n- `npm.runSilent` - Run npm script with the `--silent` option, the default is `false`.\\n- `npm.packageManager` - The package manager used to install dependencies: `auto`, `npm`, `yarn`, `pnpm` or `bun`. The default is `auto`, which detects your package manager based on files in your workspace.\\n- `npm.scriptRunner` - The script runner used to run the scripts: `auto`, `npm`, `yarn`, `pnpm`, `bun` or `node`. The default is `auto`, which detects your script runner based on files in your workspace.\\n- `npm.exclude` - Glob patterns for folders that should be excluded from automatic script detection. The pattern is matched against the **absolute path** of the package.json. For example, to exclude all test folders use '&ast;&ast;/test/&ast;&ast;'.\\n- `npm.enableScriptExplorer` - Enable an explorer view for npm scripts.\\n- `npm.scriptExplorerAction` - The default click action: `open` or `run`, the default is `open`.\\n- `npm.enableRunFromFolder` - Enable running npm scripts from the context menu of folders in Explorer, the default is `false`.\\n- `npm.scriptCodeLens.enable` - Enable/disable the code lenses to run a script, the default is `false`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/notebook-renderers/README.md', 'node_id': 4739483}, 'preview': '# Builtin Notebook Output Renderers for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following notebook renderers for VS Code:\\n\\n- Image renderer for png, jpeg and gif'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/microsoft-authentication/README.md', 'node_id': 4740838}, 'preview': '# Microsoft Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to Microsoft. It registers the `microsoft` Authentication Provider that can be leveraged by other extensions. This also provides the Microsoft authentication used by Settings Sync.\\n\\nAdditionally, it provides the `microsoft-sovereign-cloud` Authentication Provider that can be used to sign in to other Azure clouds like Azure for US Government or Azure China. Use the setting `microsoft-sovereign-cloud.endpoint` to select the authentication endpoint the provider should use. Please note that different scopes may also be required in different environments.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/mermaid-chat-features/README.md', 'node_id': 4743452}, 'preview': '# Mermaid Chat Features\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds basic [Mermaid.js](https://mermaid.js.org) diagram rendering to build-in chat.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/merge-conflict/README.md', 'node_id': 4743675}, 'preview': '# Merge Conflict\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Merge Conflicts in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_merge-conflicts) to learn about features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/media-preview/README.md', 'node_id': 4744324}, 'preview': '# Media Preview\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides basic preview for images, audio and video files.\\n\\n### Supported image file extensions\\n\\n- `.jpg`, `.jpe`, `.jpeg`\\n- `.png`\\n- `.bmp`\\n- `.gif`\\n- `.ico`\\n- `.webp`\\n- `.avif`\\n\\n### Supported audio formats\\n\\n- `.mp3`\\n- `.wav`\\n- `.ogg`, `.oga`\\n\\n### Supported video formats\\n\\n- `.mp4` (does not support `aac` audio tracks)\\n- `.webm` (vp8 only)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-math/README.md', 'node_id': 4745044}, 'preview': \"# Markdown Math\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds math rendering using [KaTeX](https://katex.org) to VS Code's built-in markdown preview and markdown cells in notebooks.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-language-features/README.md', 'node_id': 4745172}, 'preview': '# Language Features for Markdown files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Markdown in Visual Studio Code](https://code.visualstudio.com/docs/languages/markdown) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/README.md', 'node_id': 4751670}, 'preview': '# Language Features for JSON files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [JSON in Visual Studio Code](https://code.visualstudio.com/docs/languages/json) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/server/README.md', 'node_id': 4751677}, 'preview': '# VSCode JSON Language Server\\n\\n[![NPM Version](https://img.shields.io/npm/v/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Version](https://img.shields.io/npm/l/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n\\nThe JSON Language server provides language-specific smarts for editing, validating and understanding JSON documents. It runs as a separate executable and implements the [language server protocol](https://microsoft.github.io/language-server-protocol/overview) to be connected by any code editor or IDE.\\n\\n## Capabilities\\n\\n### Server capabilities\\n\\nThe JSON language server supports requests on documents of language id `json` and `jsonc`.\\n\\n- `json` documents are parsed and validated following the [JSON specification](https://tools.ietf.org/html/rfc7159).\\n- `jsonc` documents additionally accept single line (`//`) and multi-line comments (`/* ... */`). JSONC is a VSCode specific file format, intended for VSCode configuration files, without any aspirations to define a new common file format.\\n\\nThe server implements the following capabilities of the language server protocol:\\n\\n- [Code completion](https://microsoft.github.io/language-server-protocol/specification#textDocument_completion) for JSON properties and values based on the document\\'s [JSON schema](http://json-schema.org/) or based on existing properties and values used at other places in the document. JSON schemas are configured through the server configuration options.\\n- [Hover](https://microsoft.github.io/language-server-protocol/specification#textDocument_hover) for values based on descriptions in the document\\'s [JSON schema](http://json-schema.org/).\\n- [Document Symbols](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentSymbol) for quick navigation to properties in the document.\\n- [Document Colors](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentColor) for showing color decorators on values representing colors and [Color Presentation](https://microsoft.github.io/language-server-protocol/specification#textDocument_colorPresentation) for color presentation information to support color pickers. The location of colors is defined by the document\\'s [JSON schema](http://json-schema.org/). All values marked with `\"format\": \"color-hex\"` (VSCode specific, non-standard JSON Schema extension) are considered color values. The supported color formats are `#rgb[a]` and `#rrggbb[aa]`.\\n- [Code Formatting](https://microsoft.github.io/language-server-protocol/specification#textDocument_rangeFormatting) supporting ranges and formatting the whole document.\\n- [Folding Ranges](https://microsoft.github.io/language-server-protocol/specification#textDocument_foldingRange) for all folding ranges in the document.\\n- Semantic Selection for semantic selection for one or multiple cursor positions.\\n- [Goto Definition](https://microsoft.github.io/language-server-protocol/specification#textDocument_definition) for $ref references in JSON schemas\\n- [Diagnostics (Validation)](https://microsoft.github.io/language-server-protocol/specification#textDocument_publishDiagnostics) are pushed for all open documents\\n  - syntax errors\\n  - structural validation based on the document\\'s [JSON schema](http://json-schema.org/).\\n\\nIn order to load JSON schemas, the JSON server uses NodeJS `http` and `fs` modules. For all other features, the JSON server only relies on the documents and settings provided by the client through the LSP.\\n\\n### Client requirements\\n\\nThe JSON language server expects the client to only send requests and notifications for documents of language id `json` and `jsonc`.\\n\\nThe JSON language server has the following dependencies on the client\\'s capabilities:\\n\\n- Code completion requires that the client capability has *snippetSupport*. If not supported by the client, the server will not offer the completion capability.\\n- Formatting support requires the client to support *dynamicRegistration* for *rangeFormatting*. If not supported by the client, the server will not offer the format capability.\\n\\n## Configuration\\n\\n### Initialization options\\n\\nThe client can send the following initialization options to the server:\\n\\n- `provideFormatter: boolean | undefined`. If defined, the value defines whether the server provides the `documentRangeFormattingProvider` capability on initialization. If undefined, the setting `json.format.enable` is used to determine whether formatting is provided. The formatter will then be registered through dynamic registration. If the client does not support dynamic registration, no formatter will be available.\\n- `handledSchemaProtocols`: The URI schemas handles by the server. See section `Schema configuration` below.\\n- `customCapabilities`: Additional non-LSP client capabilities:\\n  - `rangeFormatting: { editLimit: x } }`: For performance reasons, limit the number of edits returned by the range formatter to `x`.\\n\\n### Settings\\n\\nClients may send a `workspace/didChangeConfiguration` notification to notify the server of settings changes.\\nThe server supports the following settings:\\n\\n- http\\n  - `proxy`: The URL of the proxy server to use when fetching schema. When undefined or empty, no proxy is used.\\n  - `proxyStrictSSL`: Whether the proxy server certificate should be verified against the list of supplied CAs.\\n\\n- json\\n  - `format`\\n    - `enable`: Whether the server should register the formatting support. This option is only applicable if the client supports *dynamicRegistration* for *rangeFormatting* and `initializationOptions.provideFormatter` is not defined.\\n  - `validate`\\n    - `enable`: Whether the server should validate. Defaults to `true` if not set.\\n  - `schemas`: Configures association of file names to schema URL or schemas and/or associations of schema URL to schema content.\\n    - `fileMatch`: an array of file names or paths (separated by `/`). `*` can be used as a wildcard. Exclusion patterns can also be defined and start with \\'!\\'. A file matches when there is at least one matching pattern and the last matching pattern is not an exclusion pattern.\\n    - `folderUri`: If provided, the association is only used if the document is located in the given folder (directly or in a subfolder)\\n    - `url`: The URL of the schema, optional when also a schema is provided.\\n    - `schema`: The schema content, optional\\n  - `resultLimit`: The max number of color decorators and outline symbols to be computed (for performance reasons)\\n  - `jsonFoldingLimit`: The max number of folding ranges to be computed for json documents (for performance reasons)\\n  - `jsoncFoldingLimit`: The max number of folding ranges to be computed for jsonc documents (for performance reasons)\\n\\n```json\\n    {\\n        \"http\": {\\n            \"proxy\": \"\",\\n            \"proxyStrictSSL\": true\\n        },\\n        \"json\": {\\n            \"format\": {\\n                \"enable\": true\\n            },\\n            \"schemas\": [\\n                {\\n                    \"fileMatch\": [\\n                        \"foo.json\",\\n                        \"*.superfoo.json\"\\n                    ],\\n                    \"url\": \"http://www.schemastore.org/foo\",\\n                    \"schema\": {\\n                        \"type\": \"array\"\\n                    }\\n                }\\n            ]\\n        }\\n    }\\n```\\n\\n### Schema configuration and custom schema content delivery\\n\\n[JSON schemas](http://json-schema.org/) are essential for code assist, hovers, color decorators to work and are required for structural validation.\\n\\nTo find the schema for a given JSON document, the server uses the following mechanisms:\\n\\n- JSON documents can define the schema URL using a `$schema` property\\n- The settings define a schema association based on the documents URL. Settings can either associate a schema URL to a file or path pattern, and they can directly provide a schema.\\n- Additionally, schema associations can also be provided by a custom \\'schemaAssociations\\' configuration call.\\n\\nSchemas are identified by URLs. To load the content of a schema, the JSON language server either tries to load from that URI or path itself or delegates to the client.\\n\\nThe `initializationOptions.handledSchemaProtocols` initialization option defines which URLs are handled by the server. Requests for all other URIs are sent to the client.\\n\\n`handledSchemaProtocols` is part of the initialization options and can\\'t be changed while the server is running.\\n\\n```ts\\nlet clientOptions: LanguageClientOptions = {\\n  initializationOptions: {\\n   handledSchemaProtocols: [\\'file\\'] // language server should only try to load file URLs\\n  }\\n        ...\\n}\\n```\\n\\nIf `handledSchemaProtocols` is not set, the JSON language server will load the following URLs itself:\\n\\n- `http`, `https`: Loaded using NodeJS\\'s HTTP support. Proxies can be configured through the settings.\\n- `file`: Loaded using NodeJS\\'s `fs` support.\\n\\n#### Schema content request\\n\\nRequests for schemas with URLs not handled by the server are forwarded to the client through an LSP request. This request is a JSON language server-specific, non-standardized, extension to the LSP.\\n\\nRequest:\\n\\n- method: \\'vscode/content\\'\\n- params: `string` - The schema URL to request.\\n- response: `string` - The content of the schema with the given URL\\n\\n#### Schema content change notification\\n\\nWhen the client is aware that a schema content has changed, it will notify the server through a notification. This notification is a JSON language server-specific, non-standardized, extension to the LSP.\\nThe server will, as a response, clear the schema content from the cache and reload the schema content when required again.\\n\\n#### Schema associations notification'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/jake/README.md', 'node_id': 4753671}, 'preview': \"# Jake - JavaScript build tool\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Jake](http://jakejs.com/) tasks defined in a `Jakefile.js` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Jake tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Jake tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `jake.autoDetect` - Enable detecting tasks from `Jakefile.js` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/ipynb/README.md', 'node_id': 4753950}, 'preview': '# Jupyter for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following Jupyter-related features for VS Code:\\n\\n- Open, edit and save .ipynb files'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/html-language-features/README.md', 'node_id': 4756255}, 'preview': '# Language Features for HTML\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [HTML in Visual Studio Code](https://code.visualstudio.com/docs/languages/html) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/html-language-features/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/gulp/README.md', 'node_id': 4762501}, 'preview': \"# Gulp - Automate and enhance your workflow\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Gulp](https://gulpjs.com/) tasks defined in a `gulpfile.{js,ts}` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Gulp tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Gulp tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `gulp.autoDetect` - Enable detecting tasks from `gulpfile.{js,ts}` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/grunt/README.md', 'node_id': 4762784}, 'preview': \"# Grunt - The JavaScript Task Runner\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Grunt](https://gruntjs.com/) tasks defined in a `gruntfile.js` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Grunt tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Grunt tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `grunt.autoDetect` - Enable detecting tasks from `gruntfile.js` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/github-authentication/README.md', 'node_id': 4763067}, 'preview': '# GitHub Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to GitHub. It registers the `github` Authentication Provider that can be leveraged by other extensions. This also provides the GitHub authentication used by Settings Sync.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/github/README.md', 'node_id': 4764868}, 'preview': '# GitHub for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following GitHub-related features for VS Code:\\n\\n- `Publish to GitHub` command\\n- `Clone from GitHub` participant to the `Git: Clone` command\\n- GitHub authentication for built-in git commands, controlled via the `github.gitAuthentication` command\\n- Automatic fork creation when attempting to push to a repository without permissions'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/git-base/README.md', 'node_id': 4766997}, 'preview': \"# Git static contributions and remote repository picker\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nGit static contributions and remote repository picker.\\n\\n## API\\n\\nThe Git extension exposes an API, reachable by any other extension.\\n\\n1. Copy `src/api/git-base.d.ts` to your extension's sources;\\n2. Include `git-base.d.ts` in your extension's compilation.\\n3. Get a hold of the API with the following snippet:\\n\\n ```ts\\n const gitBaseExtension = vscode.extensions.getExtension<GitBaseExtension>('vscode.git-base').exports;\\n const git = gitBaseExtension.getAPI(1);\\n\\n ```\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/git/README.md', 'node_id': 4767671}, 'preview': '# Git integration for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Git support in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_git-support) to learn about the features of this extension.\\n\\n## API\\n\\nThe Git extension exposes an API, reachable by any other extension.\\n\\n1. Copy `src/api/git.d.ts` to your extension\\'s sources;\\n2. Include `git.d.ts` in your extension\\'s compilation.\\n3. Get a hold of the API with the following snippet:\\n\\n\\t```ts\\n\\tconst gitExtension = vscode.extensions.getExtension<GitExtension>(\\'vscode.git\\').exports;\\n\\tconst git = gitExtension.getAPI(1);\\n\\t```\\n\\t**Note:** To ensure that the `vscode.git` extension is activated before your extension, add `extensionDependencies` ([docs](https://code.visualstudio.com/api/references/extension-manifest)) into the `package.json` of your extension:\\n\\t```json\\n\\t\"extensionDependencies\": [\\n\\t\\t\"vscode.git\"\\n\\t]\\n\\t```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/emmet/README.md', 'node_id': 4776208}, 'preview': '# Emmet integration in Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Emmet in Visual Studio Code](https://code.visualstudio.com/docs/editor/emmet) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/emmet/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/css-language-features/README.md', 'node_id': 4781506}, 'preview': '# Language Features for CSS, SCSS, and LESS files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [CSS, SCSS and Less in VS Code](https://code.visualstudio.com/docs/languages/css) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/css-language-features/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'build/monaco/README.md', 'node_id': 4803521}, 'preview': '# Steps to publish a new version of monaco-editor-core\\n\\n## Generate monaco.d.ts\\n\\n* The `monaco.d.ts` is now automatically generated when running `gulp watch`\\n\\n## Bump version\\n\\n* increase version in `build/monaco/package.json`\\n\\n## Generate npm contents for monaco-editor-core\\n\\n* Be sure to have all changes committed **and pushed to the remote**\\n* (the generated files contain the HEAD sha and that should be available on the remote)\\n* run gulp editor-distro\\n\\n## Publish\\n\\n* `cd out-monaco-editor-core`\\n* `npm publish`'}, {'FileNode': {'basename': 'README.md', 'relative_path': '.devcontainer/README.md', 'node_id': 4836320}, 'preview': '# Code - OSS Development Container\\n\\n[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode)\\n\\nThis repository includes configuration for a development container for working with Code - OSS in a local container or using [GitHub Codespaces](https://github.com/features/codespaces).\\n\\n> **Tip:** The default VNC password is `vscode`. The VNC server runs on port `5901` and a web client is available on port `6080`.\\n\\n## Quick start - local\\n\\nIf you already have VS Code and Docker installed, you can click the badge above or [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. Clicking these links will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n1. Install Docker Desktop or Docker for Linux on your local machine. (See [docs](https://aka.ms/vscode-remote/containers/getting-started) for additional details.)\\n\\n2. **Important**: Docker needs at least **4 Cores and 8 GB of RAM** to run a full build with **9 GB of RAM** being recommended. If you are on macOS, or are using the old Hyper-V engine for Windows, update these values for Docker Desktop by right-clicking on the Docker status bar item and going to **Preferences/Settings > Resources > Advanced**.\\n\\n   > **Note:** The [Resource Monitor](https://marketplace.visualstudio.com/items?itemName=mutantdino.resourcemonitor) extension is included in the container so you can keep an eye on CPU/Memory in the status bar.\\n\\n3. Install [Visual Studio Code Stable](https://code.visualstudio.com/) or [Insiders](https://code.visualstudio.com/insiders/) and the [Dev Containers](https://aka.ms/vscode-remote/download/containers) extension.\\n\\n   ![Image of Dev Containers extension](https://microsoft.github.io/vscode-remote-release/images/dev-containers-extn.png)\\n\\n   > **Note:** The Dev Containers extension requires the Visual Studio Code distribution of Code - OSS. See the [FAQ](https://aka.ms/vscode-remote/faq/license) for details.\\n\\n4. Press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd> and select **Dev Containers: Clone Repository in Container Volume...**.\\n\\n   > **Tip:** While you can use your local source tree instead, operations like `npm i` can be slow on macOS or when using the Hyper-V engine on Windows. We recommend using the WSL filesystem on Windows or the \"clone repository in container\" approach on Windows and macOS instead since it uses \"named volume\" rather than the local filesystem.\\n\\n5. Type `https://github.com/microsoft/vscode` (or a branch or PR URL) in the input box and press <kbd>Enter</kbd>.\\n\\n6. After the container is running:\\n    1. If you have the `DISPLAY` or `WAYLAND_DISPLAY` environment variables set locally (or in WSL on Windows), desktop apps in the container will be shown in local windows.\\n    2. If these are not set, open a web browser and go to [http://localhost:6080](http://localhost:6080), or use a [VNC Viewer][def] to connect to `localhost:5901` and enter `vscode` as the password. Anything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n## Quick start - GitHub Codespaces\\n\\n1. From the [microsoft/vscode GitHub repository](https://github.com/microsoft/vscode), click on the **Code** dropdown, select **Open with Codespaces**, and then click on **New codespace**. If prompted, select the **Standard** machine size (which is also the default).\\n\\n   > **Note:** You will not see these options within GitHub if you are not in the Codespaces beta.\\n\\n2. After the codespace is up and running in your browser, press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd> and select **Ports: Focus on Ports View**.\\n\\n3. You should see **VNC web client (6080)** under in the list of ports. Select the line and click on the globe icon to open it in a browser tab.\\n\\n    > **Tip:** If you do not see the port, <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd>, select **Forward a Port** and enter port `6080`.\\n\\n4. In the new tab, you should see noVNC. Click **Connect** and enter `vscode` as the password.\\n\\nAnything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n### Using VS Code with GitHub Codespaces\\n\\nYou may see improved VNC responsiveness when accessing a codespace from VS Code client since you can use a [VNC Viewer][def]. Here\\'s how to do it.\\n\\n1. Install [Visual Studio Code Stable](https://code.visualstudio.com/) or [Insiders](https://code.visualstudio.com/insiders/) and the [GitHub Codespaces extension](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces).\\n\\n    > **Note:** The GitHub Codespaces extension requires the Visual Studio Code distribution of Code - OSS.\\n\\n2. After the VS Code is up and running, press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd>, choose **Codespaces: Create New Codespace**, and use the following settings:\\n\\n- `microsoft/vscode` for the repository.\\n- Select any branch (e.g. **main**) - you can select a different one later.\\n- Choose **Standard** (4-core, 8GB) as the size.\\n\\n3. After you have connected to the codespace, you can use a [VNC Viewer][def] to connect to `localhost:5901` and enter `vscode` as the password.\\n\\n    > **Tip:** You may also need change your VNC client\\'s **Picture Quality** setting to **High** to get a full color desktop.\\n\\n4. Anything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n## Try it\\n\\nThis container uses the [Fluxbox](http://fluxbox.org/) window manager to keep things lean. **Right-click on the desktop** to see menu options. It works with GNOME and GTK applications, so other tools can be installed if needed.\\n\\n   > **Note:** You can also set the resolution from the command line by typing `set-resolution`.\\n\\nTo start working with Code - OSS, follow these steps:\\n\\n1. In your local VS Code client, open a terminal (<kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>\\\\`</kbd>) and type the following commands:\\n\\n   ```bash\\n   npm i\\n   bash scripts/code.sh\\n   ```\\n\\n2. After the build is complete, open a web browser or a [VNC Viewer][def] to connect to the desktop environment as described in the quick start and enter `vscode` as the password.\\n\\n3. You should now see Code - OSS!\\n\\nNext, let\\'s try debugging.\\n\\n1. Shut down Code - OSS by clicking the box in the upper right corner of the Code - OSS window through your browser or VNC viewer.\\n\\n2. Go to your local VS Code client, and use the **Run / Debug** view to launch the **VS Code** configuration. (Typically the default, so you can likely just press <kbd>F5</kbd>).\\n\\n   > **Note:** If launching times out, you can increase the value of `timeout` in the \"VS Code\", \"Attach Main Process\", \"Attach Extension Host\", and \"Attach to Shared Process\" configurations in [launch.json](../.vscode/launch.json). However, running `./scripts/code.sh` first will set up Electron which will usually solve timeout issues.\\n\\n3. After a bit, Code - OSS will appear with the debugger attached!\\n\\nEnjoy!\\n\\n### Notes\\n\\nThe container comes with VS Code Insiders installed. To run it from an Integrated Terminal use `VSCODE_IPC_HOOK_CLI= /usr/bin/code-insiders .`.\\n\\n[def]: https://www.realvnc.com/en/connect/download/viewer/'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_WdkaLWjds0dyrQs5L4kkPy5I', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'preview_file_content_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 37897, 'total_tokens': 37917, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 37760}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1020758b-4289-493a-bfe1-761a47ee1229-0' tool_calls=[{'name': 'preview_file_content_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_WdkaLWjds0dyrQs5L4kkPy5I', 'type': 'tool_call'}] usage_metadata={'input_tokens': 37897, 'output_tokens': 20, 'total_tokens': 37917, 'input_token_details': {'audio': 0, 'cache_read': 37760}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='Result 1:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'README.md\\', \\'node_id\\': 3734887}\\npreview: # Visual Studio Code - Open Source (\"Code - OSS\")\\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=✓&q=is%3Aissue+is%3Aopen+label%3Abug)\\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\\n\\n## The Repository\\n\\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\\n\\n## Visual Studio Code\\n\\n<p align=\"center\">\\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png\">\\n</p>\\n\\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\\n\\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\\n\\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code\\'s website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\\n\\n## Contributing\\n\\nThere are many ways in which you can participate in this project, for example:\\n\\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content\\n\\nIf you are interested in fixing issues and contributing directly to the code base,\\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\\n\\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\\n* [Contributing to translations](https://aka.ms/vscodeloc)\\n\\n## Feedback\\n\\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\\n* [Request a new feature](CONTRIBUTING.md)\\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n* [File an issue](https://github.com/microsoft/vscode/issues)\\n* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)\\n* Follow [@code](https://twitter.com/code) and let us know what you think!\\n\\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\\n\\n## Related Projects\\n\\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\\n\\n## Bundled Extensions\\n\\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.\\n\\n## Development Container\\n\\nThis repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.\\n\\n* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.\\n  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\\n\\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\\n\\n## Code of Conduct\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## License\\n\\nCopyright (c) Microsoft Corporation. All rights reserved.\\n\\nLicensed under the [MIT](LICENSE.txt) license.\\n\\n\\nResult 2:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/README.md\\', \\'node_id\\': 3734900}\\npreview: # VSCode Tests\\n\\n## Contents\\n\\nThis folder contains the various test runners for VSCode. Please refer to the documentation within for how to run them:\\n\\n* `unit`: our suite of unit tests ([README](unit/README.md))\\n* `integration`: our suite of API tests ([README](integration/browser/README.md))\\n* `smoke`: our suite of automated UI tests ([README](smoke/README.md))\\n\\n\\nResult 3:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/unit/README.md\\', \\'node_id\\': 3734908}\\npreview: # Unit Tests\\n\\n## Run (inside Electron)\\n\\n    ./scripts/test.[sh|bat]\\n\\nAll unit tests are run inside a Electron renderer environment which access to DOM and Nodejs api. This is the closest to the environment in which VS Code itself ships. Notes:\\n\\n- use the `--debug` to see an electron window with dev tools which allows for debugging\\n- to run only a subset of tests use the `--run` or `--glob` options\\n- use `npm run watch` to automatically compile changes\\n\\nFor instance, `./scripts/test.sh --debug --glob **/extHost*.test.js` runs all tests from `extHost`-files and enables you to debug them.\\n\\n## Run (inside browser)\\n\\n    npm run test-browser -- --browser webkit --browser chromium\\n\\nUnit tests from layers `common` and `browser` are run inside `chromium`, `webkit`, and (soon\\'ish) `firefox` (using playwright). This complements our electron-based unit test runner and adds more coverage of supported platforms. Notes:\\n\\n- these tests are part of the continuous build, that means you might have test failures that only happen with webkit on _windows_ or _chromium_ on linux\\n- you can run these tests locally via `npm run test-browser -- --browser chromium --browser webkit`\\n- to debug, open `<vscode>/test/unit/browser/renderer.html` inside a browser and use the `?m=<amd_module>`-query to specify what AMD module to load, e.g `file:///Users/jrieken/Code/vscode/test/unit/browser/renderer.html?m=vs/base/test/common/strings.test` runs all tests from `strings.test.ts`\\n- to run only a subset of tests use the `--run` or `--glob` options\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (https://playwright.dev/docs/debug#verbose-api-logs)\\n\\n## Run (with node)\\n\\n    npm run test-node -- --run src/vs/editor/test/browser/controller/cursor.test.ts\\n\\n## Coverage\\n\\nThe following command will create a `coverage` folder in the `.build` folder at the root of the workspace:\\n\\n### OS X and Linux\\n\\n    ./scripts/test.sh --coverage\\n\\n### Windows\\n\\n    scripts\\\\test --coverage\\n\\n\\nResult 4:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/smoke/README.md\\', \\'node_id\\': 3736755}\\npreview: # VS Code Smoke Test\\n\\nMake sure you are on **Node v12.x**.\\n\\n## Quick Overview\\n\\n```bash\\n# Build extensions in the VS Code repo (if needed)\\nnpm i && npm run compile\\n\\n# Dev (Electron)\\nnpm run smoketest\\n\\n# Dev (Web - Must be run on distro)\\nnpm run smoketest -- --web --browser [chromium|webkit]\\n\\n# Build (Electron)\\nnpm run smoketest -- --build <path to latest version>\\nexample: npm run smoketest -- --build /Applications/Visual\\\\ Studio\\\\ Code\\\\ -\\\\ Insiders.app\\n\\n# Build (Web - read instructions below)\\nnpm run smoketest -- --build <path to server web build (ends in -web)> --web --browser [chromium|webkit]\\n\\n# Remote (Electron)\\nnpm run smoketest -- --build <path to latest version> --remote\\n```\\n\\n\\\\* This step is necessary only when running without `--build` and OSS doesn\\'t already exist in the `.build/electron` directory.\\n\\n### Running for a release (Endgame)\\n\\nYou must always run the smoketest version that matches the release you are testing. So, if you want to run the smoketest for a release build (e.g. `release/1.22`), you need to check out that version of the smoke tests too:\\n\\n```bash\\ngit fetch\\ngit checkout release/1.22\\nnpm i && npm run compile\\ncd test/smoke\\nnpm i\\n```\\n\\n#### Web\\n\\nThere is no support for testing an old version to a new one yet.\\nInstead, simply configure the `--build` command line argument to point to the absolute path of the extracted server web build folder (e.g. `<rest of path here>/vscode-server-darwin-x64-web` for macOS). The server web build is available from the builds page (see previous subsection).\\n\\n**macOS**: if you have downloaded the server with web bits, make sure to run the following command before unzipping it to avoid security issues on startup:\\n\\n```bash\\nxattr -d com.apple.quarantine <path to server with web folder zip>\\n```\\n\\n**Note**: make sure to point to the server that includes the client bits!\\n\\n### Debug\\n\\n- `--verbose` logs all the low level driver calls made to Code;\\n- `-f PATTERN` (alias `-g PATTERN`) filters the tests to be run. You can also use pretty much any mocha argument;\\n- `--headless` will run playwright in headless mode when `--web` is used.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>), for example to `pw:browser`.\\n\\n### Develop\\n\\n```bash\\ncd test/smoke\\nnpm run watch\\n```\\n\\n## Troubleshooting\\n\\n### Error: Could not get a unique tmp filename, max tries reached\\n\\nOn Windows, check for the folder `C:\\\\Users\\\\<username>\\\\AppData\\\\Local\\\\Temp\\\\t`. If this folder exists, the `tmp` module can\\'t run properly, resulting in the error above. In this case, delete the `t` folder.\\n\\n## Pitfalls\\n\\n- Beware of workbench **state**. The tests within a single suite will share the same state.\\n\\n- Beware of **singletons**. This evil can, and will, manifest itself under the form of FS paths, TCP ports, IPC handles. Whenever writing a test, or setting up more smoke test architecture, make sure it can run simultaneously with any other tests and even itself. All test suites should be able to run many times in parallel.\\n\\n- Beware of **focus**. **Never** depend on DOM elements having focus using `.focused` classes or `:focus` pseudo-classes, since they will lose that state as soon as another window appears on top of the running VS Code window. A safe approach which avoids this problem is to use the `waitForActiveElement` API. Many tests use this whenever they need to wait for a specific element to _have focus_.\\n\\n- Beware of **timing**. You need to read from or write to the DOM... but is it the right time to do that? Can you 100% guarantee that `input` box will be visible at that point in time? Or are you just hoping that it will be so? Hope is your worst enemy in UI tests. Example: just because you triggered Quick Access with `F1`, it doesn\\'t mean that it\\'s open and you can just start typing; you must first wait for the input element to be in the DOM as well as be the current active element.\\n\\n- Beware of **waiting**. **Never** wait longer than a couple of seconds for anything, unless it\\'s justified. Think of it as a human using Code. Would a human take 10 minutes to run through the Search viewlet smoke test? Then, the computer should even be faster. **Don\\'t** use `setTimeout` just because. Think about what you should wait for in the DOM to be ready and wait for that instead.\\n\\n\\nResult 5:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/monaco/README.md\\', \\'node_id\\': 3738548}\\npreview: # Monaco Editor Test\\n\\nThis directory contains scripts that are used to smoke test the Monaco Editor distribution.\\n\\n## Setup & Bundle\\n\\n $test/monaco> npm i\\n $test/monaco> npm run bundle\\n\\n## Compile and run tests\\n\\n $test/monaco> npm run compile\\n $test/monaco> npm run test\\n\\n\\nResult 6:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/mcp/README.md\\', \\'node_id\\': 3738926}\\npreview: # Code - OSS Development MCP Server\\n\\nThis directory contains a Model Context Protocol (MCP) server that provides Playwright browser automation capabilities for Code - OSS development and testing. The MCP server exposes Code - OSS\\'s Playwright testing infrastructure through a standardized interface, allowing AI assistants and other tools to interact with browsers programmatically.\\n\\n## What is MCP?\\n\\nThe [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that enables AI assistants to securely connect to external data sources and tools. This MCP server specifically provides browser automation capabilities using Playwright, making it possible for AI assistants to:\\n\\n- Navigate web pages\\n- Interact with UI elements (click, type, hover, etc.)\\n- Take screenshots and capture page content\\n- Evaluate JavaScript in browser contexts\\n- Handle file uploads and downloads\\n- Manage browser tabs and windows\\n\\n## Quick Start - Stdio\\n\\nFirstly, make sure you install all dependencies (`npm i`) at the root of the repo.\\n\\nThen, open the Command Palette and run:\\n```\\nMCP: List Servers → vscode-playwright-mcp → Start Server\\n```\\nor open [mcp.json](../../.vscode/mcp.json) and start it from there.\\n\\nThat\\'s it! It should automatically compile everything needed.\\n\\nThen you can use `/playwright` to ask specific questions.\\n\\n## Arguments\\n\\nOpen the [mcp.json](../../.vscode/mcp.json) and modify the `args`:\\n\\n* `[\"run\", \"start-stdio\"]`: opens Electron window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\"]`: opens a Chromium window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\", \"--headless\"]`: opens a headless window\\n\\n> *NOTE: `--web` requires running `npm run install-playwright` from root*\\n\\n## Debugging the server\\n\\nYou can modify the mcp.json to debug the server:\\n```JSON\\n\"vscode-playwright-mcp\": {\\n\\t\"type\": \"stdio\",\\n\\t\"command\": \"node\",\\n\\t\"args\": [\"./out/stdio.js\"],\\n\\t\"cwd\": \"${workspaceFolder}/test/mcp\",\\n\\t\"dev\": {\\n\\t\\t\"watch\": \"test/mcp/**/*.ts\",\\n\\t\\t\"debug\": {\\n\\t\\t\\t\"type\": \"node\"\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\n## What the Server Provides\\n\\nThe MCP server exposes a comprehensive set of browser automation tools through the MCP protocol:\\n\\n### Element Interaction\\n- Click on elements (single, double, right-click)\\n- Type text into input fields\\n- Hover over elements\\n- Drag and drop between elements\\n- Select options in dropdowns\\n\\n### Content Capture & Analysis\\n- Take screenshots (full page or specific elements)\\n- Capture accessibility snapshots for better element targeting\\n- Get page console messages\\n- Monitor network requests\\n\\n### Advanced Features\\n- Evaluate JavaScript code in browser contexts\\n- Handle file uploads\\n- Wait for specific content or time delays\\n- Handle browser dialogs and alerts\\n\\n## Development\\n\\n### Manual Setup (Advanced)\\n\\nIf you prefer to run the server manually:\\n\\n```bash\\n# Navigate to the MCP directory\\ncd test/mcp\\n\\n# Install dependencies\\nnpm install\\n\\n# Compile TypeScript\\nnpm run compile # or watch\\n\\n# Start the server\\nnpm start\\n```\\n\\n### Project Structure\\n\\n```\\ntest/mcp/\\n├── src/\\n│   ├── main.ts              # Express server and MCP endpoint handlers\\n│   ├── playwright.ts        # Code - OSS Playwright integration\\n│   ├── inMemoryEventStore.ts # Session management for resumability\\n│   └── utils.ts             # Utility functions\\n├── package.json             # Dependencies and scripts\\n├── tsconfig.json           # TypeScript configuration\\n└── README.md              # This file\\n```\\n\\n### Key Features\\n\\n- **Session Management**: Supports multiple concurrent MCP sessions with proper cleanup\\n- **Resumability**: Built-in event store for connection resumption\\n- **Code - OSS Integration**: Uses Code - OSS\\'s existing Playwright test infrastructure\\n- **CORS Support**: Configured for cross-origin requests\\n- **Error Handling**: Comprehensive error handling and logging\\n\\n## Troubleshooting\\n\\n### Server Won\\'t Start\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Verify all dependencies are installed with `npm install`\\n\\n### Browser Automation Issues\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Check the server logs for Playwright-related errors\\n- Verify the test repository is properly cloned\\n\\n## Contributing\\n\\nThis MCP server is part of the Code - OSS development infrastructure. When making changes:\\n\\n1. Follow the existing TypeScript and coding conventions\\n2. Test with multiple MCP clients if possible\\n3. Update this README if adding new capabilities\\n4. Ensure proper error handling and logging\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the top-level project\\'s license file for details.\\n\\n\\nResult 7:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/integration/browser/README.md\\', \\'node_id\\': 3740947}\\npreview: # Integration test\\n\\n## Compile\\n\\nMake sure to run the following commands to compile and install dependencies:\\n\\n    cd test/integration/browser\\n    npm i\\n    npm run compile\\n\\n## Run (inside Electron)\\n\\n    scripts/test-integration.[sh|bat]\\n\\nAll integration tests run in an Electron instance. You can specify to run the tests against a real build by setting the environment variables `INTEGRATION_TEST_ELECTRON_PATH` and `VSCODE_REMOTE_SERVER_PATH` (if you want to include remote tests).\\n\\n## Run (inside browser)\\n\\n    scripts/test-web-integration.[sh|bat] --browser [chromium|webkit] [--debug]\\n\\nAll integration tests run in a browser instance as specified by the command line arguments.\\n\\nAdd the `--debug` flag to see a browser window with the tests running.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>)\\n\\n## Debug\\n\\nAll integration tests can be run and debugged from within VSCode (both Electron and Web) simply by selecting the related launch configuration and running them.\\n\\n\\nResult 8:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'test/automation/README.md\\', \\'node_id\\': 3741239}\\npreview: # VS Code Automation Package\\n\\nThis package contains functionality for automating various components of the VS Code UI, via an automation \"driver\" that connects from a separate process. It is used by the `smoke` tests.\\n\\n\\nResult 9:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vscode-dts/README.md\\', \\'node_id\\': 3744265}\\npreview: # vscode-dts\\n\\nThis is the place for the stable API and for API proposals.\\n\\n## Consume a proposal\\n\\n1. find a proposal you are interested in\\n1. add its name to your extensions `package.json#enabledApiProposals` property\\n1. run `npx vscode-dts dev` to download the `d.ts` files into your project\\n1. don\\'t forget that extension using proposed API cannot be published\\n1. learn more here: <https://code.visualstudio.com/api/advanced-topics/using-proposed-api>\\n\\n## Add a new proposal\\n\\n1. create a _new_ file in this directory, its name must follow this pattern `vscode.proposed.[a-zA-Z]+.d.ts`\\n1. creating the proposal-file will automatically update `src/vs/platform/extensions/common/extensionsApiProposals.ts` (make sure to run `npm run watch`)\\n1. declare and implement your proposal\\n1. make sure to use the `checkProposedApiEnabled` and/or `isProposedApiEnabled`-utils to enforce the API being proposed. Make sure to invoke them with your proposal\\'s name which got generated into `extensionsApiProposals.ts`\\n1. Most likely will need to add your proposed api to vscode-api-tests as well\\n\\n\\nResult 10:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vs/workbench/contrib/terminalContrib/README.md\\', \\'node_id\\': 3897567}\\npreview: _Terminal contribs_ are a way of splitting out standalone terminal features into their own components that build upon the main terminal code. The `terminalContrib/` folder can only import from `terminal/`, not the other way around. There are eslint rules to prevent this circular dependencies.\\n\\nHaving the entire feature and its tests in the same place makes not only the contrib easier to maintain and understand, but also the core terminal code as it\\'s less interspersed with feature code. Sometimes it\\'s not possible without bigger changes to make the feature totally standalone, in this case the goal is to get as close as possible.\\n\\nThis should not be confused with the similar `ITerminalContribution` which is a parallel to `IEditorContribution` and is used for decorating each individual terminal with additional functionality. An entry in `terminalContrib/` may use `ITerminalContribution`s to add its features.\\n\\n\\nResult 11:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'src/vs/editor/test/node/diffing/README.md\\', \\'node_id\\': 4481497}\\npreview: # Diffing Fixture Tests\\n\\nEvery folder in `fixtures` represents a test.\\nThe file that starts with `1.` is diffed against the file that starts with `2.`. Use `tst` instead of `ts` to avoid compiler/linter errors for typescript diff files.\\n\\n* Missing `*.expected.diff.json` are created automatically (as well as an `*.invalid.diff.json` file).\\n* If the actual diff does not equal the expected diff, the expected file is updated automatically. The previous value of the expected file is written to `*.invalid.diff.json`.\\n* The test will fail if there are any `*.invalid.diff.json` files. This makes sure that the test keeps failing even if it is run a second time.\\n\\nWhen changing the diffing algorithm, run the fixture tests, review the diff of the `*.expected.diff.json` files and delete all `*.invalid.diff.json` files.\\n\\n\\nResult 12:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/typescript-language-features/README.md\\', \\'node_id\\': 4707968}\\npreview: # Language Features for TypeScript and JavaScript files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [TypeScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/typescript) and [JavaScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/javascript) to learn about the features of this extension.\\n\\n\\nResult 13:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/typescript-language-features/web/README.md\\', \\'node_id\\': 4707977}\\npreview: # vscode-wasm-typescript\\n\\nLanguage server host for typescript using vscode\\'s sync-api in the browser.\\n\\n## Getting up and running\\n\\nTo test this out, you\\'ll need three shells:\\n\\n1. `npm i` for vscode itself\\n2. `npm run watch-web` for the web side\\n3. `node <root>/scripts/code-web.js --coi`\\n\\nThe last command will open a browser window. You\\'ll want to add `?vscode-coi=`\\nto the end. This is for enabling shared array buffers. So, for example:\\n`http://localhost:8080/?vscode-coi=`.\\n\\n### Working on type acquisition\\n\\nIn order to work with web\\'s new type acquisition, you\\'ll need to enable\\n`TypeScript > Experimental > Tsserver > Web: Enable Project Wide Intellisense`\\nin your VS Code options (`Ctrl-,`), you may need to reload the page.\\n\\nThis happens when working in a regular `.js` file on a dependency without\\ndeclared types. You should be able to open `file.js` and write something like\\n`import lodash from \\'lodash\\';` at the top of the file and, after a moment, get\\ntypes and other intellisense features (like Go To Def/Source Def) working as\\nexpected. This scenario works off Tsserver\\'s own Automatic Type Acquisition\\ncapabilities, and simulates a \"global\" types cache stored at\\n`/vscode-global-typings/ts-nul-authority/project`, which is backed by an\\nin-memory `MemFs` `FileSystemProvider`.\\n\\n### Simulated `node_modules`\\n\\nFor regular `.ts` files, instead of going through Tsserver\\'s type acquisition,\\na separate `AutoInstallerFs` is used to create a \"virtual\" `node_modules` that\\nextracts desired packages on demand, to an underlying `MemFs`. This will\\nhappen any time a filesystem operation is done inside a `node_modules` folder\\nacross any project in the workspace, and will use the \"real\" `package.json`\\n(and, if present, `package-lock.json`) to resolve the dependency tree.\\n\\nA fallback is then set up such that when a URI like\\n`memfs:/path/to/node_modules/lodash/lodash.d.ts` is accessed, that gets\\nredirected to\\n`vscode-node-modules:/ts-nul-authority/memfs/ts-nul-authority/path/to/node_modules/lodash/lodash.d.ts`,\\nwhich will be sent to the `AutoInstallerFs`.\\n\\n\\nResult 14:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/theme-seti/README.md\\', \\'node_id\\': 4725047}\\npreview: # theme-seti\\n\\nThis is an icon theme that uses the icons from [`seti-ui`](https://github.com/jesseweed/seti-ui).\\n\\n## Updating icons\\n\\nThere is script that can be used to update icons, [./build/update-icon-theme.js](build/update-icon-theme.js).\\n\\nTo run this script, run `npm run update` from the `theme-seti` directory.\\n\\nThis can be run in one of two ways: looking at a local copy of `seti-ui` for icons, or getting them straight from GitHub.\\n\\nIf you want to run it from a local copy of `seti-ui`, first clone [`seti-ui`](https://github.com/jesseweed/seti-ui) to the folder next to your `vscode` repo (from the `theme-seti` directory, `../../`).\\nThen, inside the `set-ui` directory, run `npm install` followed by `npm run prepublishOnly`. This will generate updated icons.\\n\\nIf you want to download the icons straight from GitHub, change the `FROM_DISK` variable to `false` inside of `update-icon-theme.js`.\\n\\n### Languages not shipped with `vscode`\\n\\nLanguages that are not shipped with `vscode` must be added to the `nonBuiltInLanguages` object inside of `update-icon-theme.js`.\\n\\nThese should match [the file mapping in `seti-ui`](https://github.com/jesseweed/seti-ui/blob/master/styles/components/icons/mapping.less).\\n\\nPlease try and keep this list in alphabetical order! Thank you.\\n\\n## Previewing icons\\n\\nThere is a [`./icons/preview.html`](./icons/preview.html) file that can be opened to see all of the icons included in the theme.\\nNote that to view this, it needs to be hosted by a web server.\\n\\nWhen updating icons, it is always a good idea to make sure that they work properly by looking at this page.\\nWhen submitting a PR that updates these icons, a screenshot of the preview page should accompany it.\\n\\n\\nResult 15:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/terminal-suggest/README.md\\', \\'node_id\\': 4725296}\\npreview: # Terminal Suggestions\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled. To enable the completions from this extension, set `terminal.integrated.suggest.enabled` to `true`.\\n\\n## Features\\n\\nProvides terminal suggestions for zsh, bash, fish, and pwsh.\\n\\n\\nResult 16:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/terminal-suggest/src/fig/README.md\\', \\'node_id\\': 4728058}\\npreview: This folder contains the `autocomplete-parser` project from https://github.com/aws/amazon-q-developer-cli/blob/main/packages/autocomplete-parser and its dependencies which were located in siblings folders and https://github.com/withfig/autocomplete-tools, both licenses under MIT. The fork was necessary for a few reasons:\\n\\n- They ship as ESM modules which we\\'re not ready to consume just yet.\\n- We want the more complete `autocomplete-parser` that contains the important `parseArguments` function that does the bulk of the smarts in parsing the fig commands.\\n- We needed to strip out all the implementation-specific parts from their `api-bindings` project that deals with settings, IPC, fuzzy sorting, etc.\\n\\n\\nResult 17:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/simple-browser/README.md\\', \\'node_id\\': 4735296}\\npreview: # Simple Browser\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nProvides a very basic browser preview using an iframe embedded in a [webviewW](). This extension is primarily meant to be used by other extensions for showing simple web content.\\n\\n\\nResult 18:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/search-result/README.md\\', \\'node_id\\': 4735682}\\npreview: # Language Features for Search Result files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nThis extension provides Syntax Highlighting, Symbol Information, Result Highlighting, and Go to Definition capabilities for the Search Results Editor.\\n\\n\\nResult 19:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/references-view/README.md\\', \\'node_id\\': 4735988}\\npreview: # References View\\n\\nThis extension shows reference search results as separate view, just like search results. It complements the peek view presentation that is also built into VS Code. The following features are available:\\n\\n- List All References via the Command Palette, the Context Menu, or via <kbd>Alt+Shift+F12</kbd>\\n- View references in a dedicated tree view that sits in the sidebar\\n- Navigate through search results via <kbd>F4</kbd> and <kbd>Shift+F4</kbd>\\n- Remove references from the list via inline commands\\n\\n![](https://raw.githubusercontent.com/microsoft/vscode-references-view/master/media/demo.png)\\n\\n**Note** that this extension is bundled with Visual Studio Code version 1.29 and later - it doesn\\'t need to be installed anymore.\\n\\n## Requirements\\n\\nThis extension is just an alternative UI for reference search and extensions implementing reference search must still be installed.\\n\\n## Issues\\n\\nThis extension ships with Visual Studio Code and uses its issue tracker. Please file issue here: https://github.com/Microsoft/vscode/issues\\n\\n# Contributing\\n\\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\\n\\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n\\nResult 20:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/php-language-features/README.md\\', \\'node_id\\': 4737042}\\npreview: # Language Features for PHP files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [PHP in Visual Studio Code](https://code.visualstudio.com/docs/languages/php) to learn about the features of this extension.\\n\\n\\nResult 21:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/npm/README.md\\', \\'node_id\\': 4737797}\\npreview: # Node npm\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\n### Task Running\\n\\nThis extension supports running npm scripts defined in the `package.json` as [tasks](https://code.visualstudio.com/docs/editor/tasks). Scripts with the name \\'build\\', \\'compile\\', or \\'watch\\'\\nare treated as build tasks.\\n\\nTo run scripts as tasks, use the **Tasks** menu.\\n\\nFor more information about auto detection of Tasks, see the [documentation](https://code.visualstudio.com/Docs/editor/tasks#_task-autodetection).\\n\\n### Script Explorer\\n\\nThe Npm Script Explorer shows the npm scripts found in your workspace. The explorer view is enabled by the setting `npm.enableScriptExplorer`. A script can be opened, run, or debug from the explorer.\\n\\n### Run Scripts from the Editor\\n\\nThe extension supports to run the selected script as a task when editing the `package.json`file. You can either run a script from\\nthe hover shown on a script or using the command `Run Selected Npm Script`.\\n\\n### Run Scripts from a Folder in the Explorer\\n\\nThe extension supports running a script as a task from a folder in the Explorer. The command  `Run NPM Script in Folder...` shown in the Explorer context menu finds all scripts in `package.json` files that are contained in this folder. You can then select the script to be executed as a task from the resulting list. You enable this support with the `npm.runScriptFromFolder` which is `false` by default.\\n\\n### Others\\n\\nThe extension fetches data from <https://registry.npmjs.org> and <https://registry.bower.io> to provide auto-completion and information on hover features on npm dependencies.\\n\\n## Settings\\n\\n- `npm.autoDetect` - Enable detecting scripts as tasks, the default is `on`.\\n- `npm.runSilent` - Run npm script with the `--silent` option, the default is `false`.\\n- `npm.packageManager` - The package manager used to install dependencies: `auto`, `npm`, `yarn`, `pnpm` or `bun`. The default is `auto`, which detects your package manager based on files in your workspace.\\n- `npm.scriptRunner` - The script runner used to run the scripts: `auto`, `npm`, `yarn`, `pnpm`, `bun` or `node`. The default is `auto`, which detects your script runner based on files in your workspace.\\n- `npm.exclude` - Glob patterns for folders that should be excluded from automatic script detection. The pattern is matched against the **absolute path** of the package.json. For example, to exclude all test folders use \\'&ast;&ast;/test/&ast;&ast;\\'.\\n- `npm.enableScriptExplorer` - Enable an explorer view for npm scripts.\\n- `npm.scriptExplorerAction` - The default click action: `open` or `run`, the default is `open`.\\n- `npm.enableRunFromFolder` - Enable running npm scripts from the context menu of folders in Explorer, the default is `false`.\\n- `npm.scriptCodeLens.enable` - Enable/disable the code lenses to run a script, the default is `false`.\\n\\n\\nResult 22:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/notebook-renderers/README.md\\', \\'node_id\\': 4739483}\\npreview: # Builtin Notebook Output Renderers for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following notebook renderers for VS Code:\\n\\n- Image renderer for png, jpeg and gif\\n\\n\\nResult 23:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/microsoft-authentication/README.md\\', \\'node_id\\': 4740838}\\npreview: # Microsoft Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to Microsoft. It registers the `microsoft` Authentication Provider that can be leveraged by other extensions. This also provides the Microsoft authentication used by Settings Sync.\\n\\nAdditionally, it provides the `microsoft-sovereign-cloud` Authentication Provider that can be used to sign in to other Azure clouds like Azure for US Government or Azure China. Use the setting `microsoft-sovereign-cloud.endpoint` to select the authentication endpoint the provider should use. Please note that different scopes may also be required in different environments.\\n\\n\\nResult 24:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/mermaid-chat-features/README.md\\', \\'node_id\\': 4743452}\\npreview: # Mermaid Chat Features\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds basic [Mermaid.js](https://mermaid.js.org) diagram rendering to build-in chat.\\n\\n\\nResult 25:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/merge-conflict/README.md\\', \\'node_id\\': 4743675}\\npreview: # Merge Conflict\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Merge Conflicts in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_merge-conflicts) to learn about features of this extension.\\n\\n\\nResult 26:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/media-preview/README.md\\', \\'node_id\\': 4744324}\\npreview: # Media Preview\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides basic preview for images, audio and video files.\\n\\n### Supported image file extensions\\n\\n- `.jpg`, `.jpe`, `.jpeg`\\n- `.png`\\n- `.bmp`\\n- `.gif`\\n- `.ico`\\n- `.webp`\\n- `.avif`\\n\\n### Supported audio formats\\n\\n- `.mp3`\\n- `.wav`\\n- `.ogg`, `.oga`\\n\\n### Supported video formats\\n\\n- `.mp4` (does not support `aac` audio tracks)\\n- `.webm` (vp8 only)\\n\\n\\nResult 27:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/markdown-math/README.md\\', \\'node_id\\': 4745044}\\npreview: # Markdown Math\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds math rendering using [KaTeX](https://katex.org) to VS Code\\'s built-in markdown preview and markdown cells in notebooks.\\n\\n\\nResult 28:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/markdown-language-features/README.md\\', \\'node_id\\': 4745172}\\npreview: # Language Features for Markdown files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Markdown in Visual Studio Code](https://code.visualstudio.com/docs/languages/markdown) to learn about the features of this extension.\\n\\n\\nResult 29:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/json-language-features/README.md\\', \\'node_id\\': 4751670}\\npreview: # Language Features for JSON files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [JSON in Visual Studio Code](https://code.visualstudio.com/docs/languages/json) to learn about the features of this extension.\\n\\n\\nResult 30:\\nFileNode: {\\'basename\\': \\'README.md\\', \\'relative_path\\': \\'extensions/json-language-features/server/README.md\\', \\'node_id\\': 4751677}\\npreview: # VSCode JSON Language Server\\n\\n[![NPM Version](https://img.shields.io/npm/v/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Version](https://img.shields.io/npm/l/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n\\nThe JSON Language server provides language-specific smarts for editing, validating and understanding JSON documents. It runs as a separate executable and implements the [language server protocol](https://microsoft.github.io/language-server-protocol/overview) to be connected by any code editor or IDE.\\n\\n## Capabilities\\n\\n### Server capabilities\\n\\nThe JSON language server supports requests on documents of language id `json` and `jsonc`.\\n\\n- `json` documents are parsed and validated following the [JSON specification](https://tools.ietf.org/html/rfc7159).\\n- `jsonc` documents additionally accept single line (`//`) and multi-line comments (`/* ... */`). JSONC is a VSCode specific file format, intended for VSCode configuration files, without any aspirations to define a new common file format.\\n\\nThe server implements the following capabilities of the language server protocol:\\n\\n- [Code completion](https://microsoft.github.io/language-server-protocol/specification#textDocument_completion) for JSON properties and values based on the document\\'s [JSON schema](http://json-schema.org/) or based on existing properties and values used at other places in the document. JSON schemas are configured through the server configuration options.\\n- [Hover](https://microsoft.github.io/language-server-protocol/specification#textDocument_hover) for values based on descriptions in the document\\'s [JSON schema](http://json-schema.org/).\\n- [Document Symbols](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentSymbol) for quick navigation to properties in the document.\\n- [Document Colors](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentColor) for showing color decorators on values representing colors and [Color Presentation](https://microsoft.github.io/language-server-protocol/specification#textDocument_colorPresentation) for color presentation information to support color... Output has been truncated becuase it is too long, please narrow down your query if you wish to see more' name='preview_file_content_with_basename' id='07b7d3bf-a2b3-4b42-9a4d-5b6b0a489b86' tool_call_id='call_WdkaLWjds0dyrQs5L4kkPy5I' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3734887}, 'preview': '# Visual Studio Code - Open Source (\"Code - OSS\")\\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=✓&q=is%3Aissue+is%3Aopen+label%3Abug)\\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\\n\\n## The Repository\\n\\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\\n\\n## Visual Studio Code\\n\\n<p align=\"center\">\\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png\">\\n</p>\\n\\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\\n\\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\\n\\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code\\'s website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\\n\\n## Contributing\\n\\nThere are many ways in which you can participate in this project, for example:\\n\\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content\\n\\nIf you are interested in fixing issues and contributing directly to the code base,\\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\\n\\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\\n* [Contributing to translations](https://aka.ms/vscodeloc)\\n\\n## Feedback\\n\\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\\n* [Request a new feature](CONTRIBUTING.md)\\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\\n* [File an issue](https://github.com/microsoft/vscode/issues)\\n* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)\\n* Follow [@code](https://twitter.com/code) and let us know what you think!\\n\\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\\n\\n## Related Projects\\n\\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\\n\\n## Bundled Extensions\\n\\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.\\n\\n## Development Container\\n\\nThis repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.\\n\\n* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.\\n  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\\n\\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\\n\\n## Code of Conduct\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## License\\n\\nCopyright (c) Microsoft Corporation. All rights reserved.\\n\\nLicensed under the [MIT](LICENSE.txt) license.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3734900}, 'preview': '# VSCode Tests\\n\\n## Contents\\n\\nThis folder contains the various test runners for VSCode. Please refer to the documentation within for how to run them:\\n\\n* `unit`: our suite of unit tests ([README](unit/README.md))\\n* `integration`: our suite of API tests ([README](integration/browser/README.md))\\n* `smoke`: our suite of automated UI tests ([README](smoke/README.md))'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3734908}, 'preview': \"# Unit Tests\\n\\n## Run (inside Electron)\\n\\n    ./scripts/test.[sh|bat]\\n\\nAll unit tests are run inside a Electron renderer environment which access to DOM and Nodejs api. This is the closest to the environment in which VS Code itself ships. Notes:\\n\\n- use the `--debug` to see an electron window with dev tools which allows for debugging\\n- to run only a subset of tests use the `--run` or `--glob` options\\n- use `npm run watch` to automatically compile changes\\n\\nFor instance, `./scripts/test.sh --debug --glob **/extHost*.test.js` runs all tests from `extHost`-files and enables you to debug them.\\n\\n## Run (inside browser)\\n\\n    npm run test-browser -- --browser webkit --browser chromium\\n\\nUnit tests from layers `common` and `browser` are run inside `chromium`, `webkit`, and (soon'ish) `firefox` (using playwright). This complements our electron-based unit test runner and adds more coverage of supported platforms. Notes:\\n\\n- these tests are part of the continuous build, that means you might have test failures that only happen with webkit on _windows_ or _chromium_ on linux\\n- you can run these tests locally via `npm run test-browser -- --browser chromium --browser webkit`\\n- to debug, open `<vscode>/test/unit/browser/renderer.html` inside a browser and use the `?m=<amd_module>`-query to specify what AMD module to load, e.g `file:///Users/jrieken/Code/vscode/test/unit/browser/renderer.html?m=vs/base/test/common/strings.test` runs all tests from `strings.test.ts`\\n- to run only a subset of tests use the `--run` or `--glob` options\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (https://playwright.dev/docs/debug#verbose-api-logs)\\n\\n## Run (with node)\\n\\n    npm run test-node -- --run src/vs/editor/test/browser/controller/cursor.test.ts\\n\\n## Coverage\\n\\nThe following command will create a `coverage` folder in the `.build` folder at the root of the workspace:\\n\\n### OS X and Linux\\n\\n    ./scripts/test.sh --coverage\\n\\n### Windows\\n\\n    scripts\\\\test --coverage\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/smoke/README.md', 'node_id': 3736755}, 'preview': \"# VS Code Smoke Test\\n\\nMake sure you are on **Node v12.x**.\\n\\n## Quick Overview\\n\\n```bash\\n# Build extensions in the VS Code repo (if needed)\\nnpm i && npm run compile\\n\\n# Dev (Electron)\\nnpm run smoketest\\n\\n# Dev (Web - Must be run on distro)\\nnpm run smoketest -- --web --browser [chromium|webkit]\\n\\n# Build (Electron)\\nnpm run smoketest -- --build <path to latest version>\\nexample: npm run smoketest -- --build /Applications/Visual\\\\ Studio\\\\ Code\\\\ -\\\\ Insiders.app\\n\\n# Build (Web - read instructions below)\\nnpm run smoketest -- --build <path to server web build (ends in -web)> --web --browser [chromium|webkit]\\n\\n# Remote (Electron)\\nnpm run smoketest -- --build <path to latest version> --remote\\n```\\n\\n\\\\* This step is necessary only when running without `--build` and OSS doesn't already exist in the `.build/electron` directory.\\n\\n### Running for a release (Endgame)\\n\\nYou must always run the smoketest version that matches the release you are testing. So, if you want to run the smoketest for a release build (e.g. `release/1.22`), you need to check out that version of the smoke tests too:\\n\\n```bash\\ngit fetch\\ngit checkout release/1.22\\nnpm i && npm run compile\\ncd test/smoke\\nnpm i\\n```\\n\\n#### Web\\n\\nThere is no support for testing an old version to a new one yet.\\nInstead, simply configure the `--build` command line argument to point to the absolute path of the extracted server web build folder (e.g. `<rest of path here>/vscode-server-darwin-x64-web` for macOS). The server web build is available from the builds page (see previous subsection).\\n\\n**macOS**: if you have downloaded the server with web bits, make sure to run the following command before unzipping it to avoid security issues on startup:\\n\\n```bash\\nxattr -d com.apple.quarantine <path to server with web folder zip>\\n```\\n\\n**Note**: make sure to point to the server that includes the client bits!\\n\\n### Debug\\n\\n- `--verbose` logs all the low level driver calls made to Code;\\n- `-f PATTERN` (alias `-g PATTERN`) filters the tests to be run. You can also use pretty much any mocha argument;\\n- `--headless` will run playwright in headless mode when `--web` is used.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>), for example to `pw:browser`.\\n\\n### Develop\\n\\n```bash\\ncd test/smoke\\nnpm run watch\\n```\\n\\n## Troubleshooting\\n\\n### Error: Could not get a unique tmp filename, max tries reached\\n\\nOn Windows, check for the folder `C:\\\\Users\\\\<username>\\\\AppData\\\\Local\\\\Temp\\\\t`. If this folder exists, the `tmp` module can't run properly, resulting in the error above. In this case, delete the `t` folder.\\n\\n## Pitfalls\\n\\n- Beware of workbench **state**. The tests within a single suite will share the same state.\\n\\n- Beware of **singletons**. This evil can, and will, manifest itself under the form of FS paths, TCP ports, IPC handles. Whenever writing a test, or setting up more smoke test architecture, make sure it can run simultaneously with any other tests and even itself. All test suites should be able to run many times in parallel.\\n\\n- Beware of **focus**. **Never** depend on DOM elements having focus using `.focused` classes or `:focus` pseudo-classes, since they will lose that state as soon as another window appears on top of the running VS Code window. A safe approach which avoids this problem is to use the `waitForActiveElement` API. Many tests use this whenever they need to wait for a specific element to _have focus_.\\n\\n- Beware of **timing**. You need to read from or write to the DOM... but is it the right time to do that? Can you 100% guarantee that `input` box will be visible at that point in time? Or are you just hoping that it will be so? Hope is your worst enemy in UI tests. Example: just because you triggered Quick Access with `F1`, it doesn't mean that it's open and you can just start typing; you must first wait for the input element to be in the DOM as well as be the current active element.\\n\\n- Beware of **waiting**. **Never** wait longer than a couple of seconds for anything, unless it's justified. Think of it as a human using Code. Would a human take 10 minutes to run through the Search viewlet smoke test? Then, the computer should even be faster. **Don't** use `setTimeout` just because. Think about what you should wait for in the DOM to be ready and wait for that instead.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/monaco/README.md', 'node_id': 3738548}, 'preview': '# Monaco Editor Test\\n\\nThis directory contains scripts that are used to smoke test the Monaco Editor distribution.\\n\\n## Setup & Bundle\\n\\n $test/monaco> npm i\\n $test/monaco> npm run bundle\\n\\n## Compile and run tests\\n\\n $test/monaco> npm run compile\\n $test/monaco> npm run test'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/mcp/README.md', 'node_id': 3738926}, 'preview': '# Code - OSS Development MCP Server\\n\\nThis directory contains a Model Context Protocol (MCP) server that provides Playwright browser automation capabilities for Code - OSS development and testing. The MCP server exposes Code - OSS\\'s Playwright testing infrastructure through a standardized interface, allowing AI assistants and other tools to interact with browsers programmatically.\\n\\n## What is MCP?\\n\\nThe [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that enables AI assistants to securely connect to external data sources and tools. This MCP server specifically provides browser automation capabilities using Playwright, making it possible for AI assistants to:\\n\\n- Navigate web pages\\n- Interact with UI elements (click, type, hover, etc.)\\n- Take screenshots and capture page content\\n- Evaluate JavaScript in browser contexts\\n- Handle file uploads and downloads\\n- Manage browser tabs and windows\\n\\n## Quick Start - Stdio\\n\\nFirstly, make sure you install all dependencies (`npm i`) at the root of the repo.\\n\\nThen, open the Command Palette and run:\\n```\\nMCP: List Servers → vscode-playwright-mcp → Start Server\\n```\\nor open [mcp.json](../../.vscode/mcp.json) and start it from there.\\n\\nThat\\'s it! It should automatically compile everything needed.\\n\\nThen you can use `/playwright` to ask specific questions.\\n\\n## Arguments\\n\\nOpen the [mcp.json](../../.vscode/mcp.json) and modify the `args`:\\n\\n* `[\"run\", \"start-stdio\"]`: opens Electron window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\"]`: opens a Chromium window\\n* `[\"run\", \"start-stdio\", \"--\", \"--web\", \"--headless\"]`: opens a headless window\\n\\n> *NOTE: `--web` requires running `npm run install-playwright` from root*\\n\\n## Debugging the server\\n\\nYou can modify the mcp.json to debug the server:\\n```JSON\\n\"vscode-playwright-mcp\": {\\n\\t\"type\": \"stdio\",\\n\\t\"command\": \"node\",\\n\\t\"args\": [\"./out/stdio.js\"],\\n\\t\"cwd\": \"${workspaceFolder}/test/mcp\",\\n\\t\"dev\": {\\n\\t\\t\"watch\": \"test/mcp/**/*.ts\",\\n\\t\\t\"debug\": {\\n\\t\\t\\t\"type\": \"node\"\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\n## What the Server Provides\\n\\nThe MCP server exposes a comprehensive set of browser automation tools through the MCP protocol:\\n\\n### Element Interaction\\n- Click on elements (single, double, right-click)\\n- Type text into input fields\\n- Hover over elements\\n- Drag and drop between elements\\n- Select options in dropdowns\\n\\n### Content Capture & Analysis\\n- Take screenshots (full page or specific elements)\\n- Capture accessibility snapshots for better element targeting\\n- Get page console messages\\n- Monitor network requests\\n\\n### Advanced Features\\n- Evaluate JavaScript code in browser contexts\\n- Handle file uploads\\n- Wait for specific content or time delays\\n- Handle browser dialogs and alerts\\n\\n## Development\\n\\n### Manual Setup (Advanced)\\n\\nIf you prefer to run the server manually:\\n\\n```bash\\n# Navigate to the MCP directory\\ncd test/mcp\\n\\n# Install dependencies\\nnpm install\\n\\n# Compile TypeScript\\nnpm run compile # or watch\\n\\n# Start the server\\nnpm start\\n```\\n\\n### Project Structure\\n\\n```\\ntest/mcp/\\n├── src/\\n│   ├── main.ts              # Express server and MCP endpoint handlers\\n│   ├── playwright.ts        # Code - OSS Playwright integration\\n│   ├── inMemoryEventStore.ts # Session management for resumability\\n│   └── utils.ts             # Utility functions\\n├── package.json             # Dependencies and scripts\\n├── tsconfig.json           # TypeScript configuration\\n└── README.md              # This file\\n```\\n\\n### Key Features\\n\\n- **Session Management**: Supports multiple concurrent MCP sessions with proper cleanup\\n- **Resumability**: Built-in event store for connection resumption\\n- **Code - OSS Integration**: Uses Code - OSS\\'s existing Playwright test infrastructure\\n- **CORS Support**: Configured for cross-origin requests\\n- **Error Handling**: Comprehensive error handling and logging\\n\\n## Troubleshooting\\n\\n### Server Won\\'t Start\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Verify all dependencies are installed with `npm install`\\n\\n### Browser Automation Issues\\n- Ensure Code - OSS has been built and run at least once (via F5 or `code.sh`)\\n- Check the server logs for Playwright-related errors\\n- Verify the test repository is properly cloned\\n\\n## Contributing\\n\\nThis MCP server is part of the Code - OSS development infrastructure. When making changes:\\n\\n1. Follow the existing TypeScript and coding conventions\\n2. Test with multiple MCP clients if possible\\n3. Update this README if adding new capabilities\\n4. Ensure proper error handling and logging\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the top-level project\\'s license file for details.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/integration/browser/README.md', 'node_id': 3740947}, 'preview': '# Integration test\\n\\n## Compile\\n\\nMake sure to run the following commands to compile and install dependencies:\\n\\n    cd test/integration/browser\\n    npm i\\n    npm run compile\\n\\n## Run (inside Electron)\\n\\n    scripts/test-integration.[sh|bat]\\n\\nAll integration tests run in an Electron instance. You can specify to run the tests against a real build by setting the environment variables `INTEGRATION_TEST_ELECTRON_PATH` and `VSCODE_REMOTE_SERVER_PATH` (if you want to include remote tests).\\n\\n## Run (inside browser)\\n\\n    scripts/test-web-integration.[sh|bat] --browser [chromium|webkit] [--debug]\\n\\nAll integration tests run in a browser instance as specified by the command line arguments.\\n\\nAdd the `--debug` flag to see a browser window with the tests running.\\n\\n**Note**: you can enable verbose logging of playwright library by setting a `DEBUG` environment variable before running the tests (<https://playwright.dev/docs/debug#verbose-api-logs>)\\n\\n## Debug\\n\\nAll integration tests can be run and debugged from within VSCode (both Electron and Web) simply by selecting the related launch configuration and running them.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/automation/README.md', 'node_id': 3741239}, 'preview': '# VS Code Automation Package\\n\\nThis package contains functionality for automating various components of the VS Code UI, via an automation \"driver\" that connects from a separate process. It is used by the `smoke` tests.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vscode-dts/README.md', 'node_id': 3744265}, 'preview': \"# vscode-dts\\n\\nThis is the place for the stable API and for API proposals.\\n\\n## Consume a proposal\\n\\n1. find a proposal you are interested in\\n1. add its name to your extensions `package.json#enabledApiProposals` property\\n1. run `npx vscode-dts dev` to download the `d.ts` files into your project\\n1. don't forget that extension using proposed API cannot be published\\n1. learn more here: <https://code.visualstudio.com/api/advanced-topics/using-proposed-api>\\n\\n## Add a new proposal\\n\\n1. create a _new_ file in this directory, its name must follow this pattern `vscode.proposed.[a-zA-Z]+.d.ts`\\n1. creating the proposal-file will automatically update `src/vs/platform/extensions/common/extensionsApiProposals.ts` (make sure to run `npm run watch`)\\n1. declare and implement your proposal\\n1. make sure to use the `checkProposedApiEnabled` and/or `isProposedApiEnabled`-utils to enforce the API being proposed. Make sure to invoke them with your proposal's name which got generated into `extensionsApiProposals.ts`\\n1. Most likely will need to add your proposed api to vscode-api-tests as well\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/workbench/contrib/terminalContrib/README.md', 'node_id': 3897567}, 'preview': \"_Terminal contribs_ are a way of splitting out standalone terminal features into their own components that build upon the main terminal code. The `terminalContrib/` folder can only import from `terminal/`, not the other way around. There are eslint rules to prevent this circular dependencies.\\n\\nHaving the entire feature and its tests in the same place makes not only the contrib easier to maintain and understand, but also the core terminal code as it's less interspersed with feature code. Sometimes it's not possible without bigger changes to make the feature totally standalone, in this case the goal is to get as close as possible.\\n\\nThis should not be confused with the similar `ITerminalContribution` which is a parallel to `IEditorContribution` and is used for decorating each individual terminal with additional functionality. An entry in `terminalContrib/` may use `ITerminalContribution`s to add its features.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/editor/test/node/diffing/README.md', 'node_id': 4481497}, 'preview': '# Diffing Fixture Tests\\n\\nEvery folder in `fixtures` represents a test.\\nThe file that starts with `1.` is diffed against the file that starts with `2.`. Use `tst` instead of `ts` to avoid compiler/linter errors for typescript diff files.\\n\\n* Missing `*.expected.diff.json` are created automatically (as well as an `*.invalid.diff.json` file).\\n* If the actual diff does not equal the expected diff, the expected file is updated automatically. The previous value of the expected file is written to `*.invalid.diff.json`.\\n* The test will fail if there are any `*.invalid.diff.json` files. This makes sure that the test keeps failing even if it is run a second time.\\n\\nWhen changing the diffing algorithm, run the fixture tests, review the diff of the `*.expected.diff.json` files and delete all `*.invalid.diff.json` files.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/README.md', 'node_id': 4707968}, 'preview': '# Language Features for TypeScript and JavaScript files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [TypeScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/typescript) and [JavaScript in Visual Studio Code](https://code.visualstudio.com/docs/languages/javascript) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/web/README.md', 'node_id': 4707977}, 'preview': '# vscode-wasm-typescript\\n\\nLanguage server host for typescript using vscode\\'s sync-api in the browser.\\n\\n## Getting up and running\\n\\nTo test this out, you\\'ll need three shells:\\n\\n1. `npm i` for vscode itself\\n2. `npm run watch-web` for the web side\\n3. `node <root>/scripts/code-web.js --coi`\\n\\nThe last command will open a browser window. You\\'ll want to add `?vscode-coi=`\\nto the end. This is for enabling shared array buffers. So, for example:\\n`http://localhost:8080/?vscode-coi=`.\\n\\n### Working on type acquisition\\n\\nIn order to work with web\\'s new type acquisition, you\\'ll need to enable\\n`TypeScript > Experimental > Tsserver > Web: Enable Project Wide Intellisense`\\nin your VS Code options (`Ctrl-,`), you may need to reload the page.\\n\\nThis happens when working in a regular `.js` file on a dependency without\\ndeclared types. You should be able to open `file.js` and write something like\\n`import lodash from \\'lodash\\';` at the top of the file and, after a moment, get\\ntypes and other intellisense features (like Go To Def/Source Def) working as\\nexpected. This scenario works off Tsserver\\'s own Automatic Type Acquisition\\ncapabilities, and simulates a \"global\" types cache stored at\\n`/vscode-global-typings/ts-nul-authority/project`, which is backed by an\\nin-memory `MemFs` `FileSystemProvider`.\\n\\n### Simulated `node_modules`\\n\\nFor regular `.ts` files, instead of going through Tsserver\\'s type acquisition,\\na separate `AutoInstallerFs` is used to create a \"virtual\" `node_modules` that\\nextracts desired packages on demand, to an underlying `MemFs`. This will\\nhappen any time a filesystem operation is done inside a `node_modules` folder\\nacross any project in the workspace, and will use the \"real\" `package.json`\\n(and, if present, `package-lock.json`) to resolve the dependency tree.\\n\\nA fallback is then set up such that when a URI like\\n`memfs:/path/to/node_modules/lodash/lodash.d.ts` is accessed, that gets\\nredirected to\\n`vscode-node-modules:/ts-nul-authority/memfs/ts-nul-authority/path/to/node_modules/lodash/lodash.d.ts`,\\nwhich will be sent to the `AutoInstallerFs`.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/theme-seti/README.md', 'node_id': 4725047}, 'preview': '# theme-seti\\n\\nThis is an icon theme that uses the icons from [`seti-ui`](https://github.com/jesseweed/seti-ui).\\n\\n## Updating icons\\n\\nThere is script that can be used to update icons, [./build/update-icon-theme.js](build/update-icon-theme.js).\\n\\nTo run this script, run `npm run update` from the `theme-seti` directory.\\n\\nThis can be run in one of two ways: looking at a local copy of `seti-ui` for icons, or getting them straight from GitHub.\\n\\nIf you want to run it from a local copy of `seti-ui`, first clone [`seti-ui`](https://github.com/jesseweed/seti-ui) to the folder next to your `vscode` repo (from the `theme-seti` directory, `../../`).\\nThen, inside the `set-ui` directory, run `npm install` followed by `npm run prepublishOnly`. This will generate updated icons.\\n\\nIf you want to download the icons straight from GitHub, change the `FROM_DISK` variable to `false` inside of `update-icon-theme.js`.\\n\\n### Languages not shipped with `vscode`\\n\\nLanguages that are not shipped with `vscode` must be added to the `nonBuiltInLanguages` object inside of `update-icon-theme.js`.\\n\\nThese should match [the file mapping in `seti-ui`](https://github.com/jesseweed/seti-ui/blob/master/styles/components/icons/mapping.less).\\n\\nPlease try and keep this list in alphabetical order! Thank you.\\n\\n## Previewing icons\\n\\nThere is a [`./icons/preview.html`](./icons/preview.html) file that can be opened to see all of the icons included in the theme.\\nNote that to view this, it needs to be hosted by a web server.\\n\\nWhen updating icons, it is always a good idea to make sure that they work properly by looking at this page.\\nWhen submitting a PR that updates these icons, a screenshot of the preview page should accompany it.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/README.md', 'node_id': 4725296}, 'preview': '# Terminal Suggestions\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled. To enable the completions from this extension, set `terminal.integrated.suggest.enabled` to `true`.\\n\\n## Features\\n\\nProvides terminal suggestions for zsh, bash, fish, and pwsh.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/src/fig/README.md', 'node_id': 4728058}, 'preview': \"This folder contains the `autocomplete-parser` project from https://github.com/aws/amazon-q-developer-cli/blob/main/packages/autocomplete-parser and its dependencies which were located in siblings folders and https://github.com/withfig/autocomplete-tools, both licenses under MIT. The fork was necessary for a few reasons:\\n\\n- They ship as ESM modules which we're not ready to consume just yet.\\n- We want the more complete `autocomplete-parser` that contains the important `parseArguments` function that does the bulk of the smarts in parsing the fig commands.\\n- We needed to strip out all the implementation-specific parts from their `api-bindings` project that deals with settings, IPC, fuzzy sorting, etc.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/simple-browser/README.md', 'node_id': 4735296}, 'preview': '# Simple Browser\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nProvides a very basic browser preview using an iframe embedded in a [webviewW](). This extension is primarily meant to be used by other extensions for showing simple web content.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/search-result/README.md', 'node_id': 4735682}, 'preview': '# Language Features for Search Result files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nThis extension provides Syntax Highlighting, Symbol Information, Result Highlighting, and Go to Definition capabilities for the Search Results Editor.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/references-view/README.md', 'node_id': 4735988}, 'preview': \"# References View\\n\\nThis extension shows reference search results as separate view, just like search results. It complements the peek view presentation that is also built into VS Code. The following features are available:\\n\\n- List All References via the Command Palette, the Context Menu, or via <kbd>Alt+Shift+F12</kbd>\\n- View references in a dedicated tree view that sits in the sidebar\\n- Navigate through search results via <kbd>F4</kbd> and <kbd>Shift+F4</kbd>\\n- Remove references from the list via inline commands\\n\\n![](https://raw.githubusercontent.com/microsoft/vscode-references-view/master/media/demo.png)\\n\\n**Note** that this extension is bundled with Visual Studio Code version 1.29 and later - it doesn't need to be installed anymore.\\n\\n## Requirements\\n\\nThis extension is just an alternative UI for reference search and extensions implementing reference search must still be installed.\\n\\n## Issues\\n\\nThis extension ships with Visual Studio Code and uses its issue tracker. Please file issue here: https://github.com/Microsoft/vscode/issues\\n\\n# Contributing\\n\\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\\n\\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/php-language-features/README.md', 'node_id': 4737042}, 'preview': '# Language Features for PHP files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [PHP in Visual Studio Code](https://code.visualstudio.com/docs/languages/php) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/npm/README.md', 'node_id': 4737797}, 'preview': \"# Node npm\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\n### Task Running\\n\\nThis extension supports running npm scripts defined in the `package.json` as [tasks](https://code.visualstudio.com/docs/editor/tasks). Scripts with the name 'build', 'compile', or 'watch'\\nare treated as build tasks.\\n\\nTo run scripts as tasks, use the **Tasks** menu.\\n\\nFor more information about auto detection of Tasks, see the [documentation](https://code.visualstudio.com/Docs/editor/tasks#_task-autodetection).\\n\\n### Script Explorer\\n\\nThe Npm Script Explorer shows the npm scripts found in your workspace. The explorer view is enabled by the setting `npm.enableScriptExplorer`. A script can be opened, run, or debug from the explorer.\\n\\n### Run Scripts from the Editor\\n\\nThe extension supports to run the selected script as a task when editing the `package.json`file. You can either run a script from\\nthe hover shown on a script or using the command `Run Selected Npm Script`.\\n\\n### Run Scripts from a Folder in the Explorer\\n\\nThe extension supports running a script as a task from a folder in the Explorer. The command  `Run NPM Script in Folder...` shown in the Explorer context menu finds all scripts in `package.json` files that are contained in this folder. You can then select the script to be executed as a task from the resulting list. You enable this support with the `npm.runScriptFromFolder` which is `false` by default.\\n\\n### Others\\n\\nThe extension fetches data from <https://registry.npmjs.org> and <https://registry.bower.io> to provide auto-completion and information on hover features on npm dependencies.\\n\\n## Settings\\n\\n- `npm.autoDetect` - Enable detecting scripts as tasks, the default is `on`.\\n- `npm.runSilent` - Run npm script with the `--silent` option, the default is `false`.\\n- `npm.packageManager` - The package manager used to install dependencies: `auto`, `npm`, `yarn`, `pnpm` or `bun`. The default is `auto`, which detects your package manager based on files in your workspace.\\n- `npm.scriptRunner` - The script runner used to run the scripts: `auto`, `npm`, `yarn`, `pnpm`, `bun` or `node`. The default is `auto`, which detects your script runner based on files in your workspace.\\n- `npm.exclude` - Glob patterns for folders that should be excluded from automatic script detection. The pattern is matched against the **absolute path** of the package.json. For example, to exclude all test folders use '&ast;&ast;/test/&ast;&ast;'.\\n- `npm.enableScriptExplorer` - Enable an explorer view for npm scripts.\\n- `npm.scriptExplorerAction` - The default click action: `open` or `run`, the default is `open`.\\n- `npm.enableRunFromFolder` - Enable running npm scripts from the context menu of folders in Explorer, the default is `false`.\\n- `npm.scriptCodeLens.enable` - Enable/disable the code lenses to run a script, the default is `false`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/notebook-renderers/README.md', 'node_id': 4739483}, 'preview': '# Builtin Notebook Output Renderers for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following notebook renderers for VS Code:\\n\\n- Image renderer for png, jpeg and gif'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/microsoft-authentication/README.md', 'node_id': 4740838}, 'preview': '# Microsoft Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to Microsoft. It registers the `microsoft` Authentication Provider that can be leveraged by other extensions. This also provides the Microsoft authentication used by Settings Sync.\\n\\nAdditionally, it provides the `microsoft-sovereign-cloud` Authentication Provider that can be used to sign in to other Azure clouds like Azure for US Government or Azure China. Use the setting `microsoft-sovereign-cloud.endpoint` to select the authentication endpoint the provider should use. Please note that different scopes may also be required in different environments.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/mermaid-chat-features/README.md', 'node_id': 4743452}, 'preview': '# Mermaid Chat Features\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds basic [Mermaid.js](https://mermaid.js.org) diagram rendering to build-in chat.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/merge-conflict/README.md', 'node_id': 4743675}, 'preview': '# Merge Conflict\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Merge Conflicts in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_merge-conflicts) to learn about features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/media-preview/README.md', 'node_id': 4744324}, 'preview': '# Media Preview\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides basic preview for images, audio and video files.\\n\\n### Supported image file extensions\\n\\n- `.jpg`, `.jpe`, `.jpeg`\\n- `.png`\\n- `.bmp`\\n- `.gif`\\n- `.ico`\\n- `.webp`\\n- `.avif`\\n\\n### Supported audio formats\\n\\n- `.mp3`\\n- `.wav`\\n- `.ogg`, `.oga`\\n\\n### Supported video formats\\n\\n- `.mp4` (does not support `aac` audio tracks)\\n- `.webm` (vp8 only)'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-math/README.md', 'node_id': 4745044}, 'preview': \"# Markdown Math\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\nAdds math rendering using [KaTeX](https://katex.org) to VS Code's built-in markdown preview and markdown cells in notebooks.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-language-features/README.md', 'node_id': 4745172}, 'preview': '# Language Features for Markdown files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Markdown in Visual Studio Code](https://code.visualstudio.com/docs/languages/markdown) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/README.md', 'node_id': 4751670}, 'preview': '# Language Features for JSON files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [JSON in Visual Studio Code](https://code.visualstudio.com/docs/languages/json) to learn about the features of this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/server/README.md', 'node_id': 4751677}, 'preview': '# VSCode JSON Language Server\\n\\n[![NPM Version](https://img.shields.io/npm/v/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n[![NPM Version](https://img.shields.io/npm/l/vscode-json-languageserver.svg)](https://npmjs.org/package/vscode-json-languageserver)\\n\\nThe JSON Language server provides language-specific smarts for editing, validating and understanding JSON documents. It runs as a separate executable and implements the [language server protocol](https://microsoft.github.io/language-server-protocol/overview) to be connected by any code editor or IDE.\\n\\n## Capabilities\\n\\n### Server capabilities\\n\\nThe JSON language server supports requests on documents of language id `json` and `jsonc`.\\n\\n- `json` documents are parsed and validated following the [JSON specification](https://tools.ietf.org/html/rfc7159).\\n- `jsonc` documents additionally accept single line (`//`) and multi-line comments (`/* ... */`). JSONC is a VSCode specific file format, intended for VSCode configuration files, without any aspirations to define a new common file format.\\n\\nThe server implements the following capabilities of the language server protocol:\\n\\n- [Code completion](https://microsoft.github.io/language-server-protocol/specification#textDocument_completion) for JSON properties and values based on the document\\'s [JSON schema](http://json-schema.org/) or based on existing properties and values used at other places in the document. JSON schemas are configured through the server configuration options.\\n- [Hover](https://microsoft.github.io/language-server-protocol/specification#textDocument_hover) for values based on descriptions in the document\\'s [JSON schema](http://json-schema.org/).\\n- [Document Symbols](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentSymbol) for quick navigation to properties in the document.\\n- [Document Colors](https://microsoft.github.io/language-server-protocol/specification#textDocument_documentColor) for showing color decorators on values representing colors and [Color Presentation](https://microsoft.github.io/language-server-protocol/specification#textDocument_colorPresentation) for color presentation information to support color pickers. The location of colors is defined by the document\\'s [JSON schema](http://json-schema.org/). All values marked with `\"format\": \"color-hex\"` (VSCode specific, non-standard JSON Schema extension) are considered color values. The supported color formats are `#rgb[a]` and `#rrggbb[aa]`.\\n- [Code Formatting](https://microsoft.github.io/language-server-protocol/specification#textDocument_rangeFormatting) supporting ranges and formatting the whole document.\\n- [Folding Ranges](https://microsoft.github.io/language-server-protocol/specification#textDocument_foldingRange) for all folding ranges in the document.\\n- Semantic Selection for semantic selection for one or multiple cursor positions.\\n- [Goto Definition](https://microsoft.github.io/language-server-protocol/specification#textDocument_definition) for $ref references in JSON schemas\\n- [Diagnostics (Validation)](https://microsoft.github.io/language-server-protocol/specification#textDocument_publishDiagnostics) are pushed for all open documents\\n  - syntax errors\\n  - structural validation based on the document\\'s [JSON schema](http://json-schema.org/).\\n\\nIn order to load JSON schemas, the JSON server uses NodeJS `http` and `fs` modules. For all other features, the JSON server only relies on the documents and settings provided by the client through the LSP.\\n\\n### Client requirements\\n\\nThe JSON language server expects the client to only send requests and notifications for documents of language id `json` and `jsonc`.\\n\\nThe JSON language server has the following dependencies on the client\\'s capabilities:\\n\\n- Code completion requires that the client capability has *snippetSupport*. If not supported by the client, the server will not offer the completion capability.\\n- Formatting support requires the client to support *dynamicRegistration* for *rangeFormatting*. If not supported by the client, the server will not offer the format capability.\\n\\n## Configuration\\n\\n### Initialization options\\n\\nThe client can send the following initialization options to the server:\\n\\n- `provideFormatter: boolean | undefined`. If defined, the value defines whether the server provides the `documentRangeFormattingProvider` capability on initialization. If undefined, the setting `json.format.enable` is used to determine whether formatting is provided. The formatter will then be registered through dynamic registration. If the client does not support dynamic registration, no formatter will be available.\\n- `handledSchemaProtocols`: The URI schemas handles by the server. See section `Schema configuration` below.\\n- `customCapabilities`: Additional non-LSP client capabilities:\\n  - `rangeFormatting: { editLimit: x } }`: For performance reasons, limit the number of edits returned by the range formatter to `x`.\\n\\n### Settings\\n\\nClients may send a `workspace/didChangeConfiguration` notification to notify the server of settings changes.\\nThe server supports the following settings:\\n\\n- http\\n  - `proxy`: The URL of the proxy server to use when fetching schema. When undefined or empty, no proxy is used.\\n  - `proxyStrictSSL`: Whether the proxy server certificate should be verified against the list of supplied CAs.\\n\\n- json\\n  - `format`\\n    - `enable`: Whether the server should register the formatting support. This option is only applicable if the client supports *dynamicRegistration* for *rangeFormatting* and `initializationOptions.provideFormatter` is not defined.\\n  - `validate`\\n    - `enable`: Whether the server should validate. Defaults to `true` if not set.\\n  - `schemas`: Configures association of file names to schema URL or schemas and/or associations of schema URL to schema content.\\n    - `fileMatch`: an array of file names or paths (separated by `/`). `*` can be used as a wildcard. Exclusion patterns can also be defined and start with \\'!\\'. A file matches when there is at least one matching pattern and the last matching pattern is not an exclusion pattern.\\n    - `folderUri`: If provided, the association is only used if the document is located in the given folder (directly or in a subfolder)\\n    - `url`: The URL of the schema, optional when also a schema is provided.\\n    - `schema`: The schema content, optional\\n  - `resultLimit`: The max number of color decorators and outline symbols to be computed (for performance reasons)\\n  - `jsonFoldingLimit`: The max number of folding ranges to be computed for json documents (for performance reasons)\\n  - `jsoncFoldingLimit`: The max number of folding ranges to be computed for jsonc documents (for performance reasons)\\n\\n```json\\n    {\\n        \"http\": {\\n            \"proxy\": \"\",\\n            \"proxyStrictSSL\": true\\n        },\\n        \"json\": {\\n            \"format\": {\\n                \"enable\": true\\n            },\\n            \"schemas\": [\\n                {\\n                    \"fileMatch\": [\\n                        \"foo.json\",\\n                        \"*.superfoo.json\"\\n                    ],\\n                    \"url\": \"http://www.schemastore.org/foo\",\\n                    \"schema\": {\\n                        \"type\": \"array\"\\n                    }\\n                }\\n            ]\\n        }\\n    }\\n```\\n\\n### Schema configuration and custom schema content delivery\\n\\n[JSON schemas](http://json-schema.org/) are essential for code assist, hovers, color decorators to work and are required for structural validation.\\n\\nTo find the schema for a given JSON document, the server uses the following mechanisms:\\n\\n- JSON documents can define the schema URL using a `$schema` property\\n- The settings define a schema association based on the documents URL. Settings can either associate a schema URL to a file or path pattern, and they can directly provide a schema.\\n- Additionally, schema associations can also be provided by a custom \\'schemaAssociations\\' configuration call.\\n\\nSchemas are identified by URLs. To load the content of a schema, the JSON language server either tries to load from that URI or path itself or delegates to the client.\\n\\nThe `initializationOptions.handledSchemaProtocols` initialization option defines which URLs are handled by the server. Requests for all other URIs are sent to the client.\\n\\n`handledSchemaProtocols` is part of the initialization options and can\\'t be changed while the server is running.\\n\\n```ts\\nlet clientOptions: LanguageClientOptions = {\\n  initializationOptions: {\\n   handledSchemaProtocols: [\\'file\\'] // language server should only try to load file URLs\\n  }\\n        ...\\n}\\n```\\n\\nIf `handledSchemaProtocols` is not set, the JSON language server will load the following URLs itself:\\n\\n- `http`, `https`: Loaded using NodeJS\\'s HTTP support. Proxies can be configured through the settings.\\n- `file`: Loaded using NodeJS\\'s `fs` support.\\n\\n#### Schema content request\\n\\nRequests for schemas with URLs not handled by the server are forwarded to the client through an LSP request. This request is a JSON language server-specific, non-standardized, extension to the LSP.\\n\\nRequest:\\n\\n- method: \\'vscode/content\\'\\n- params: `string` - The schema URL to request.\\n- response: `string` - The content of the schema with the given URL\\n\\n#### Schema content change notification\\n\\nWhen the client is aware that a schema content has changed, it will notify the server through a notification. This notification is a JSON language server-specific, non-standardized, extension to the LSP.\\nThe server will, as a response, clear the schema content from the cache and reload the schema content when required again.\\n\\n#### Schema associations notification'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/jake/README.md', 'node_id': 4753671}, 'preview': \"# Jake - JavaScript build tool\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Jake](http://jakejs.com/) tasks defined in a `Jakefile.js` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Jake tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Jake tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `jake.autoDetect` - Enable detecting tasks from `Jakefile.js` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/ipynb/README.md', 'node_id': 4753950}, 'preview': '# Jupyter for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following Jupyter-related features for VS Code:\\n\\n- Open, edit and save .ipynb files'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/html-language-features/README.md', 'node_id': 4756255}, 'preview': '# Language Features for HTML\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [HTML in Visual Studio Code](https://code.visualstudio.com/docs/languages/html) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/html-language-features/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/gulp/README.md', 'node_id': 4762501}, 'preview': \"# Gulp - Automate and enhance your workflow\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Gulp](https://gulpjs.com/) tasks defined in a `gulpfile.{js,ts}` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Gulp tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Gulp tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `gulp.autoDetect` - Enable detecting tasks from `gulpfile.{js,ts}` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/grunt/README.md', 'node_id': 4762784}, 'preview': \"# Grunt - The JavaScript Task Runner\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension supports running [Grunt](https://gruntjs.com/) tasks defined in a `gruntfile.js` file as [VS Code tasks](https://code.visualstudio.com/docs/editor/tasks). Grunt tasks with the name 'build', 'compile', or 'watch' are treated as build tasks.\\n\\nTo run Grunt tasks, use the **Tasks** menu.\\n\\n## Settings\\n\\n- `grunt.autoDetect` - Enable detecting tasks from `gruntfile.js` files, the default is `on`.\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/github-authentication/README.md', 'node_id': 4763067}, 'preview': '# GitHub Authentication for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides support for authenticating to GitHub. It registers the `github` Authentication Provider that can be leveraged by other extensions. This also provides the GitHub authentication used by Settings Sync.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/github/README.md', 'node_id': 4764868}, 'preview': '# GitHub for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nThis extension provides the following GitHub-related features for VS Code:\\n\\n- `Publish to GitHub` command\\n- `Clone from GitHub` participant to the `Git: Clone` command\\n- GitHub authentication for built-in git commands, controlled via the `github.gitAuthentication` command\\n- Automatic fork creation when attempting to push to a repository without permissions'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/git-base/README.md', 'node_id': 4766997}, 'preview': \"# Git static contributions and remote repository picker\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nGit static contributions and remote repository picker.\\n\\n## API\\n\\nThe Git extension exposes an API, reachable by any other extension.\\n\\n1. Copy `src/api/git-base.d.ts` to your extension's sources;\\n2. Include `git-base.d.ts` in your extension's compilation.\\n3. Get a hold of the API with the following snippet:\\n\\n ```ts\\n const gitBaseExtension = vscode.extensions.getExtension<GitBaseExtension>('vscode.git-base').exports;\\n const git = gitBaseExtension.getAPI(1);\\n\\n ```\"}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/git/README.md', 'node_id': 4767671}, 'preview': '# Git integration for Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Git support in VS Code](https://code.visualstudio.com/docs/editor/versioncontrol#_git-support) to learn about the features of this extension.\\n\\n## API\\n\\nThe Git extension exposes an API, reachable by any other extension.\\n\\n1. Copy `src/api/git.d.ts` to your extension\\'s sources;\\n2. Include `git.d.ts` in your extension\\'s compilation.\\n3. Get a hold of the API with the following snippet:\\n\\n\\t```ts\\n\\tconst gitExtension = vscode.extensions.getExtension<GitExtension>(\\'vscode.git\\').exports;\\n\\tconst git = gitExtension.getAPI(1);\\n\\t```\\n\\t**Note:** To ensure that the `vscode.git` extension is activated before your extension, add `extensionDependencies` ([docs](https://code.visualstudio.com/api/references/extension-manifest)) into the `package.json` of your extension:\\n\\t```json\\n\\t\"extensionDependencies\": [\\n\\t\\t\"vscode.git\"\\n\\t]\\n\\t```'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/emmet/README.md', 'node_id': 4776208}, 'preview': '# Emmet integration in Visual Studio Code\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [Emmet in Visual Studio Code](https://code.visualstudio.com/docs/editor/emmet) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/emmet/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/css-language-features/README.md', 'node_id': 4781506}, 'preview': '# Language Features for CSS, SCSS, and LESS files\\n\\n**Notice:** This extension is bundled with Visual Studio Code. It can be disabled but not uninstalled.\\n\\n## Features\\n\\nSee [CSS, SCSS and Less in VS Code](https://code.visualstudio.com/docs/languages/css) to learn about the features of this extension.\\n\\nPlease read the [CONTRIBUTING.md](https://github.com/microsoft/vscode/blob/master/extensions/css-language-features/CONTRIBUTING.md) file to learn how to contribute to this extension.'}, {'FileNode': {'basename': 'README.md', 'relative_path': 'build/monaco/README.md', 'node_id': 4803521}, 'preview': '# Steps to publish a new version of monaco-editor-core\\n\\n## Generate monaco.d.ts\\n\\n* The `monaco.d.ts` is now automatically generated when running `gulp watch`\\n\\n## Bump version\\n\\n* increase version in `build/monaco/package.json`\\n\\n## Generate npm contents for monaco-editor-core\\n\\n* Be sure to have all changes committed **and pushed to the remote**\\n* (the generated files contain the HEAD sha and that should be available on the remote)\\n* run gulp editor-distro\\n\\n## Publish\\n\\n* `cd out-monaco-editor-core`\\n* `npm publish`'}, {'FileNode': {'basename': 'README.md', 'relative_path': '.devcontainer/README.md', 'node_id': 4836320}, 'preview': '# Code - OSS Development Container\\n\\n[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode)\\n\\nThis repository includes configuration for a development container for working with Code - OSS in a local container or using [GitHub Codespaces](https://github.com/features/codespaces).\\n\\n> **Tip:** The default VNC password is `vscode`. The VNC server runs on port `5901` and a web client is available on port `6080`.\\n\\n## Quick start - local\\n\\nIf you already have VS Code and Docker installed, you can click the badge above or [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. Clicking these links will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\\n\\n1. Install Docker Desktop or Docker for Linux on your local machine. (See [docs](https://aka.ms/vscode-remote/containers/getting-started) for additional details.)\\n\\n2. **Important**: Docker needs at least **4 Cores and 8 GB of RAM** to run a full build with **9 GB of RAM** being recommended. If you are on macOS, or are using the old Hyper-V engine for Windows, update these values for Docker Desktop by right-clicking on the Docker status bar item and going to **Preferences/Settings > Resources > Advanced**.\\n\\n   > **Note:** The [Resource Monitor](https://marketplace.visualstudio.com/items?itemName=mutantdino.resourcemonitor) extension is included in the container so you can keep an eye on CPU/Memory in the status bar.\\n\\n3. Install [Visual Studio Code Stable](https://code.visualstudio.com/) or [Insiders](https://code.visualstudio.com/insiders/) and the [Dev Containers](https://aka.ms/vscode-remote/download/containers) extension.\\n\\n   ![Image of Dev Containers extension](https://microsoft.github.io/vscode-remote-release/images/dev-containers-extn.png)\\n\\n   > **Note:** The Dev Containers extension requires the Visual Studio Code distribution of Code - OSS. See the [FAQ](https://aka.ms/vscode-remote/faq/license) for details.\\n\\n4. Press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd> and select **Dev Containers: Clone Repository in Container Volume...**.\\n\\n   > **Tip:** While you can use your local source tree instead, operations like `npm i` can be slow on macOS or when using the Hyper-V engine on Windows. We recommend using the WSL filesystem on Windows or the \"clone repository in container\" approach on Windows and macOS instead since it uses \"named volume\" rather than the local filesystem.\\n\\n5. Type `https://github.com/microsoft/vscode` (or a branch or PR URL) in the input box and press <kbd>Enter</kbd>.\\n\\n6. After the container is running:\\n    1. If you have the `DISPLAY` or `WAYLAND_DISPLAY` environment variables set locally (or in WSL on Windows), desktop apps in the container will be shown in local windows.\\n    2. If these are not set, open a web browser and go to [http://localhost:6080](http://localhost:6080), or use a [VNC Viewer][def] to connect to `localhost:5901` and enter `vscode` as the password. Anything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n## Quick start - GitHub Codespaces\\n\\n1. From the [microsoft/vscode GitHub repository](https://github.com/microsoft/vscode), click on the **Code** dropdown, select **Open with Codespaces**, and then click on **New codespace**. If prompted, select the **Standard** machine size (which is also the default).\\n\\n   > **Note:** You will not see these options within GitHub if you are not in the Codespaces beta.\\n\\n2. After the codespace is up and running in your browser, press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd> and select **Ports: Focus on Ports View**.\\n\\n3. You should see **VNC web client (6080)** under in the list of ports. Select the line and click on the globe icon to open it in a browser tab.\\n\\n    > **Tip:** If you do not see the port, <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd>, select **Forward a Port** and enter port `6080`.\\n\\n4. In the new tab, you should see noVNC. Click **Connect** and enter `vscode` as the password.\\n\\nAnything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n### Using VS Code with GitHub Codespaces\\n\\nYou may see improved VNC responsiveness when accessing a codespace from VS Code client since you can use a [VNC Viewer][def]. Here\\'s how to do it.\\n\\n1. Install [Visual Studio Code Stable](https://code.visualstudio.com/) or [Insiders](https://code.visualstudio.com/insiders/) and the [GitHub Codespaces extension](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces).\\n\\n    > **Note:** The GitHub Codespaces extension requires the Visual Studio Code distribution of Code - OSS.\\n\\n2. After the VS Code is up and running, press <kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> or <kbd>F1</kbd>, choose **Codespaces: Create New Codespace**, and use the following settings:\\n\\n- `microsoft/vscode` for the repository.\\n- Select any branch (e.g. **main**) - you can select a different one later.\\n- Choose **Standard** (4-core, 8GB) as the size.\\n\\n3. After you have connected to the codespace, you can use a [VNC Viewer][def] to connect to `localhost:5901` and enter `vscode` as the password.\\n\\n    > **Tip:** You may also need change your VNC client\\'s **Picture Quality** setting to **High** to get a full color desktop.\\n\\n4. Anything you start in VS Code, or the integrated terminal, will appear here.\\n\\nNext: **[Try it out!](#try-it)**\\n\\n## Try it\\n\\nThis container uses the [Fluxbox](http://fluxbox.org/) window manager to keep things lean. **Right-click on the desktop** to see menu options. It works with GNOME and GTK applications, so other tools can be installed if needed.\\n\\n   > **Note:** You can also set the resolution from the command line by typing `set-resolution`.\\n\\nTo start working with Code - OSS, follow these steps:\\n\\n1. In your local VS Code client, open a terminal (<kbd>Ctrl/Cmd</kbd> + <kbd>Shift</kbd> + <kbd>\\\\`</kbd>) and type the following commands:\\n\\n   ```bash\\n   npm i\\n   bash scripts/code.sh\\n   ```\\n\\n2. After the build is complete, open a web browser or a [VNC Viewer][def] to connect to the desktop environment as described in the quick start and enter `vscode` as the password.\\n\\n3. You should now see Code - OSS!\\n\\nNext, let\\'s try debugging.\\n\\n1. Shut down Code - OSS by clicking the box in the upper right corner of the Code - OSS window through your browser or VNC viewer.\\n\\n2. Go to your local VS Code client, and use the **Run / Debug** view to launch the **VS Code** configuration. (Typically the default, so you can likely just press <kbd>F5</kbd>).\\n\\n   > **Note:** If launching times out, you can increase the value of `timeout` in the \"VS Code\", \"Attach Main Process\", \"Attach Extension Host\", and \"Attach to Shared Process\" configurations in [launch.json](../.vscode/launch.json). However, running `./scripts/code.sh` first will set up Electron which will usually solve timeout issues.\\n\\n3. After a bit, Code - OSS will appear with the debugger attached!\\n\\nEnjoy!\\n\\n### Notes\\n\\nThe container comes with VS Code Insiders installed. To run it from an Integrated Terminal use `VSCODE_IPC_HOOK_CLI= /usr/bin/code-insiders .`.\\n\\n[def]: https://www.realvnc.com/en/connect/download/viewer/'}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_DczNUnzaH2seU9aR7rKRFg5r', 'function': {'arguments': '{\"basename\":\"README.md\"}', 'name': 'find_file_node_with_basename'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 37897, 'total_tokens': 37917, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 37760}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--8f50f096-7b29-41e3-9123-c7b3236eab61-0' tool_calls=[{'name': 'find_file_node_with_basename', 'args': {'basename': 'README.md'}, 'id': 'call_DczNUnzaH2seU9aR7rKRFg5r', 'type': 'tool_call'}] usage_metadata={'input_tokens': 37897, 'output_tokens': 20, 'total_tokens': 37917, 'input_token_details': {'audio': 0, 'cache_read': 37760}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content=\"Result 1:\\nFileNode: {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3734887}\\n\\n\\nResult 2:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3734900}\\n\\n\\nResult 3:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3734908}\\n\\n\\nResult 4:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/smoke/README.md', 'node_id': 3736755}\\n\\n\\nResult 5:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/monaco/README.md', 'node_id': 3738548}\\n\\n\\nResult 6:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/mcp/README.md', 'node_id': 3738926}\\n\\n\\nResult 7:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/integration/browser/README.md', 'node_id': 3740947}\\n\\n\\nResult 8:\\nFileNode: {'basename': 'README.md', 'relative_path': 'test/automation/README.md', 'node_id': 3741239}\\n\\n\\nResult 9:\\nFileNode: {'basename': 'README.md', 'relative_path': 'src/vscode-dts/README.md', 'node_id': 3744265}\\n\\n\\nResult 10:\\nFileNode: {'basename': 'README.md', 'relative_path': 'src/vs/workbench/contrib/terminalContrib/README.md', 'node_id': 3897567}\\n\\n\\nResult 11:\\nFileNode: {'basename': 'README.md', 'relative_path': 'src/vs/editor/test/node/diffing/README.md', 'node_id': 4481497}\\n\\n\\nResult 12:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/README.md', 'node_id': 4707968}\\n\\n\\nResult 13:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/web/README.md', 'node_id': 4707977}\\n\\n\\nResult 14:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/theme-seti/README.md', 'node_id': 4725047}\\n\\n\\nResult 15:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/README.md', 'node_id': 4725296}\\n\\n\\nResult 16:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/src/fig/README.md', 'node_id': 4728058}\\n\\n\\nResult 17:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/simple-browser/README.md', 'node_id': 4735296}\\n\\n\\nResult 18:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/search-result/README.md', 'node_id': 4735682}\\n\\n\\nResult 19:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/references-view/README.md', 'node_id': 4735988}\\n\\n\\nResult 20:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/php-language-features/README.md', 'node_id': 4737042}\\n\\n\\nResult 21:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/npm/README.md', 'node_id': 4737797}\\n\\n\\nResult 22:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/notebook-renderers/README.md', 'node_id': 4739483}\\n\\n\\nResult 23:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/microsoft-authentication/README.md', 'node_id': 4740838}\\n\\n\\nResult 24:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/mermaid-chat-features/README.md', 'node_id': 4743452}\\n\\n\\nResult 25:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/merge-conflict/README.md', 'node_id': 4743675}\\n\\n\\nResult 26:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/media-preview/README.md', 'node_id': 4744324}\\n\\n\\nResult 27:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/markdown-math/README.md', 'node_id': 4745044}\\n\\n\\nResult 28:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/markdown-language-features/README.md', 'node_id': 4745172}\\n\\n\\nResult 29:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/README.md', 'node_id': 4751670}\\n\\n\\nResult 30:\\nFileNode: {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/server/README.md', 'node_id': 4751677}\" name='find_file_node_with_basename' id='fb6c825a-d649-4fc1-826b-ad4ab065de63' tool_call_id='call_DczNUnzaH2seU9aR7rKRFg5r' artifact=[{'FileNode': {'basename': 'README.md', 'relative_path': 'README.md', 'node_id': 3734887}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/README.md', 'node_id': 3734900}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/unit/README.md', 'node_id': 3734908}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/smoke/README.md', 'node_id': 3736755}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/monaco/README.md', 'node_id': 3738548}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/mcp/README.md', 'node_id': 3738926}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/integration/browser/README.md', 'node_id': 3740947}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'test/automation/README.md', 'node_id': 3741239}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vscode-dts/README.md', 'node_id': 3744265}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/workbench/contrib/terminalContrib/README.md', 'node_id': 3897567}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'src/vs/editor/test/node/diffing/README.md', 'node_id': 4481497}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/README.md', 'node_id': 4707968}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/typescript-language-features/web/README.md', 'node_id': 4707977}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/theme-seti/README.md', 'node_id': 4725047}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/README.md', 'node_id': 4725296}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/terminal-suggest/src/fig/README.md', 'node_id': 4728058}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/simple-browser/README.md', 'node_id': 4735296}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/search-result/README.md', 'node_id': 4735682}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/references-view/README.md', 'node_id': 4735988}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/php-language-features/README.md', 'node_id': 4737042}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/npm/README.md', 'node_id': 4737797}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/notebook-renderers/README.md', 'node_id': 4739483}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/microsoft-authentication/README.md', 'node_id': 4740838}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/mermaid-chat-features/README.md', 'node_id': 4743452}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/merge-conflict/README.md', 'node_id': 4743675}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/media-preview/README.md', 'node_id': 4744324}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-math/README.md', 'node_id': 4745044}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/markdown-language-features/README.md', 'node_id': 4745172}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/README.md', 'node_id': 4751670}}, {'FileNode': {'basename': 'README.md', 'relative_path': 'extensions/json-language-features/server/README.md', 'node_id': 4751677}}]",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Check the main README.md file and any Quickstart, Installation, or Getting Started sections for a quick verification command.' additional_kwargs={} response_metadata={} id='36ca7864-ae00-4b9d-bd63-ac7d90c5b560'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Check the main README.md file and any Quickstart, Installation, or Getting Started sections for a quick verification command.' additional_kwargs={} response_metadata={} id='27185d90-e8a2-486c-821e-c1047975a5b6'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search the main README.md or Quickstart/Installation/Getting Started sections for a quick verification command, such as a version check or a basic test command.' additional_kwargs={} response_metadata={} id='b5ab4613-10aa-4668-930f-3296a1358a89'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Check the main README.md file for a quick verification command or instructions in Quickstart, Installation, or Getting Started sections.' additional_kwargs={} response_metadata={} id='f573eeb3-34f2-4ce1-9aeb-b782eed3a552'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "HumanMessage",
                    "content": "content='Search the root README.md or any Quickstart/Getting Started sections for a quick verification command, such as a version check or test run.' additional_kwargs={} response_metadata={} id='f1dfc85a-511b-4f0c-a367-2837d60dd73d'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "testsuite_refined_query": "",
            "testsuite_command": []
        },
        "env_states": {
            "max_refined_query_loop": 3,
            "env_implement_file_context_query": "OBJECTIVE: Find the most relevant environment configuration files that can help generate an accurate Dockerfile for this project,\nincluding Dockerfiles, dependency files, build configurations, and environment setup files.\n\n<reasoning>\n1. Analyze project characteristics:\n   - Programming language and framework\n   - Dependency management files\n   - Build system and tools\n   - Runtime requirements\n   - Environment configurations\n\n2. Search requirements:\n   - Existing Dockerfiles or containerization files\n   - Dependency files (requirements.txt, package.json, pom.xml, etc.)\n   - Build configuration files (Makefile, CMakeLists.txt, etc.)\n   - Environment configuration files (.env, config files)\n   - Setup and installation scripts\n\n3. Focus areas:\n   - Docker-related files (Dockerfile, docker-compose.yml, .dockerignore)\n   - Package management files (requirements.txt, package.json, go.mod, Cargo.toml, etc.)\n   - Build system files (Makefile, CMakeLists.txt, build.gradle, etc.)\n   - Environment configuration (.env, config.json, application.properties, etc.)\n   - Setup documentation (README.md, INSTALL.md, SETUP.md)\n   - CI/CD configuration files\n</reasoning>\n\nREQUIREMENTS:\n- Return the most relevant environment configuration files for Dockerfile generation\n- Must include complete file content with exact file paths and line numbers\n- Must include dependency files, build configurations, and environment setups\n- Must include any existing Docker-related files\n- Must include setup documentation and installation instructions\n\n<examples>\n<example id=\"python-web-app\">\n<project_context>\nPython Flask web application with requirements.txt\n</project_context>\n\n<ideal_files>\n# File: requirements.txt\nFlask==2.3.3\ngunicorn==21.2.0\npsycopg2-binary==2.9.7\nredis==4.6.0\n\n# File: app.py\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    return 'Hello World!'\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)\n\n# File: README.md\n## Installation\npip install -r requirements.txt\npython app.py\n</ideal_files>\n</example>\n\n<example id=\"nodejs-api\">\n<project_context>\nNode.js Express API with package.json\n</project_context>\n\n<ideal_files>\n# File: package.json\n{\n  \"name\": \"my-api\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^7.5.0\"\n  }\n}\n\n# File: server.js\nconst express = require('express');\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\napp.get('/', (req, res) => {\n  res.json({ message: 'API is running' });\n});\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});\n</ideal_files>\n</example>\n\nSearch priority:\n1. Existing Dockerfiles or containerization files\n2. Dependency management files (requirements.txt, package.json, etc.)\n3. Build configuration files (Makefile, CMakeLists.txt, etc.)\n4. Environment configuration files (.env, config files)\n5. Setup documentation and installation instructions\n\nFind the most relevant environment configuration files with complete context for Dockerfile generation.\n",
            "env_implement_file_context": [
                {
                    "type": "Context",
                    "content": "File: README.md\nLine number range: 65 - 78\nContent:\n65. \n66. * For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\n67. \n68. Docker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\n69. \n70. ## Code of Conduct\n71. \n72. This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n73. \n74. ## License\n75. \n76. Copyright (c) Microsoft Corporation. All rights reserved.\n77. \n78. Licensed under the [MIT](LICENSE.txt) license.\n",
                    "relative_path": "README.md",
                    "start_line_number": 65,
                    "end_line_number": 78
                }
            ],
            "env_implement_write_messages": [
                {
                    "type": "HumanMessage",
                    "content": "content=\"Project Environment Context:\\nFile: README.md\\nLine number range: 65 - 78\\nContent:\\n65. \\n66. * For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\\n67. \\n68. Docker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\\n69. \\n70. ## Code of Conduct\\n71. \\n72. This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n73. \\n74. ## License\\n75. \\n76. Copyright (c) Microsoft Corporation. All rights reserved.\\n77. \\n78. Licensed under the [MIT](LICENSE.txt) license.\\n\\n\\n\\nNow generate a complete executable bash script that can successfully set up and configure the environment for this project, especially designed to run inside Docker containers. The bash script should:\\n1. Install the appropriate runtime and dependencies for the project's technology stack\\n2. Install all necessary system packages and tools\\n3. Set up the project directory structure and permissions\\n4. Configure the runtime environment properly\\n5. Set up necessary environment variables and configurations\\n6. Follow bash scripting best practices for error handling and security\\n\\nMake sure the bash script is self-contained and can set up the project environment from scratch in a Docker container environment.\\n\" additional_kwargs={} response_metadata={} id='8c6b073b-c6f5-4f56-97e7-f1d55177dcce'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='```bash\\n#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is running as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root. Exiting.\"\\n    exit 1\\nfi\\n\\n# Install necessary system packages\\ninstall_system_packages() {\\n    log \"Installing necessary system packages...\"\\n    apt-get update\\n    apt-get install -y \\\\\\n        curl \\\\\\n        git \\\\\\n        build-essential \\\\\\n        wget \\\\\\n        unzip \\\\\\n        ca-certificates \\\\\\n        software-properties-common\\n    log \"System packages installed successfully.\"\\n}\\n\\n# Install Docker (if not already installed)\\ninstall_docker() {\\n    if ! command -v docker &> /dev/null; then\\n        log \"Docker not found. Installing Docker...\"\\n        curl -fsSL https://get.docker.com | bash\\n        log \"Docker installed successfully.\"\\n    else\\n        log \"Docker is already installed.\"\\n    fi\\n}\\n\\n# Set up project directory structure\\nsetup_project_directory() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /workspace/project\\n    chmod -R 755 /workspace/project\\n    log \"Project directory structure set up successfully.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime_environment() {\\n    log \"Configuring runtime environment...\"\\n    export PROJECT_HOME=\"/workspace/project\"\\n    export PATH=\"$PROJECT_HOME/bin:$PATH\"\\n    log \"Runtime environment configured successfully.\"\\n}\\n\\n# Set up environment variables\\nsetup_environment_variables() {\\n    log \"Setting up environment variables...\"\\n    export CODESPACE_MIN_CORES=4\\n    export CODESPACE_MIN_RAM=6\\n    export CODESPACE_RECOMMENDED_RAM=8\\n    log \"Environment variables set up successfully.\"\\n}\\n\\n# Install project-specific dependencies\\ninstall_project_dependencies() {\\n    log \"Installing project-specific dependencies...\"\\n    # Placeholder for project-specific dependency installation\\n    # Example: Install Node.js if the project uses it\\n    curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n    apt-get install -y nodejs\\n    log \"Project-specific dependencies installed successfully.\"\\n}\\n\\n# Main function to orchestrate the setup\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_packages\\n    install_docker\\n    setup_project_directory\\n    configure_runtime_environment\\n    setup_environment_variables\\n    install_project_dependencies\\n\\n    log \"Project environment setup completed successfully!\"\\n}\\n\\n# Run the main function\\nmain \"$@\"\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 645, 'prompt_tokens': 1402, 'total_tokens': 2047, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--e7219f90-7962-41e1-91d8-bf5aa429c98b-0' usage_metadata={'input_tokens': 1402, 'output_tokens': 645, 'total_tokens': 2047, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_file_messages": [
                {
                    "type": "AIMessage",
                    "content": "content='' additional_kwargs={'tool_calls': [{'id': 'call_HbaUGNUuGSSZuDNX5k4j0kZp', 'function': {'arguments': '{\"relative_path\":\"prometheus_setup.sh\",\"content\":\"#!/bin/bash\\\\n\\\\n# Exit immediately if a command exits with a non-zero status\\\\nset -e\\\\n\\\\n# Colors for output\\\\nRED=\\'\\\\\\\\033[0;31m\\'\\\\nGREEN=\\'\\\\\\\\033[0;32m\\'\\\\nYELLOW=\\'\\\\\\\\033[1;33m\\'\\\\nNC=\\'\\\\\\\\033[0m\\' # No Color\\\\n\\\\n# Logging functions\\\\nlog() {\\\\n    echo -e \\\\\"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\\\\\"\\\\n}\\\\n\\\\nerror() {\\\\n    echo -e \\\\\"${RED}[ERROR] $1${NC}\\\\\" >&2\\\\n}\\\\n\\\\nwarning() {\\\\n    echo -e \\\\\"${YELLOW}[WARNING] $1${NC}\\\\\"\\\\n}\\\\n\\\\n# Ensure the script is running as root (Docker containers typically run as root)\\\\nif [ \\\\\"$(id -u)\\\\\" -ne 0 ]; then\\\\n    error \\\\\"This script must be run as root. Exiting.\\\\\"\\\\n    exit 1\\\\nfi\\\\n\\\\n# Install necessary system packages\\\\ninstall_system_packages() {\\\\n    log \\\\\"Installing necessary system packages...\\\\\"\\\\n    apt-get update\\\\n    apt-get install -y \\\\\\\\\\\\n        curl \\\\\\\\\\\\n        git \\\\\\\\\\\\n        build-essential \\\\\\\\\\\\n        wget \\\\\\\\\\\\n        unzip \\\\\\\\\\\\n        ca-certificates \\\\\\\\\\\\n        software-properties-common\\\\n    log \\\\\"System packages installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Install Docker (if not already installed)\\\\ninstall_docker() {\\\\n    if ! command -v docker &> /dev/null; then\\\\n        log \\\\\"Docker not found. Installing Docker...\\\\\"\\\\n        curl -fsSL https://get.docker.com | bash\\\\n        log \\\\\"Docker installed successfully.\\\\\"\\\\n    else\\\\n        log \\\\\"Docker is already installed.\\\\\"\\\\n    fi\\\\n}\\\\n\\\\n# Set up project directory structure\\\\nsetup_project_directory() {\\\\n    log \\\\\"Setting up project directory structure...\\\\\"\\\\n    mkdir -p /workspace/project\\\\n    chmod -R 755 /workspace/project\\\\n    log \\\\\"Project directory structure set up successfully.\\\\\"\\\\n}\\\\n\\\\n# Configure runtime environment\\\\nconfigure_runtime_environment() {\\\\n    log \\\\\"Configuring runtime environment...\\\\\"\\\\n    export PROJECT_HOME=\\\\\"/workspace/project\\\\\"\\\\n    export PATH=\\\\\"$PROJECT_HOME/bin:$PATH\\\\\"\\\\n    log \\\\\"Runtime environment configured successfully.\\\\\"\\\\n}\\\\n\\\\n# Set up environment variables\\\\nsetup_environment_variables() {\\\\n    log \\\\\"Setting up environment variables...\\\\\"\\\\n    export CODESPACE_MIN_CORES=4\\\\n    export CODESPACE_MIN_RAM=6\\\\n    export CODESPACE_RECOMMENDED_RAM=8\\\\n    log \\\\\"Environment variables set up successfully.\\\\\"\\\\n}\\\\n\\\\n# Install project-specific dependencies\\\\ninstall_project_dependencies() {\\\\n    log \\\\\"Installing project-specific dependencies...\\\\\"\\\\n    # Placeholder for project-specific dependency installation\\\\n    # Example: Install Node.js if the project uses it\\\\n    curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\\\n    apt-get install -y nodejs\\\\n    log \\\\\"Project-specific dependencies installed successfully.\\\\\"\\\\n}\\\\n\\\\n# Main function to orchestrate the setup\\\\nmain() {\\\\n    log \\\\\"Starting project environment setup...\\\\\"\\\\n\\\\n    install_system_packages\\\\n    install_docker\\\\n    setup_project_directory\\\\n    configure_runtime_environment\\\\n    setup_environment_variables\\\\n    install_project_dependencies\\\\n\\\\n    log \\\\\"Project environment setup completed successfully!\\\\\"\\\\n}\\\\n\\\\n# Run the main function\\\\nmain \\\\\"$@\\\\\"\"}', 'name': 'create_file'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 766, 'prompt_tokens': 37816, 'total_tokens': 38582, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--50ec2226-730c-44f6-856b-8b543313c798-0' tool_calls=[{'name': 'create_file', 'args': {'relative_path': 'prometheus_setup.sh', 'content': '#!/bin/bash\\n\\n# Exit immediately if a command exits with a non-zero status\\nset -e\\n\\n# Colors for output\\nRED=\\'\\\\033[0;31m\\'\\nGREEN=\\'\\\\033[0;32m\\'\\nYELLOW=\\'\\\\033[1;33m\\'\\nNC=\\'\\\\033[0m\\' # No Color\\n\\n# Logging functions\\nlog() {\\n    echo -e \"${GREEN}[$(date +\\'%Y-%m-%d %H:%M:%S\\')] $1${NC}\"\\n}\\n\\nerror() {\\n    echo -e \"${RED}[ERROR] $1${NC}\" >&2\\n}\\n\\nwarning() {\\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\\n}\\n\\n# Ensure the script is running as root (Docker containers typically run as root)\\nif [ \"$(id -u)\" -ne 0 ]; then\\n    error \"This script must be run as root. Exiting.\"\\n    exit 1\\nfi\\n\\n# Install necessary system packages\\ninstall_system_packages() {\\n    log \"Installing necessary system packages...\"\\n    apt-get update\\n    apt-get install -y \\\\\\n        curl \\\\\\n        git \\\\\\n        build-essential \\\\\\n        wget \\\\\\n        unzip \\\\\\n        ca-certificates \\\\\\n        software-properties-common\\n    log \"System packages installed successfully.\"\\n}\\n\\n# Install Docker (if not already installed)\\ninstall_docker() {\\n    if ! command -v docker &> /dev/null; then\\n        log \"Docker not found. Installing Docker...\"\\n        curl -fsSL https://get.docker.com | bash\\n        log \"Docker installed successfully.\"\\n    else\\n        log \"Docker is already installed.\"\\n    fi\\n}\\n\\n# Set up project directory structure\\nsetup_project_directory() {\\n    log \"Setting up project directory structure...\"\\n    mkdir -p /workspace/project\\n    chmod -R 755 /workspace/project\\n    log \"Project directory structure set up successfully.\"\\n}\\n\\n# Configure runtime environment\\nconfigure_runtime_environment() {\\n    log \"Configuring runtime environment...\"\\n    export PROJECT_HOME=\"/workspace/project\"\\n    export PATH=\"$PROJECT_HOME/bin:$PATH\"\\n    log \"Runtime environment configured successfully.\"\\n}\\n\\n# Set up environment variables\\nsetup_environment_variables() {\\n    log \"Setting up environment variables...\"\\n    export CODESPACE_MIN_CORES=4\\n    export CODESPACE_MIN_RAM=6\\n    export CODESPACE_RECOMMENDED_RAM=8\\n    log \"Environment variables set up successfully.\"\\n}\\n\\n# Install project-specific dependencies\\ninstall_project_dependencies() {\\n    log \"Installing project-specific dependencies...\"\\n    # Placeholder for project-specific dependency installation\\n    # Example: Install Node.js if the project uses it\\n    curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\\n    apt-get install -y nodejs\\n    log \"Project-specific dependencies installed successfully.\"\\n}\\n\\n# Main function to orchestrate the setup\\nmain() {\\n    log \"Starting project environment setup...\"\\n\\n    install_system_packages\\n    install_docker\\n    setup_project_directory\\n    configure_runtime_environment\\n    setup_environment_variables\\n    install_project_dependencies\\n\\n    log \"Project environment setup completed successfully!\"\\n}\\n\\n# Run the main function\\nmain \"$@\"'}, 'id': 'call_HbaUGNUuGSSZuDNX5k4j0kZp', 'type': 'tool_call'}] usage_metadata={'input_tokens': 37816, 'output_tokens': 766, 'total_tokens': 38582, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "ToolMessage",
                    "content": "content='The file prometheus_setup.sh has been created.' name='create_file' id='4ef87adb-f225-4497-997f-7955060f9bfb' tool_call_id='call_HbaUGNUuGSSZuDNX5k4j0kZp'",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                },
                {
                    "type": "AIMessage",
                    "content": "content='The bash script has been saved at the root of the project with the relative path:\\n\\n`prometheus_setup.sh`' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 38599, 'total_tokens': 38624, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 38528}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--729d28fc-9ec7-462a-8521-aefda3d7786f-0' usage_metadata={'input_tokens': 38599, 'output_tokens': 25, 'total_tokens': 38624, 'input_token_details': {'audio': 0, 'cache_read': 38528}, 'output_token_details': {'audio': 0, 'reasoning': 0}}",
                    "relative_path": null,
                    "start_line_number": null,
                    "end_line_number": null
                }
            ],
            "env_implement_execute_messages": [],
            "env_implement_bash_content": "diff --git a/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh b/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh\ndeleted file mode 120000\nindex 8f2b5db2692..00000000000\n--- a/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh\n+++ /dev/null\n@@ -1 +0,0 @@\n-real-executable.sh\n\\ No newline at end of file\ndiff --git a/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh b/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh\nnew file mode 100755\nindex 00000000000..8ff19e15b3c\n--- /dev/null\n+++ b/extensions/terminal-suggest/src/test/fixtures/symlink-test/symlink-executable.sh\n@@ -0,0 +1,2 @@\n+#!/bin/bash\n+echo \"real executable\"\ndiff --git a/prometheus.Dockerfile b/prometheus.Dockerfile\nnew file mode 100644\nindex 00000000000..1616a728241\n--- /dev/null\n+++ b/prometheus.Dockerfile\n@@ -0,0 +1,22 @@\n+FROM ubuntu:24.04\n+\n+# Avoid timezone prompts during package installation\n+ENV DEBIAN_FRONTEND=noninteractive\n+ENV TZ=UTC\n+\n+# Set working directory\n+WORKDIR /app\n+\n+# Install essential build and development tools\n+RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     wget     python3     python3-pip     python3-dev     python3-venv     nodejs     npm     default-jdk     gcc     g++     gdb     postgresql-client     mysql-client     sqlite3     iputils-ping     vim     nano     zip     unzip     ca-certificates     gnupg     lsb-release\n+\n+RUN mkdir -p /etc/apt/keyrings     && curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg     && echo     \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu     $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n+\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+RUN apt-get clean\n+RUN rm -rf /var/lib/apt/lists/*\n+RUN ln -s /usr/bin/python3 /usr/bin/python\n+\n+# Copy project files\n+COPY . /app/\ndiff --git a/prometheus_setup.sh b/prometheus_setup.sh\nnew file mode 100644\nindex 00000000000..064a3076309\n--- /dev/null\n+++ b/prometheus_setup.sh\n@@ -0,0 +1,107 @@\n+#!/bin/bash\n+\n+# Exit immediately if a command exits with a non-zero status\n+set -e\n+\n+# Colors for output\n+RED='\\033[0;31m'\n+GREEN='\\033[0;32m'\n+YELLOW='\\033[1;33m'\n+NC='\\033[0m' # No Color\n+\n+# Logging functions\n+log() {\n+    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n+}\n+\n+error() {\n+    echo -e \"${RED}[ERROR] $1${NC}\" >&2\n+}\n+\n+warning() {\n+    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n+}\n+\n+# Ensure the script is running as root (Docker containers typically run as root)\n+if [ \"$(id -u)\" -ne 0 ]; then\n+    error \"This script must be run as root. Exiting.\"\n+    exit 1\n+fi\n+\n+# Install necessary system packages\n+install_system_packages() {\n+    log \"Installing necessary system packages...\"\n+    apt-get update\n+    apt-get install -y \\\n+        curl \\\n+        git \\\n+        build-essential \\\n+        wget \\\n+        unzip \\\n+        ca-certificates \\\n+        software-properties-common\n+    log \"System packages installed successfully.\"\n+}\n+\n+# Install Docker (if not already installed)\n+install_docker() {\n+    if ! command -v docker &> /dev/null; then\n+        log \"Docker not found. Installing Docker...\"\n+        curl -fsSL https://get.docker.com | bash\n+        log \"Docker installed successfully.\"\n+    else\n+        log \"Docker is already installed.\"\n+    fi\n+}\n+\n+# Set up project directory structure\n+setup_project_directory() {\n+    log \"Setting up project directory structure...\"\n+    mkdir -p /workspace/project\n+    chmod -R 755 /workspace/project\n+    log \"Project directory structure set up successfully.\"\n+}\n+\n+# Configure runtime environment\n+configure_runtime_environment() {\n+    log \"Configuring runtime environment...\"\n+    export PROJECT_HOME=\"/workspace/project\"\n+    export PATH=\"$PROJECT_HOME/bin:$PATH\"\n+    log \"Runtime environment configured successfully.\"\n+}\n+\n+# Set up environment variables\n+setup_environment_variables() {\n+    log \"Setting up environment variables...\"\n+    export CODESPACE_MIN_CORES=4\n+    export CODESPACE_MIN_RAM=6\n+    export CODESPACE_RECOMMENDED_RAM=8\n+    log \"Environment variables set up successfully.\"\n+}\n+\n+# Install project-specific dependencies\n+install_project_dependencies() {\n+    log \"Installing project-specific dependencies...\"\n+    # Placeholder for project-specific dependency installation\n+    # Example: Install Node.js if the project uses it\n+    curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\n+    apt-get install -y nodejs\n+    log \"Project-specific dependencies installed successfully.\"\n+}\n+\n+# Main function to orchestrate the setup\n+main() {\n+    log \"Starting project environment setup...\"\n+\n+    install_system_packages\n+    install_docker\n+    setup_project_directory\n+    configure_runtime_environment\n+    setup_environment_variables\n+    install_project_dependencies\n+\n+    log \"Project environment setup completed successfully!\"\n+}\n+\n+# Run the main function\n+main \"$@\"\n\\ No newline at end of file\ndiff --git a/prometheus_testsuite_commands.txt b/prometheus_testsuite_commands.txt\nnew file mode 100644\nindex 00000000000..e69de29bb2d\n",
            "env_implement_bash_path": "prometheus_setup.sh"
        },
        "timestamp": "2025-10-18T10:34:43.842100"
    }
}